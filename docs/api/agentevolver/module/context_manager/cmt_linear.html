<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 16.0.0"/>
    <title>agentevolver.module.context_manager.cmt_linear API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:27px;vertical-align:bottom;width:50px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../context_manager.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;agentevolver.module.context_manager</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#Linear_CMT">Linear_CMT</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Linear_CMT.__init__">Linear_CMT</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.config">config</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.tokenizer">tokenizer</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.full_context">full_context</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.current_context_status">current_context_status</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.max_seq_length">max_seq_length</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.max_env_output_length">max_env_output_length</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.blackout_token_combo">blackout_token_combo</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.generated_token_cnt">generated_token_cnt</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.terminal_rewards_dict">terminal_rewards_dict</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.discarded">discarded</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.is_terminated">is_terminated</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.reward">reward</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.context_time_cost">context_time_cost</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.tag">tag</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.task_id">task_id</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.current_batch_success_rate">current_batch_success_rate</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.llm_output_mistakes">llm_output_mistakes</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.prepare_previous_context">prepare_previous_context</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.check_context_token_num_safe">check_context_token_num_safe</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.get_inc">get_inc</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.remove_last_context">remove_last_context</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.remove_last_non_llm_msg">remove_last_non_llm_msg</a>
                        </li>
                        <li>
                                <a class="variable" href="#Linear_CMT.steps">steps</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.json">json</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.prepare_next_llm_context">prepare_next_llm_context</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.save_init_input">save_init_input</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.influence_extra_reward">influence_extra_reward</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.save_llm_output">save_llm_output</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.save_llm_output_do_not_register_full_context">save_llm_output_do_not_register_full_context</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.save_env_output">save_env_output</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.to_role_content">to_role_content</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.prepare_world_interaction">prepare_world_interaction</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.filter_context_via_author">filter_context_via_author</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.filter_context_via_authors">filter_context_via_authors</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.group_tokenize">group_tokenize</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.group_render_token_log">group_render_token_log</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.generate_log">generate_log</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.reward_patch">reward_patch</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.compute_madness">compute_madness</a>
                        </li>
                        <li>
                                <a class="function" href="#Linear_CMT.tokenize_steps">tokenize_steps</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22160%22%20viewBox%3D%220%200%20150%2080%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M132.316%2048.886c.276-4.679%202.342-6.698%204.409-7.982s4.27-1.165%206.751-1.055c1.586.07%203.044.156%204.222-.482%201.142-.619%202.026-1.932%202.162-3.739.268-3.576-1.929-5.368-5.006-5.551s-7.599.524-10.517%201.606c-4.455%201.652-8.588%206.606-9.552%208.992s-2.342%206.193-1.745%2010.873%202.664%209.221%205.878%2011.79%205.878%203.808%2010.103%204.312%203.444.229%206.062.229%205.006-2.202%204.914-4.909-2.296-5.001-4.501-4.863-3.077.505-5.281.229-7.715-2.064-7.899-9.451z%22%20fill%3D%22%23198754%22/%3E%3Ccircle%20cx%3D%22101.504%22%20cy%3D%2248.943%22%20r%3D%2214.208%22%20fill%3D%22none%22%20stroke%3D%22%23198754%22%20stroke-width%3D%229.354%22/%3E%3Cpath%20d%3D%22M87.81.002c-3.637.065-5.001.454-7.014%201.232s-3.443%201.363-6.3%204.282c-1.723%201.76-3.148%205.019-3.776%207.329-.413%201.521-.316%202.63-.316%202.63l-.195%2034.612c.065%205.774-6.755%208.305-9.612%208.37s-9.678-1.038-9.743-9.408%207.128-9.521%208.362-9.521c1.413-.13%202.526-.021%203.718-.016%202.071.009%204.157-.778%204.092-4.671s-4.157-4.736-4.157-4.736c-6.3-.843-11.43%202.206-11.43%202.206S40.917%2038.15%2041.372%2049.634%2051.568%2068.19%2061.311%2068.125s18.316-7.007%2018.445-17.193l.13-22.772c.046-2.291%202.683-3.644%204.476-4.203.745-.232%201.694-.274%201.694-.274l10.457-.13s4.871-.324%207.729-3.114%204.352-6.294%204.352-6.294.974-3.049.13-4.606-.195-1.233-2.792-3.309-8.573-4.477-8.573-4.477S91.447-.063%2087.81.002zM0%2047.169l.065%2028.417S0%2080.127%204.481%2079.997s5.072-3.866%205.049-4.152l-.113-28.482s1.624-7.656%209.937-7.721%2010.002%206.942%2010.002%208.499-.909%2010.51-9.093%2010.51c-.948%200-2.99-.567-4.145-.272-3.919%201-3.194%204.554-3.194%204.554s.065%205.061%207.404%204.996%2018.575-6.034%2018.575-19.074S26.953%2030.04%2019.549%2029.91%201.234%2035.296%200%2047.169z%22%20fill%3D%22%23198754%22/%3E%3Cg%20transform%3D%22matrix%28.325601%200%200%20.325256%20-10.32669%20-45.802786%29%22%3E%3Ccircle%20cx%3D%22297.554%22%20cy%3D%22172.286%22%20r%3D%2216.5%22%20fill%3D%22%23fff%22/%3E%3Cellipse%20cx%3D%22297.709%22%20cy%3D%22172.642%22%20rx%3D%2211.071%22%20ry%3D%2210.871%22%20fill%3D%22%23105a48%22/%3E%3Ccircle%20cx%3D%22304.104%22%20cy%3D%22167.667%22%20r%3D%224.5%22%20fill%3D%22%23fff%22/%3E%3C/g%3E%3Cpath%20d%3D%22M94.661%2017.032l.893-1.476s.99.714%201.916.925%201.575.114%202.955.114l14.565-.162c1.283-.032%203.085-.762%203.02-3.293s-.373-3.503-.373-3.503l1.283-.487s.52.503.877%201.573.309%201.995.292%202.66-.227%201.541-.227%201.541%201.564-.308%202.359-1.038.823-.779%201.489-1.508.812-.86.812-.86.552-.13.877.26.341.957.065%201.46-1.672%202.206-3.247%203.066-2.76%201.427-3.929%201.768-3.848.73-7.063.714l-10.944-.114s-2.143-.081-3.02-.373-2.241-.973-2.598-1.265z%22%20fill%3D%22%23d36d49%22/%3E%3Cg%20fill%3D%22%23105a48%22%3E%3Cellipse%20cx%3D%2293.052%22%20cy%3D%2243.567%22%20rx%3D%22.869%22%20ry%3D%221.014%22%20transform%3D%22rotate%28341.022%29%22/%3E%3Cellipse%20cx%3D%22104.3%22%20cy%3D%22-16.184%22%20rx%3D%22.865%22%20ry%3D%221.009%22%20transform%3D%22rotate%2814.786%29%22/%3E%3C/g%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../agentevolver.html">agentevolver</a><wbr>.<a href="./../../module.html">module</a><wbr>.<a href="./../context_manager.html">context_manager</a><wbr>.cmt_linear    </h1>

                
                        <input id="mod-cmt_linear-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-cmt_linear-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">uuid</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.schema.trajectory</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sample</span><span class="p">,</span> <span class="n">Reward</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.schema.trajectory</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sample</span><span class="p">,</span> <span class="n">Trajectory</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.compute_madness</span><span class="w"> </span><span class="kn">import</span> <span class="n">repetition_penalty_reward_scalar</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.context_manager.cmt_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExtendedMessage</span><span class="p">,</span> <span class="n">ContextManagerBase</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.context_manager.cmt_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">find_sublist_indices</span><span class="p">,</span> <span class="n">replace_token_ids</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">best_logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">register_logger</span><span class="p">,</span> <span class="n">print_listofdict</span><span class="p">,</span> <span class="n">print_dict</span><span class="p">,</span> <span class="n">print_nested</span><span class="p">,</span> <span class="n">NestedJsonItem</span><span class="p">,</span> <span class="n">SeqItem</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.exp_manager.exp_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExperienceWorker</span><span class="p">,</span> <span class="n">TrajExpConfig</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="k">class</span><span class="w"> </span><span class="nc">Linear_CMT</span><span class="p">(</span><span class="n">Trajectory</span><span class="p">,</span> <span class="n">ContextManagerBase</span><span class="p">):</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="sd">    A linear context manager template that handles the conversation flow between LLM and environment.</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a><span class="sd">    This class manages the context window, tokenization, and message history in a linear fashion.</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a><span class="sd">    Attributes:</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a><span class="sd">        config: Configuration object containing environment and model settings</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="sd">        tokenizer: Tokenizer instance for processing text</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a><span class="sd">        full_context (List[ExtendedMessage]): List of all messages in the conversation</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a><span class="sd">        current_context_status (str): Current status of the context</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a><span class="sd">        max_seq_length (int): Maximum sequence length for the context window</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a><span class="sd">        max_env_output_length (int): Maximum length for environment outputs</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a><span class="sd">        terminal_rewards_dict (dict): Dictionary storing terminal rewards</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a><span class="sd">        Initializes the Linear_CMT class with the provided configuration and tokenizer.</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a><span class="sd">        Args:</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a><span class="sd">            config: Configuration object containing environment and model settings.</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a><span class="sd">            tokenizer: Tokenizer instance for processing text.</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># ⭐ Initialize the list to store all messages in the conversation</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_context_status</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>        <span class="n">max_response_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">response_length</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>        <span class="n">max_model_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_model_len</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">max_model_len</span> <span class="o">-</span> <span class="n">max_response_length</span>  <span class="c1"># ⭐ Calculate the maximum sequence length for the context window</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_len</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">terminal_rewards_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discarded</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_terminated</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Reward</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">context_time_cost</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>        <span class="c1"># self.task_train_exp_mode: str = &quot;&quot;</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_batch_success_rate</span><span class="p">:</span><span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>        <span class="c1"># self.experiences = []</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>        <span class="c1"># log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.rollout.log_prob_max_token_len_per_gpu</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>        <span class="c1"># ref_log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.ref.log_prob_max_token_len_per_gpu</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a>        <span class="c1"># actor_ppo_max_token_len_per_gpu: int = self.config.actor_rollout_ref.actor.ppo_max_token_len_per_gpu</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a>        <span class="c1"># critic_ppo_max_token_len_per_gpu: int = self.config.critic.ppo_max_token_len_per_gpu</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>        <span class="c1"># assert log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>        <span class="c1"># assert critic_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>        <span class="c1"># assert actor_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>        <span class="c1"># assert ref_log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">&lt;=</span> <span class="n">max_model_len</span>  <span class="c1"># ⭐ Ensure the sum of prompt and response lengths does not exceed the maximum model length</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_previous_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">):</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a><span class="sd">        Prepare the input context for a future LLM call.</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a><span class="sd">        Args:</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a><span class="sd">            mod (str, optional): The mode to format the context. Defaults to &#39;future&#39;.</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="sd">                                 - &#39;future&#39;: Uses `content_for_future` for each message.</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a><span class="sd">                                 - &#39;raw&#39;: Uses `content` for each message.</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a><span class="sd">        Returns:</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a><span class="sd">            list: Array of message dictionaries containing role and content, formatted for LLM input.</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a><span class="sd">        Raises:</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a><span class="sd">            ValueError: If an unknown mode is provided.</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>        <span class="k">if</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;future&#39;</span><span class="p">:</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content_for_future</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>            <span class="p">]</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>        <span class="k">elif</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;raw&#39;</span><span class="p">:</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>            <span class="p">]</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown mod </span><span class="si">{</span><span class="n">mod</span><span class="si">}</span><span class="s2"> in prepare_previous_context, only support &#39;future&#39; and &#39;raw&#39;&quot;</span><span class="p">)</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">check_context_token_num_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a><span class="sd">        Checks if the total number of tokens in the prepared context messages is within a safe limit.</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a><span class="sd">        Args:</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a><span class="sd">            messages (List[dict]): A list of message dictionaries to be checked.</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a><span class="sd">        Returns:</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a><span class="sd">            bool: True if the total number of tokens is less than the maximum allowed sequence length, False otherwise.</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">):</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>            <span class="n">prompt_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the total number of tokens in the messages</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>        <span class="n">messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">)</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>        <span class="k">return</span> <span class="n">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span>   <span class="c1"># self.config.env_engine.max_seq_length = 20480</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_inc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_frag_from</span><span class="p">,</span> <span class="n">text_frag_to</span><span class="p">):</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a><span class="sd">        Get the incremental token array from text_frag_from to text_frag_to.</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a><span class="sd">        Args:</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a><span class="sd">            text_frag_from (str): The starting text fragment.</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a><span class="sd">            text_frag_to (str): The ending text fragment.</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a><span class="sd">        Returns:</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a><span class="sd">            Tuple[List[int], str]: A tuple containing the list of incremental token IDs and a message with token length details.</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_from</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>        <span class="n">tokenizer_input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="n">tokenizer_input_ids</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_to</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>        <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># ⭐ Get the new tokens added in this step</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a>        <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>            <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>        <span class="c1"># print(msg)</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>        <span class="k">return</span> <span class="n">input_id_increment</span><span class="p">,</span> <span class="n">msg</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a><span class="sd">        Removes the last message from the full context if it is not authored by the language model.</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a><span class="sd">        This method checks the author of the last message in the `full_context` list. If the author is not &quot;llm&quot;,</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a><span class="sd">        the last message is removed from the context. This is useful for managing the conversation history and</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a><span class="sd">        ensuring that only relevant messages are kept in the context.</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a><span class="sd">        Returns:</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a><span class="sd">            None</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># ⭐ Check if there are any messages in the context</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>  <span class="c1"># ⭐ Ensure the last message is not from the language model</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message from the context</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_non_llm_msg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_list</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]):</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a><span class="sd">        Removes the last message from the list if it is not authored by the language model (llm).</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a><span class="sd">        Args:</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a><span class="sd">            ext_msg_list (List[ExtendedMessage]): The list of ExtendedMessage objects representing the conversation history.</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a><span class="sd">        Returns:</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a><span class="sd">            List[ExtendedMessage]: The updated list of ExtendedMessage objects with the last non-llm message removed if applicable.</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>            <span class="k">if</span> <span class="n">ext_msg_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>                <span class="n">ext_msg_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message if it is not from the llm</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>        <span class="k">return</span> <span class="n">ext_msg_list</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>    <span class="nd">@property</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">steps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a><span class="sd">        Returns the prepared previous context with the mode set to &#39;future&#39;.</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a><span class="sd">        Returns:</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a><span class="sd">            dict: The prepared previous context.</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Get the prepared context in &#39;future&#39; mode</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a><span class="sd">        Converts the prepared previous context (with the mode set to &#39;future&#39;) into a JSON-formatted string.</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a><span class="sd">        Returns:</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a><span class="sd">            str: A JSON-formatted string of the prepared previous context.</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">),</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># ⭐ Convert the context to a JSON string</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_next_llm_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a><span class="sd">        Prepares the context for the next LLM (Language Model) interaction.</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a><span class="sd">        This function calls `prepare_previous_context` with the &#39;future&#39; mode to set up the context.</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a><span class="sd">        Returns:</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a><span class="sd">            The result of the `prepare_previous_context` function call.</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Prepares the context for the next LLM interaction</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_init_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_input_arr</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_nothink</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a><span class="sd">        Save and process the initial input messages to the context.</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a><span class="sd">        Args:</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a><span class="sd">            init_input_arr (list): Array of initial input messages to be processed</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a><span class="sd">                                  Each message should be a dict with &#39;role&#39; and &#39;content&#39;</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a><span class="sd">            add_nothink (bool, optional): If True, appends &quot;/no_think&quot; to the last message&#39;s content. Defaults to False.</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a><span class="sd">        Note:</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a><span class="sd">            - Initializes the context with the provided messages</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a><span class="sd">            - Computes token arrays for each message</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a><span class="sd">            - Validates that the context is empty before saving</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>        <span class="c1"># save basic</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;full_context should be empty when saving init input&quot;</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">llm_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">):</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>                <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>                    <span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">/no_think&quot;</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>            <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>                <span class="n">author</span><span class="o">=</span><span class="s2">&quot;initialization&quot;</span><span class="p">,</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>                <span class="n">role</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>                <span class="n">content</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>                <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;manual&quot;</span><span class="p">,</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>            <span class="p">)</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Adds the extended message to the full context</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>        <span class="c1"># compute token array for each message</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>        <span class="k">for</span> <span class="n">llm_msg</span><span class="p">,</span> <span class="n">ext_msg</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">))):</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>            <span class="n">text_with_chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">[:(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>            <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_with_chat_template</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>            <span class="c1"># attention_mask = outputs[&quot;attention_mask&quot;][0].tolist()</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>            <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># get the new tokens added in this step</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>            <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>                <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">input_id_increment</span>  <span class="c1"># ⭐ Sets the token array for the extended message</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>            <span class="n">token_ids_acc</span> <span class="o">+=</span> <span class="n">input_ids</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>        <span class="k">return</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">influence_extra_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">):</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a><span class="sd">        Evaluates the LLM output for repetition and applies a penalty reward.</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a><span class="sd">        The penalty is logged if non-zero, and the minimum penalty value is stored in the mistakes dictionary.</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a><span class="sd">        Args:</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a><span class="sd">            llm_output (dict): The output from the language model, expected to contain a &#39;content&#39; key.</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a><span class="sd">        Returns:</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a><span class="sd">            None</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>        <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">=</span> <span class="n">repetition_penalty_reward_scalar</span><span class="p">(</span><span class="n">completion</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the repetition penalty reward</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>        <span class="k">if</span> <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>            <span class="n">print_dict</span><span class="p">({</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>                <span class="s2">&quot;reason&quot;</span><span class="p">:</span> <span class="s2">&quot;repetition_penalty_reward&quot;</span><span class="p">,</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>            <span class="p">})</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>        <span class="k">if</span> <span class="s1">&#39;repetition_penalty_reward&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">:</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Update the mistakes dictionary with the minimum penalty</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a><span class="sd">        Save the output from the LLM to the full context.</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a><span class="sd">        Args:</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a><span class="sd">            llm_output (dict): The output from the LLM containing &#39;role&#39;, &#39;content&#39;, and &#39;tokens&#39;.</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a><span class="sd">            input_msg_ref: Reference to the input messages for token increment calculation.</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a><span class="sd">            auto_register_full_context (bool): Whether to register the output in the full context.</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a><span class="sd">        Returns:</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a><span class="sd">            ExtendedMessage: The processed and extended message object.</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a><span class="sd">        Note:</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a><span class="sd">            - Processes the LLM output and adds it to the conversation history.</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a><span class="sd">            - Handles token processing and generation prompt management.</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a><span class="sd">            - Ensures proper tokenization and context maintenance.</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>        <span class="c1"># save basic</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">llm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a>        <span class="n">token_generator</span> <span class="o">=</span> <span class="s2">&quot;manual&quot;</span> <span class="k">if</span> <span class="s1">&#39;tokens&#39;</span> <span class="ow">in</span> <span class="n">llm_output</span> <span class="k">else</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">,</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a>            <span class="n">role</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="n">token_generator</span><span class="p">,</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with LLM output details</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context if auto_register_full_context is True</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>        <span class="c1"># check mistakes</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">influence_extra_reward</span><span class="p">(</span><span class="n">llm_output</span><span class="p">)</span>  <span class="c1"># ⭐ Influence extra reward based on LLM output</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a>        <span class="c1"># generate token</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>            <span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a>            <span class="p">)</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a>            <span class="c1"># completion_token_arr will contain generation_prompt header</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a>            <span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">msg2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;&lt;|im_start|&gt;...&lt;|im_end|&gt;</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span> <span class="o">+</span> <span class="p">[</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>  <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]}</span> <span class="p">],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a>            <span class="p">)</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a>            <span class="n">vllm_output_raw_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_id</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]]</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vllm_output_raw_token</span><span class="p">)</span>  <span class="c1"># ⭐ Increment the generated token count</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>            <span class="n">final_token_arr</span> <span class="o">=</span> <span class="n">replace_token_ids</span><span class="p">(</span><span class="n">place_holder</span><span class="o">=</span><span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">replace_with</span><span class="o">=</span><span class="n">vllm_output_raw_token</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">])</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a>            <span class="k">return</span> <span class="n">final_token_arr</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>        <span class="k">if</span> <span class="n">token_generator</span> <span class="o">==</span> <span class="s2">&quot;manual&quot;</span><span class="p">:</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>            <span class="n">token_arr_method2</span> <span class="o">=</span> <span class="n">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span>  <span class="c1"># ⭐ Generate token increments using the VLLM response</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">token_arr_method2</span>  <span class="c1"># ⭐ Assign the generated token array to the ExtendedMessage</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>        <span class="k">return</span> <span class="n">ext_msg</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output_do_not_register_full_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">):</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a><span class="sd">        Saves the LLM output to the context without registering the full context.</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a><span class="sd">        Args:</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a><span class="sd">            llm_output: The output from the language model.</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a><span class="sd">            input_msg_ref: Reference to the input message.</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a><span class="sd">        Returns:</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a><span class="sd">            The result of saving the LLM output with the specified options.</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>        <span class="k">return</span> <span class="n">Linear_CMT</span><span class="o">.</span><span class="n">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># ⭐ Save LLM output without full context registration</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_env_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_output</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_nothink</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a><span class="sd">        Save and process environment output to the context.</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a><span class="sd">        Args:</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a><span class="sd">            env_output (dict): Environment output containing &#39;content&#39;</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a><span class="sd">            input_msg_ref (List[dict], optional): Reference messages for token calculation</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a><span class="sd">            add_nothink (bool, optional): Whether to append &#39;/no_think&#39; to the content</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a><span class="sd">        Note:</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a><span class="sd">            - Clips environment output if it exceeds max_env_output_length</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a><span class="sd">            - Processes the output as a user message in the conversation</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a><span class="sd">            - Computes and stores token arrays for the environment response</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a>        <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;error&#39;</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">):</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[Error from environment: </span><span class="si">{</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">]&quot;</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]):</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;[No content provided by the environment]&#39;</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a>        <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot; /no_think&quot;</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;env&quot;</span><span class="p">,</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a>            <span class="n">clip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a>            <span class="n">clip_token_limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">,</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with the environment content</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>        <span class="k">return</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_role_content</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a><span class="sd">        Converts a list of ExtendedMessage objects into a list of dictionaries with &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a><span class="sd">        Args:</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a><span class="sd">            ext_msg_array (List[ExtendedMessage]): A list of ExtendedMessage objects.</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a><span class="sd">        Returns:</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a><span class="sd">            List[dict]: A list of dictionaries, each containing &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a>        <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span> <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_msg_array</span><span class="p">]</span>  <span class="c1"># ⭐ Convert each ExtendedMessage to a dictionary</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_world_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a><span class="sd">        Process the latest model content before environment interaction.</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a><span class="sd">        Returns:</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a><span class="sd">            str: Processed content, with code extracted from markdown code blocks if present</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a><span class="sd">                 or the raw content if no code blocks are found</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a><span class="sd">        Note:</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a><span class="sd">            - Extracts Python code from markdown code blocks (```python```)</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a><span class="sd">            - Returns the raw content if no valid code blocks are found</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a>        <span class="n">latest_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>        <span class="k">return</span> <span class="n">latest_content</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">author</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a><span class="sd">        Filters the full context to include only messages from a specific author and returns a deep copy of the filtered list.</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a><span class="sd">        Args:</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a><span class="sd">            author (str): The name of the author whose messages are to be included in the result.</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a><span class="sd">        Returns:</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a><span class="sd">            List[ExtendedMessage]: A deep copy of the list containing only the messages from the specified author.</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="n">author</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and create a deep copy of the context</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_authors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">authors</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a><span class="sd">        Filters the full context of messages, returning only those authored by the specified authors.</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a><span class="sd">        Args:</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a><span class="sd">            authors (str): A string of author names, separated by commas, indicating which authors&#39; messages to include.</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a><span class="sd">        Returns:</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a><span class="sd">            List[ExtendedMessage]: A list of ExtendedMessage objects from the full context that match the specified authors.</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="ow">in</span> <span class="n">authors</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and deep copy the relevant messages</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a><span class="sd">        Tokenizes the full context into a format suitable for input to a language model, creating a sample with necessary attributes like input IDs, attention masks, and position IDs.</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a><span class="sd">        Returns:</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a><span class="sd">            List[Sample]: An array containing a single Sample object, representing the tokenized context.</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>        <span class="c1"># assert self.latest_llm_interaction_socket is None, &quot;unprocessed message buffer! forget to call `save_llm_output` after `prepare_next_llm_context`?&quot;</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a>        <span class="n">sample_arr</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a>        <span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>            <span class="n">data_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_id</span><span class="p">,</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a>            <span class="n">rollout_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_id</span><span class="p">,</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>            <span class="n">task_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>            <span class="n">minor_index_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a>            <span class="n">messages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">to_role_content</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">),</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>            <span class="n">input_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a>            <span class="n">prompt_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">],</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a>            <span class="n">response_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">],</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a>            <span class="n">prompt_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">],</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>            <span class="n">response_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">],</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>            <span class="n">loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">],</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>            <span class="n">prompt_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">],</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>            <span class="n">response_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">],</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>            <span class="n">position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>            <span class="n">prompt_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">],</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>            <span class="n">response_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">],</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>            <span class="n">reward_scores</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">model_dump</span><span class="p">(),</span> <span class="c1"># reward is duplicated in each sample</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>            <span class="n">max_prompt_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>            <span class="n">max_response_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span><span class="p">,</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>            <span class="n">max_model_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>        <span class="p">)</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>        <span class="n">sample</span><span class="o">.</span><span class="n">truncate_output_ids</span><span class="p">()</span>  <span class="c1"># ⭐ Ensure the output IDs are within the allowed length</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>        <span class="n">sample_arr</span> <span class="o">+=</span> <span class="p">[</span><span class="n">sample</span><span class="p">]</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>        <span class="k">return</span> <span class="n">sample_arr</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_render_token_log</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>        <span class="p">}</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">generate_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_id</span><span class="p">):</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a><span class="sd">        Generates and prints a log for the specified task, including detailed information about the tokenized steps,</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a><span class="sd">        input IDs, loss mask colors, and rewards. The log is formatted into a nested JSON structure and printed.</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a><span class="sd">        Args:</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a><span class="sd">            task_id (str): The ID of the task for which the log is being generated.</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a><span class="sd">        Returns:</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a><span class="sd">            None</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a>        <span class="n">nested_items_print_buffer</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>  <span class="c1"># ⭐ Retrieve the full context for the task</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>  <span class="c1"># ⭐ Tokenize the extended steps</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Decode the tokenized input IDs to text</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Convert input IDs to strings</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Generate color array based on loss mask</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>        <span class="n">buffer</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>        <span class="p">}</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>        <span class="n">len_prompt_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of prompt IDs</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>        <span class="n">len_response_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of response IDs</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>        <span class="n">len_input_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of input IDs</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the reward outcome</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a>        <span class="n">task_outcome</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">success_rate</span><span class="p">)</span>  <span class="c1"># ⭐ Get the task success rate as a string</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>        <span class="n">final_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">)</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the final reward after applying the reward patch</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>        <span class="n">selectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_id</span><span class="p">,</span> <span class="n">task_outcome</span><span class="p">]</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>        <span class="n">nested_items_print_buffer</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">selectors</span><span class="p">)]</span> <span class="o">=</span> <span class="n">NestedJsonItem</span><span class="p">(</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>            <span class="n">item_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;item&quot;</span><span class="p">,</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>            <span class="n">outcome</span><span class="o">=</span><span class="n">task_outcome</span><span class="p">,</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>            <span class="n">len_prompt_ids</span><span class="o">=</span><span class="n">len_prompt_ids</span><span class="p">,</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>            <span class="n">len_response_ids</span><span class="o">=</span><span class="n">len_response_ids</span><span class="p">,</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>            <span class="n">len_input_ids</span><span class="o">=</span><span class="n">len_input_ids</span><span class="p">,</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>            <span class="n">reward</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>            <span class="n">final_reward</span><span class="o">=</span><span class="n">final_reward</span><span class="p">,</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">SeqItem</span><span class="p">(</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>                <span class="n">text</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span>  <span class="c1"># text</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>                <span class="n">title</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span> <span class="c1"># mouse hover</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>                <span class="n">count</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;input_id_arr&#39;</span><span class="p">],</span> <span class="c1"># highlight text</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>                <span class="n">color</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;loss_mask_color_arr&#39;</span><span class="p">]</span>   <span class="c1"># color</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>            <span class="p">)</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>        <span class="p">)</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>        <span class="n">print_nested</span><span class="p">(</span><span class="n">nested_items_print_buffer</span><span class="p">,</span>  <span class="c1"># ⭐ Print the nested JSON buffer</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a>            <span class="n">main_content</span><span class="o">=</span><span class="s2">&quot;This is the main content of the nested JSON&quot;</span><span class="p">,</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;rollout&quot;</span><span class="p">,</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a>            <span class="n">attach</span><span class="o">=</span><span class="s2">&quot;Copy Sample Message&quot;</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a>        <span class="p">)</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a>        <span class="n">print_listofdict</span><span class="p">(</span>  <span class="c1"># ⭐ Print the list of dictionaries</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;conversation&quot;</span><span class="p">,</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a>        <span class="p">)</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a><span class="sd">        Creates a deep copy of the provided reward and may modify it based on internal state.</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a><span class="sd">        Args:</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a><span class="sd">            reward (object): The reward object to be patched, which must have an &#39;outcome&#39; attribute.</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a><span class="sd">        Returns:</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a><span class="sd">            object: The possibly modified deep copy of the original reward.</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a>        <span class="n">_reward</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>  <span class="c1"># ⭐ Create a deep copy of the reward to avoid modifying the original</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>        <span class="c1"># if self.compute_madness() &lt; 0: _reward.outcome = -1.0</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>        <span class="k">return</span> <span class="n">_reward</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_madness</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a><span class="sd">        Evaluates the &#39;madness&#39; of the model&#39;s output based on the proportion of certain types of mistakes (e.g., special tokens, repeated characters, non-ASCII characters).</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a><span class="sd">        Returns:</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a><span class="sd">            float: -1.0 if any mistake proportion is below the threshold, otherwise 0.0.</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>        <span class="n">threshold</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.01</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>            <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span> <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span>  <span class="c1"># ⭐ Check if any mistake proportion is below the threshold</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>        <span class="k">return</span> <span class="mf">0.0</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_steps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">],</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a><span class="sd">        Tokenizes the given extended messages, processes them to separate prompts and responses, and prepares the data for model training.</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a><span class="sd">        It also handles the extraction and discarding of experience information if needed.</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a><span class="sd">        Args:</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a><span class="sd">            ext_steps (List[ExtendedMessage]): A list of ExtendedMessage objects representing the conversation context.</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a><span class="sd">            debug (bool, optional): A flag to enable debugging. Defaults to False.</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a><span class="sd">        Returns:</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a><span class="sd">            dict: A dictionary containing tokenized and processed data for model training.</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_position_id_with_mask</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a>        <span class="n">ext_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_last_non_llm_msg</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">))</span>  <span class="c1"># ⭐ Remove the last non-LLM message</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>        <span class="n">exp_worker</span> <span class="o">=</span> <span class="n">ExperienceWorker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">):</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a>            <span class="n">experience</span><span class="p">,</span> <span class="n">new_content</span> <span class="o">=</span> <span class="n">exp_worker</span><span class="o">.</span><span class="n">manage_training_context</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a>            <span class="k">if</span> <span class="n">experience</span><span class="p">:</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a>                <span class="n">ext_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a>                    <span class="n">author</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span><span class="p">,</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a>                    <span class="n">role</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a>                    <span class="n">content</span><span class="o">=</span><span class="n">new_content</span><span class="p">,</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a>                    <span class="n">token_generator</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a>                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a>                    <span class="n">uuid</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">uuid</span><span class="p">,</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a>                <span class="p">)</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a>        <span class="c1"># mapping</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a>        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a>        <span class="n">loss_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a>        <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a>        <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_steps</span><span class="p">:</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a>            <span class="c1"># find split index, this have to be done before input_ids += ext_msg.token_arr</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">split_prompt_reponse_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">need_training</span><span class="p">):</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a>                <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a>                <span class="k">assert</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="s1">&#39;llm&#39;</span><span class="p">,</span> <span class="s2">&quot;The first message after initialization should be from LLM, not from env or user&quot;</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a>            <span class="n">input_ids</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a>            <span class="n">attention_mask</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span><span class="p">)</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>            <span class="n">loss_mask</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">get_loss_mask</span><span class="p">(</span><span class="n">blackout_token_combo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span><span class="p">)</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>        <span class="k">assert</span> <span class="n">split_prompt_reponse_index</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;split_prompt_reponse_index should not be -1, at least one message should be in the context&quot;</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">compute_position_id_with_mask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ⭐ Compute position IDs with mask</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>        <span class="c1"># separate prompt and response</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>        <span class="n">prompt_ids</span> <span class="o">=</span>            <span class="n">input_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>        <span class="n">prompt_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>        <span class="n">prompt_position_ids</span> <span class="o">=</span>   <span class="n">position_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>        <span class="n">prompt_loss_mask</span> <span class="o">=</span>      <span class="n">loss_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a>        <span class="n">response_ids</span> <span class="o">=</span>              <span class="n">input_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a>        <span class="n">response_attention_mask</span> <span class="o">=</span>   <span class="n">attention_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a>        <span class="n">response_position_ids</span> <span class="o">=</span>     <span class="n">position_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a>        <span class="n">response_loss_mask</span> <span class="o">=</span>        <span class="n">loss_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_ids</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_ids</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_attention_mask</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_attention_mask</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_mask</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_loss_mask</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_loss_mask</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">position_ids</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_position_ids</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_position_ids</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a>        <span class="k">return</span> <span class="n">cmt_tokenized</span>
</span></pre></div>


            </section>
                <section id="Linear_CMT">
                            <input id="Linear_CMT-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">Linear_CMT</span><wbr>(<span class="base"><a href="../../schema/trajectory.html#Trajectory">agentevolver.schema.trajectory.Trajectory</a></span>, <span class="base"><a href="cmt_base.html#ContextManagerBase">agentevolver.module.context_manager.cmt_base.ContextManagerBase</a></span>):

                <label class="view-source-button" for="Linear_CMT-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT-19"><a href="#Linear_CMT-19"><span class="linenos"> 19</span></a><span class="k">class</span><span class="w"> </span><span class="nc">Linear_CMT</span><span class="p">(</span><span class="n">Trajectory</span><span class="p">,</span> <span class="n">ContextManagerBase</span><span class="p">):</span>
</span><span id="Linear_CMT-20"><a href="#Linear_CMT-20"><span class="linenos"> 20</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-21"><a href="#Linear_CMT-21"><span class="linenos"> 21</span></a><span class="sd">    A linear context manager template that handles the conversation flow between LLM and environment.</span>
</span><span id="Linear_CMT-22"><a href="#Linear_CMT-22"><span class="linenos"> 22</span></a><span class="sd">    This class manages the context window, tokenization, and message history in a linear fashion.</span>
</span><span id="Linear_CMT-23"><a href="#Linear_CMT-23"><span class="linenos"> 23</span></a>
</span><span id="Linear_CMT-24"><a href="#Linear_CMT-24"><span class="linenos"> 24</span></a><span class="sd">    Attributes:</span>
</span><span id="Linear_CMT-25"><a href="#Linear_CMT-25"><span class="linenos"> 25</span></a><span class="sd">        config: Configuration object containing environment and model settings</span>
</span><span id="Linear_CMT-26"><a href="#Linear_CMT-26"><span class="linenos"> 26</span></a><span class="sd">        tokenizer: Tokenizer instance for processing text</span>
</span><span id="Linear_CMT-27"><a href="#Linear_CMT-27"><span class="linenos"> 27</span></a><span class="sd">        full_context (List[ExtendedMessage]): List of all messages in the conversation</span>
</span><span id="Linear_CMT-28"><a href="#Linear_CMT-28"><span class="linenos"> 28</span></a><span class="sd">        current_context_status (str): Current status of the context</span>
</span><span id="Linear_CMT-29"><a href="#Linear_CMT-29"><span class="linenos"> 29</span></a><span class="sd">        max_seq_length (int): Maximum sequence length for the context window</span>
</span><span id="Linear_CMT-30"><a href="#Linear_CMT-30"><span class="linenos"> 30</span></a><span class="sd">        max_env_output_length (int): Maximum length for environment outputs</span>
</span><span id="Linear_CMT-31"><a href="#Linear_CMT-31"><span class="linenos"> 31</span></a><span class="sd">        terminal_rewards_dict (dict): Dictionary storing terminal rewards</span>
</span><span id="Linear_CMT-32"><a href="#Linear_CMT-32"><span class="linenos"> 32</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-33"><a href="#Linear_CMT-33"><span class="linenos"> 33</span></a>
</span><span id="Linear_CMT-34"><a href="#Linear_CMT-34"><span class="linenos"> 34</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
</span><span id="Linear_CMT-35"><a href="#Linear_CMT-35"><span class="linenos"> 35</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-36"><a href="#Linear_CMT-36"><span class="linenos"> 36</span></a><span class="sd">        Initializes the Linear_CMT class with the provided configuration and tokenizer.</span>
</span><span id="Linear_CMT-37"><a href="#Linear_CMT-37"><span class="linenos"> 37</span></a>
</span><span id="Linear_CMT-38"><a href="#Linear_CMT-38"><span class="linenos"> 38</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-39"><a href="#Linear_CMT-39"><span class="linenos"> 39</span></a><span class="sd">            config: Configuration object containing environment and model settings.</span>
</span><span id="Linear_CMT-40"><a href="#Linear_CMT-40"><span class="linenos"> 40</span></a><span class="sd">            tokenizer: Tokenizer instance for processing text.</span>
</span><span id="Linear_CMT-41"><a href="#Linear_CMT-41"><span class="linenos"> 41</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-42"><a href="#Linear_CMT-42"><span class="linenos"> 42</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="Linear_CMT-43"><a href="#Linear_CMT-43"><span class="linenos"> 43</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="Linear_CMT-44"><a href="#Linear_CMT-44"><span class="linenos"> 44</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="Linear_CMT-45"><a href="#Linear_CMT-45"><span class="linenos"> 45</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># ⭐ Initialize the list to store all messages in the conversation</span>
</span><span id="Linear_CMT-46"><a href="#Linear_CMT-46"><span class="linenos"> 46</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_context_status</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT-47"><a href="#Linear_CMT-47"><span class="linenos"> 47</span></a>        <span class="n">max_response_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">response_length</span>
</span><span id="Linear_CMT-48"><a href="#Linear_CMT-48"><span class="linenos"> 48</span></a>        <span class="n">max_model_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_model_len</span>
</span><span id="Linear_CMT-49"><a href="#Linear_CMT-49"><span class="linenos"> 49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">max_model_len</span> <span class="o">-</span> <span class="n">max_response_length</span>  <span class="c1"># ⭐ Calculate the maximum sequence length for the context window</span>
</span><span id="Linear_CMT-50"><a href="#Linear_CMT-50"><span class="linenos"> 50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_len</span>
</span><span id="Linear_CMT-51"><a href="#Linear_CMT-51"><span class="linenos"> 51</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Linear_CMT-52"><a href="#Linear_CMT-52"><span class="linenos"> 52</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT-53"><a href="#Linear_CMT-53"><span class="linenos"> 53</span></a>
</span><span id="Linear_CMT-54"><a href="#Linear_CMT-54"><span class="linenos"> 54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">terminal_rewards_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT-55"><a href="#Linear_CMT-55"><span class="linenos"> 55</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discarded</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="Linear_CMT-56"><a href="#Linear_CMT-56"><span class="linenos"> 56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_terminated</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="Linear_CMT-57"><a href="#Linear_CMT-57"><span class="linenos"> 57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Reward</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="Linear_CMT-58"><a href="#Linear_CMT-58"><span class="linenos"> 58</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">context_time_cost</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT-59"><a href="#Linear_CMT-59"><span class="linenos"> 59</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT-60"><a href="#Linear_CMT-60"><span class="linenos"> 60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT-61"><a href="#Linear_CMT-61"><span class="linenos"> 61</span></a>        <span class="c1"># self.task_train_exp_mode: str = &quot;&quot;</span>
</span><span id="Linear_CMT-62"><a href="#Linear_CMT-62"><span class="linenos"> 62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_batch_success_rate</span><span class="p">:</span><span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="Linear_CMT-63"><a href="#Linear_CMT-63"><span class="linenos"> 63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT-64"><a href="#Linear_CMT-64"><span class="linenos"> 64</span></a>        <span class="c1"># self.experiences = []</span>
</span><span id="Linear_CMT-65"><a href="#Linear_CMT-65"><span class="linenos"> 65</span></a>
</span><span id="Linear_CMT-66"><a href="#Linear_CMT-66"><span class="linenos"> 66</span></a>        <span class="c1"># log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.rollout.log_prob_max_token_len_per_gpu</span>
</span><span id="Linear_CMT-67"><a href="#Linear_CMT-67"><span class="linenos"> 67</span></a>        <span class="c1"># ref_log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.ref.log_prob_max_token_len_per_gpu</span>
</span><span id="Linear_CMT-68"><a href="#Linear_CMT-68"><span class="linenos"> 68</span></a>        <span class="c1"># actor_ppo_max_token_len_per_gpu: int = self.config.actor_rollout_ref.actor.ppo_max_token_len_per_gpu</span>
</span><span id="Linear_CMT-69"><a href="#Linear_CMT-69"><span class="linenos"> 69</span></a>        <span class="c1"># critic_ppo_max_token_len_per_gpu: int = self.config.critic.ppo_max_token_len_per_gpu</span>
</span><span id="Linear_CMT-70"><a href="#Linear_CMT-70"><span class="linenos"> 70</span></a>        <span class="c1"># assert log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT-71"><a href="#Linear_CMT-71"><span class="linenos"> 71</span></a>        <span class="c1"># assert critic_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT-72"><a href="#Linear_CMT-72"><span class="linenos"> 72</span></a>        <span class="c1"># assert actor_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT-73"><a href="#Linear_CMT-73"><span class="linenos"> 73</span></a>        <span class="c1"># assert ref_log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT-74"><a href="#Linear_CMT-74"><span class="linenos"> 74</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">&lt;=</span> <span class="n">max_model_len</span>  <span class="c1"># ⭐ Ensure the sum of prompt and response lengths does not exceed the maximum model length</span>
</span><span id="Linear_CMT-75"><a href="#Linear_CMT-75"><span class="linenos"> 75</span></a>
</span><span id="Linear_CMT-76"><a href="#Linear_CMT-76"><span class="linenos"> 76</span></a>
</span><span id="Linear_CMT-77"><a href="#Linear_CMT-77"><span class="linenos"> 77</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_previous_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">):</span>
</span><span id="Linear_CMT-78"><a href="#Linear_CMT-78"><span class="linenos"> 78</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-79"><a href="#Linear_CMT-79"><span class="linenos"> 79</span></a><span class="sd">        Prepare the input context for a future LLM call.</span>
</span><span id="Linear_CMT-80"><a href="#Linear_CMT-80"><span class="linenos"> 80</span></a>
</span><span id="Linear_CMT-81"><a href="#Linear_CMT-81"><span class="linenos"> 81</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-82"><a href="#Linear_CMT-82"><span class="linenos"> 82</span></a><span class="sd">            mod (str, optional): The mode to format the context. Defaults to &#39;future&#39;.</span>
</span><span id="Linear_CMT-83"><a href="#Linear_CMT-83"><span class="linenos"> 83</span></a><span class="sd">                                 - &#39;future&#39;: Uses `content_for_future` for each message.</span>
</span><span id="Linear_CMT-84"><a href="#Linear_CMT-84"><span class="linenos"> 84</span></a><span class="sd">                                 - &#39;raw&#39;: Uses `content` for each message.</span>
</span><span id="Linear_CMT-85"><a href="#Linear_CMT-85"><span class="linenos"> 85</span></a>
</span><span id="Linear_CMT-86"><a href="#Linear_CMT-86"><span class="linenos"> 86</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-87"><a href="#Linear_CMT-87"><span class="linenos"> 87</span></a><span class="sd">            list: Array of message dictionaries containing role and content, formatted for LLM input.</span>
</span><span id="Linear_CMT-88"><a href="#Linear_CMT-88"><span class="linenos"> 88</span></a>
</span><span id="Linear_CMT-89"><a href="#Linear_CMT-89"><span class="linenos"> 89</span></a><span class="sd">        Raises:</span>
</span><span id="Linear_CMT-90"><a href="#Linear_CMT-90"><span class="linenos"> 90</span></a><span class="sd">            ValueError: If an unknown mode is provided.</span>
</span><span id="Linear_CMT-91"><a href="#Linear_CMT-91"><span class="linenos"> 91</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-92"><a href="#Linear_CMT-92"><span class="linenos"> 92</span></a>        <span class="k">if</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;future&#39;</span><span class="p">:</span>
</span><span id="Linear_CMT-93"><a href="#Linear_CMT-93"><span class="linenos"> 93</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="Linear_CMT-94"><a href="#Linear_CMT-94"><span class="linenos"> 94</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content_for_future</span>
</span><span id="Linear_CMT-95"><a href="#Linear_CMT-95"><span class="linenos"> 95</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT-96"><a href="#Linear_CMT-96"><span class="linenos"> 96</span></a>            <span class="p">]</span>
</span><span id="Linear_CMT-97"><a href="#Linear_CMT-97"><span class="linenos"> 97</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="Linear_CMT-98"><a href="#Linear_CMT-98"><span class="linenos"> 98</span></a>
</span><span id="Linear_CMT-99"><a href="#Linear_CMT-99"><span class="linenos"> 99</span></a>        <span class="k">elif</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;raw&#39;</span><span class="p">:</span>
</span><span id="Linear_CMT-100"><a href="#Linear_CMT-100"><span class="linenos">100</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="Linear_CMT-101"><a href="#Linear_CMT-101"><span class="linenos">101</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content</span>
</span><span id="Linear_CMT-102"><a href="#Linear_CMT-102"><span class="linenos">102</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT-103"><a href="#Linear_CMT-103"><span class="linenos">103</span></a>            <span class="p">]</span>
</span><span id="Linear_CMT-104"><a href="#Linear_CMT-104"><span class="linenos">104</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="Linear_CMT-105"><a href="#Linear_CMT-105"><span class="linenos">105</span></a>
</span><span id="Linear_CMT-106"><a href="#Linear_CMT-106"><span class="linenos">106</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="Linear_CMT-107"><a href="#Linear_CMT-107"><span class="linenos">107</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown mod </span><span class="si">{</span><span class="n">mod</span><span class="si">}</span><span class="s2"> in prepare_previous_context, only support &#39;future&#39; and &#39;raw&#39;&quot;</span><span class="p">)</span>
</span><span id="Linear_CMT-108"><a href="#Linear_CMT-108"><span class="linenos">108</span></a>
</span><span id="Linear_CMT-109"><a href="#Linear_CMT-109"><span class="linenos">109</span></a>
</span><span id="Linear_CMT-110"><a href="#Linear_CMT-110"><span class="linenos">110</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">check_context_token_num_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
</span><span id="Linear_CMT-111"><a href="#Linear_CMT-111"><span class="linenos">111</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-112"><a href="#Linear_CMT-112"><span class="linenos">112</span></a><span class="sd">        Checks if the total number of tokens in the prepared context messages is within a safe limit.</span>
</span><span id="Linear_CMT-113"><a href="#Linear_CMT-113"><span class="linenos">113</span></a>
</span><span id="Linear_CMT-114"><a href="#Linear_CMT-114"><span class="linenos">114</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-115"><a href="#Linear_CMT-115"><span class="linenos">115</span></a><span class="sd">            messages (List[dict]): A list of message dictionaries to be checked.</span>
</span><span id="Linear_CMT-116"><a href="#Linear_CMT-116"><span class="linenos">116</span></a>
</span><span id="Linear_CMT-117"><a href="#Linear_CMT-117"><span class="linenos">117</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-118"><a href="#Linear_CMT-118"><span class="linenos">118</span></a><span class="sd">            bool: True if the total number of tokens is less than the maximum allowed sequence length, False otherwise.</span>
</span><span id="Linear_CMT-119"><a href="#Linear_CMT-119"><span class="linenos">119</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-120"><a href="#Linear_CMT-120"><span class="linenos">120</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">):</span>
</span><span id="Linear_CMT-121"><a href="#Linear_CMT-121"><span class="linenos">121</span></a>            <span class="n">prompt_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="Linear_CMT-122"><a href="#Linear_CMT-122"><span class="linenos">122</span></a>            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the total number of tokens in the messages</span>
</span><span id="Linear_CMT-123"><a href="#Linear_CMT-123"><span class="linenos">123</span></a>        <span class="n">messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">)</span>
</span><span id="Linear_CMT-124"><a href="#Linear_CMT-124"><span class="linenos">124</span></a>        <span class="k">return</span> <span class="n">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span>   <span class="c1"># self.config.env_engine.max_seq_length = 20480</span>
</span><span id="Linear_CMT-125"><a href="#Linear_CMT-125"><span class="linenos">125</span></a>
</span><span id="Linear_CMT-126"><a href="#Linear_CMT-126"><span class="linenos">126</span></a>
</span><span id="Linear_CMT-127"><a href="#Linear_CMT-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_inc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_frag_from</span><span class="p">,</span> <span class="n">text_frag_to</span><span class="p">):</span>
</span><span id="Linear_CMT-128"><a href="#Linear_CMT-128"><span class="linenos">128</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-129"><a href="#Linear_CMT-129"><span class="linenos">129</span></a><span class="sd">        Get the incremental token array from text_frag_from to text_frag_to.</span>
</span><span id="Linear_CMT-130"><a href="#Linear_CMT-130"><span class="linenos">130</span></a>
</span><span id="Linear_CMT-131"><a href="#Linear_CMT-131"><span class="linenos">131</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-132"><a href="#Linear_CMT-132"><span class="linenos">132</span></a><span class="sd">            text_frag_from (str): The starting text fragment.</span>
</span><span id="Linear_CMT-133"><a href="#Linear_CMT-133"><span class="linenos">133</span></a><span class="sd">            text_frag_to (str): The ending text fragment.</span>
</span><span id="Linear_CMT-134"><a href="#Linear_CMT-134"><span class="linenos">134</span></a>
</span><span id="Linear_CMT-135"><a href="#Linear_CMT-135"><span class="linenos">135</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-136"><a href="#Linear_CMT-136"><span class="linenos">136</span></a><span class="sd">            Tuple[List[int], str]: A tuple containing the list of incremental token IDs and a message with token length details.</span>
</span><span id="Linear_CMT-137"><a href="#Linear_CMT-137"><span class="linenos">137</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-138"><a href="#Linear_CMT-138"><span class="linenos">138</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_from</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT-139"><a href="#Linear_CMT-139"><span class="linenos">139</span></a>        <span class="n">tokenizer_input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT-140"><a href="#Linear_CMT-140"><span class="linenos">140</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="n">tokenizer_input_ids</span>
</span><span id="Linear_CMT-141"><a href="#Linear_CMT-141"><span class="linenos">141</span></a>
</span><span id="Linear_CMT-142"><a href="#Linear_CMT-142"><span class="linenos">142</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_to</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT-143"><a href="#Linear_CMT-143"><span class="linenos">143</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT-144"><a href="#Linear_CMT-144"><span class="linenos">144</span></a>        <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># ⭐ Get the new tokens added in this step</span>
</span><span id="Linear_CMT-145"><a href="#Linear_CMT-145"><span class="linenos">145</span></a>        <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT-146"><a href="#Linear_CMT-146"><span class="linenos">146</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="Linear_CMT-147"><a href="#Linear_CMT-147"><span class="linenos">147</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Linear_CMT-148"><a href="#Linear_CMT-148"><span class="linenos">148</span></a>            <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="Linear_CMT-149"><a href="#Linear_CMT-149"><span class="linenos">149</span></a>        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="Linear_CMT-150"><a href="#Linear_CMT-150"><span class="linenos">150</span></a>        <span class="c1"># print(msg)</span>
</span><span id="Linear_CMT-151"><a href="#Linear_CMT-151"><span class="linenos">151</span></a>        <span class="k">return</span> <span class="n">input_id_increment</span><span class="p">,</span> <span class="n">msg</span>
</span><span id="Linear_CMT-152"><a href="#Linear_CMT-152"><span class="linenos">152</span></a>
</span><span id="Linear_CMT-153"><a href="#Linear_CMT-153"><span class="linenos">153</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-154"><a href="#Linear_CMT-154"><span class="linenos">154</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-155"><a href="#Linear_CMT-155"><span class="linenos">155</span></a><span class="sd">        Removes the last message from the full context if it is not authored by the language model.</span>
</span><span id="Linear_CMT-156"><a href="#Linear_CMT-156"><span class="linenos">156</span></a>
</span><span id="Linear_CMT-157"><a href="#Linear_CMT-157"><span class="linenos">157</span></a><span class="sd">        This method checks the author of the last message in the `full_context` list. If the author is not &quot;llm&quot;,</span>
</span><span id="Linear_CMT-158"><a href="#Linear_CMT-158"><span class="linenos">158</span></a><span class="sd">        the last message is removed from the context. This is useful for managing the conversation history and</span>
</span><span id="Linear_CMT-159"><a href="#Linear_CMT-159"><span class="linenos">159</span></a><span class="sd">        ensuring that only relevant messages are kept in the context.</span>
</span><span id="Linear_CMT-160"><a href="#Linear_CMT-160"><span class="linenos">160</span></a>
</span><span id="Linear_CMT-161"><a href="#Linear_CMT-161"><span class="linenos">161</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-162"><a href="#Linear_CMT-162"><span class="linenos">162</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT-163"><a href="#Linear_CMT-163"><span class="linenos">163</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-164"><a href="#Linear_CMT-164"><span class="linenos">164</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># ⭐ Check if there are any messages in the context</span>
</span><span id="Linear_CMT-165"><a href="#Linear_CMT-165"><span class="linenos">165</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>  <span class="c1"># ⭐ Ensure the last message is not from the language model</span>
</span><span id="Linear_CMT-166"><a href="#Linear_CMT-166"><span class="linenos">166</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message from the context</span>
</span><span id="Linear_CMT-167"><a href="#Linear_CMT-167"><span class="linenos">167</span></a>
</span><span id="Linear_CMT-168"><a href="#Linear_CMT-168"><span class="linenos">168</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_non_llm_msg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_list</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]):</span>
</span><span id="Linear_CMT-169"><a href="#Linear_CMT-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-170"><a href="#Linear_CMT-170"><span class="linenos">170</span></a><span class="sd">        Removes the last message from the list if it is not authored by the language model (llm).</span>
</span><span id="Linear_CMT-171"><a href="#Linear_CMT-171"><span class="linenos">171</span></a>
</span><span id="Linear_CMT-172"><a href="#Linear_CMT-172"><span class="linenos">172</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-173"><a href="#Linear_CMT-173"><span class="linenos">173</span></a><span class="sd">            ext_msg_list (List[ExtendedMessage]): The list of ExtendedMessage objects representing the conversation history.</span>
</span><span id="Linear_CMT-174"><a href="#Linear_CMT-174"><span class="linenos">174</span></a>
</span><span id="Linear_CMT-175"><a href="#Linear_CMT-175"><span class="linenos">175</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-176"><a href="#Linear_CMT-176"><span class="linenos">176</span></a><span class="sd">            List[ExtendedMessage]: The updated list of ExtendedMessage objects with the last non-llm message removed if applicable.</span>
</span><span id="Linear_CMT-177"><a href="#Linear_CMT-177"><span class="linenos">177</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-178"><a href="#Linear_CMT-178"><span class="linenos">178</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="Linear_CMT-179"><a href="#Linear_CMT-179"><span class="linenos">179</span></a>            <span class="k">if</span> <span class="n">ext_msg_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>
</span><span id="Linear_CMT-180"><a href="#Linear_CMT-180"><span class="linenos">180</span></a>                <span class="n">ext_msg_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message if it is not from the llm</span>
</span><span id="Linear_CMT-181"><a href="#Linear_CMT-181"><span class="linenos">181</span></a>        <span class="k">return</span> <span class="n">ext_msg_list</span>
</span><span id="Linear_CMT-182"><a href="#Linear_CMT-182"><span class="linenos">182</span></a>
</span><span id="Linear_CMT-183"><a href="#Linear_CMT-183"><span class="linenos">183</span></a>
</span><span id="Linear_CMT-184"><a href="#Linear_CMT-184"><span class="linenos">184</span></a>
</span><span id="Linear_CMT-185"><a href="#Linear_CMT-185"><span class="linenos">185</span></a>    <span class="nd">@property</span>
</span><span id="Linear_CMT-186"><a href="#Linear_CMT-186"><span class="linenos">186</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">steps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-187"><a href="#Linear_CMT-187"><span class="linenos">187</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-188"><a href="#Linear_CMT-188"><span class="linenos">188</span></a><span class="sd">        Returns the prepared previous context with the mode set to &#39;future&#39;.</span>
</span><span id="Linear_CMT-189"><a href="#Linear_CMT-189"><span class="linenos">189</span></a>
</span><span id="Linear_CMT-190"><a href="#Linear_CMT-190"><span class="linenos">190</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-191"><a href="#Linear_CMT-191"><span class="linenos">191</span></a><span class="sd">            dict: The prepared previous context.</span>
</span><span id="Linear_CMT-192"><a href="#Linear_CMT-192"><span class="linenos">192</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-193"><a href="#Linear_CMT-193"><span class="linenos">193</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Get the prepared context in &#39;future&#39; mode</span>
</span><span id="Linear_CMT-194"><a href="#Linear_CMT-194"><span class="linenos">194</span></a>
</span><span id="Linear_CMT-195"><a href="#Linear_CMT-195"><span class="linenos">195</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-196"><a href="#Linear_CMT-196"><span class="linenos">196</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-197"><a href="#Linear_CMT-197"><span class="linenos">197</span></a><span class="sd">        Converts the prepared previous context (with the mode set to &#39;future&#39;) into a JSON-formatted string.</span>
</span><span id="Linear_CMT-198"><a href="#Linear_CMT-198"><span class="linenos">198</span></a>
</span><span id="Linear_CMT-199"><a href="#Linear_CMT-199"><span class="linenos">199</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-200"><a href="#Linear_CMT-200"><span class="linenos">200</span></a><span class="sd">            str: A JSON-formatted string of the prepared previous context.</span>
</span><span id="Linear_CMT-201"><a href="#Linear_CMT-201"><span class="linenos">201</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-202"><a href="#Linear_CMT-202"><span class="linenos">202</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">),</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># ⭐ Convert the context to a JSON string</span>
</span><span id="Linear_CMT-203"><a href="#Linear_CMT-203"><span class="linenos">203</span></a>
</span><span id="Linear_CMT-204"><a href="#Linear_CMT-204"><span class="linenos">204</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_next_llm_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-205"><a href="#Linear_CMT-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-206"><a href="#Linear_CMT-206"><span class="linenos">206</span></a><span class="sd">        Prepares the context for the next LLM (Language Model) interaction.</span>
</span><span id="Linear_CMT-207"><a href="#Linear_CMT-207"><span class="linenos">207</span></a>
</span><span id="Linear_CMT-208"><a href="#Linear_CMT-208"><span class="linenos">208</span></a><span class="sd">        This function calls `prepare_previous_context` with the &#39;future&#39; mode to set up the context.</span>
</span><span id="Linear_CMT-209"><a href="#Linear_CMT-209"><span class="linenos">209</span></a>
</span><span id="Linear_CMT-210"><a href="#Linear_CMT-210"><span class="linenos">210</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-211"><a href="#Linear_CMT-211"><span class="linenos">211</span></a><span class="sd">            The result of the `prepare_previous_context` function call.</span>
</span><span id="Linear_CMT-212"><a href="#Linear_CMT-212"><span class="linenos">212</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-213"><a href="#Linear_CMT-213"><span class="linenos">213</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Prepares the context for the next LLM interaction</span>
</span><span id="Linear_CMT-214"><a href="#Linear_CMT-214"><span class="linenos">214</span></a>
</span><span id="Linear_CMT-215"><a href="#Linear_CMT-215"><span class="linenos">215</span></a>
</span><span id="Linear_CMT-216"><a href="#Linear_CMT-216"><span class="linenos">216</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_init_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_input_arr</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_nothink</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="Linear_CMT-217"><a href="#Linear_CMT-217"><span class="linenos">217</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-218"><a href="#Linear_CMT-218"><span class="linenos">218</span></a><span class="sd">        Save and process the initial input messages to the context.</span>
</span><span id="Linear_CMT-219"><a href="#Linear_CMT-219"><span class="linenos">219</span></a>
</span><span id="Linear_CMT-220"><a href="#Linear_CMT-220"><span class="linenos">220</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-221"><a href="#Linear_CMT-221"><span class="linenos">221</span></a><span class="sd">            init_input_arr (list): Array of initial input messages to be processed</span>
</span><span id="Linear_CMT-222"><a href="#Linear_CMT-222"><span class="linenos">222</span></a><span class="sd">                                  Each message should be a dict with &#39;role&#39; and &#39;content&#39;</span>
</span><span id="Linear_CMT-223"><a href="#Linear_CMT-223"><span class="linenos">223</span></a><span class="sd">            add_nothink (bool, optional): If True, appends &quot;/no_think&quot; to the last message&#39;s content. Defaults to False.</span>
</span><span id="Linear_CMT-224"><a href="#Linear_CMT-224"><span class="linenos">224</span></a>
</span><span id="Linear_CMT-225"><a href="#Linear_CMT-225"><span class="linenos">225</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT-226"><a href="#Linear_CMT-226"><span class="linenos">226</span></a><span class="sd">            - Initializes the context with the provided messages</span>
</span><span id="Linear_CMT-227"><a href="#Linear_CMT-227"><span class="linenos">227</span></a><span class="sd">            - Computes token arrays for each message</span>
</span><span id="Linear_CMT-228"><a href="#Linear_CMT-228"><span class="linenos">228</span></a><span class="sd">            - Validates that the context is empty before saving</span>
</span><span id="Linear_CMT-229"><a href="#Linear_CMT-229"><span class="linenos">229</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-230"><a href="#Linear_CMT-230"><span class="linenos">230</span></a>        <span class="c1"># save basic</span>
</span><span id="Linear_CMT-231"><a href="#Linear_CMT-231"><span class="linenos">231</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;full_context should be empty when saving init input&quot;</span>
</span><span id="Linear_CMT-232"><a href="#Linear_CMT-232"><span class="linenos">232</span></a>        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">llm_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">):</span>
</span><span id="Linear_CMT-233"><a href="#Linear_CMT-233"><span class="linenos">233</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="Linear_CMT-234"><a href="#Linear_CMT-234"><span class="linenos">234</span></a>                <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="Linear_CMT-235"><a href="#Linear_CMT-235"><span class="linenos">235</span></a>                    <span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">/no_think&quot;</span>
</span><span id="Linear_CMT-236"><a href="#Linear_CMT-236"><span class="linenos">236</span></a>            <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT-237"><a href="#Linear_CMT-237"><span class="linenos">237</span></a>                <span class="n">author</span><span class="o">=</span><span class="s2">&quot;initialization&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-238"><a href="#Linear_CMT-238"><span class="linenos">238</span></a>                <span class="n">role</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-239"><a href="#Linear_CMT-239"><span class="linenos">239</span></a>                <span class="n">content</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-240"><a href="#Linear_CMT-240"><span class="linenos">240</span></a>                <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;manual&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-241"><a href="#Linear_CMT-241"><span class="linenos">241</span></a>                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT-242"><a href="#Linear_CMT-242"><span class="linenos">242</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT-243"><a href="#Linear_CMT-243"><span class="linenos">243</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Adds the extended message to the full context</span>
</span><span id="Linear_CMT-244"><a href="#Linear_CMT-244"><span class="linenos">244</span></a>
</span><span id="Linear_CMT-245"><a href="#Linear_CMT-245"><span class="linenos">245</span></a>        <span class="c1"># compute token array for each message</span>
</span><span id="Linear_CMT-246"><a href="#Linear_CMT-246"><span class="linenos">246</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT-247"><a href="#Linear_CMT-247"><span class="linenos">247</span></a>        <span class="k">for</span> <span class="n">llm_msg</span><span class="p">,</span> <span class="n">ext_msg</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">))):</span>
</span><span id="Linear_CMT-248"><a href="#Linear_CMT-248"><span class="linenos">248</span></a>            <span class="n">text_with_chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">[:(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT-249"><a href="#Linear_CMT-249"><span class="linenos">249</span></a>            <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_with_chat_template</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT-250"><a href="#Linear_CMT-250"><span class="linenos">250</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT-251"><a href="#Linear_CMT-251"><span class="linenos">251</span></a>            <span class="c1"># attention_mask = outputs[&quot;attention_mask&quot;][0].tolist()</span>
</span><span id="Linear_CMT-252"><a href="#Linear_CMT-252"><span class="linenos">252</span></a>            <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># get the new tokens added in this step</span>
</span><span id="Linear_CMT-253"><a href="#Linear_CMT-253"><span class="linenos">253</span></a>            <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT-254"><a href="#Linear_CMT-254"><span class="linenos">254</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="Linear_CMT-255"><a href="#Linear_CMT-255"><span class="linenos">255</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Linear_CMT-256"><a href="#Linear_CMT-256"><span class="linenos">256</span></a>                <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="Linear_CMT-257"><a href="#Linear_CMT-257"><span class="linenos">257</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="Linear_CMT-258"><a href="#Linear_CMT-258"><span class="linenos">258</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">input_id_increment</span>  <span class="c1"># ⭐ Sets the token array for the extended message</span>
</span><span id="Linear_CMT-259"><a href="#Linear_CMT-259"><span class="linenos">259</span></a>            <span class="n">token_ids_acc</span> <span class="o">+=</span> <span class="n">input_ids</span>
</span><span id="Linear_CMT-260"><a href="#Linear_CMT-260"><span class="linenos">260</span></a>        <span class="k">return</span>
</span><span id="Linear_CMT-261"><a href="#Linear_CMT-261"><span class="linenos">261</span></a>
</span><span id="Linear_CMT-262"><a href="#Linear_CMT-262"><span class="linenos">262</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">influence_extra_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">):</span>
</span><span id="Linear_CMT-263"><a href="#Linear_CMT-263"><span class="linenos">263</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-264"><a href="#Linear_CMT-264"><span class="linenos">264</span></a><span class="sd">        Evaluates the LLM output for repetition and applies a penalty reward.</span>
</span><span id="Linear_CMT-265"><a href="#Linear_CMT-265"><span class="linenos">265</span></a><span class="sd">        The penalty is logged if non-zero, and the minimum penalty value is stored in the mistakes dictionary.</span>
</span><span id="Linear_CMT-266"><a href="#Linear_CMT-266"><span class="linenos">266</span></a>
</span><span id="Linear_CMT-267"><a href="#Linear_CMT-267"><span class="linenos">267</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-268"><a href="#Linear_CMT-268"><span class="linenos">268</span></a><span class="sd">            llm_output (dict): The output from the language model, expected to contain a &#39;content&#39; key.</span>
</span><span id="Linear_CMT-269"><a href="#Linear_CMT-269"><span class="linenos">269</span></a>
</span><span id="Linear_CMT-270"><a href="#Linear_CMT-270"><span class="linenos">270</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-271"><a href="#Linear_CMT-271"><span class="linenos">271</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT-272"><a href="#Linear_CMT-272"><span class="linenos">272</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-273"><a href="#Linear_CMT-273"><span class="linenos">273</span></a>        <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">=</span> <span class="n">repetition_penalty_reward_scalar</span><span class="p">(</span><span class="n">completion</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the repetition penalty reward</span>
</span><span id="Linear_CMT-274"><a href="#Linear_CMT-274"><span class="linenos">274</span></a>        <span class="k">if</span> <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="Linear_CMT-275"><a href="#Linear_CMT-275"><span class="linenos">275</span></a>            <span class="n">print_dict</span><span class="p">({</span>
</span><span id="Linear_CMT-276"><a href="#Linear_CMT-276"><span class="linenos">276</span></a>                <span class="s2">&quot;reason&quot;</span><span class="p">:</span> <span class="s2">&quot;repetition_penalty_reward&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-277"><a href="#Linear_CMT-277"><span class="linenos">277</span></a>                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-278"><a href="#Linear_CMT-278"><span class="linenos">278</span></a>                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span>
</span><span id="Linear_CMT-279"><a href="#Linear_CMT-279"><span class="linenos">279</span></a>            <span class="p">})</span>
</span><span id="Linear_CMT-280"><a href="#Linear_CMT-280"><span class="linenos">280</span></a>        <span class="k">if</span> <span class="s1">&#39;repetition_penalty_reward&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">:</span>
</span><span id="Linear_CMT-281"><a href="#Linear_CMT-281"><span class="linenos">281</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT-282"><a href="#Linear_CMT-282"><span class="linenos">282</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Update the mistakes dictionary with the minimum penalty</span>
</span><span id="Linear_CMT-283"><a href="#Linear_CMT-283"><span class="linenos">283</span></a>
</span><span id="Linear_CMT-284"><a href="#Linear_CMT-284"><span class="linenos">284</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="Linear_CMT-285"><a href="#Linear_CMT-285"><span class="linenos">285</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-286"><a href="#Linear_CMT-286"><span class="linenos">286</span></a><span class="sd">        Save the output from the LLM to the full context.</span>
</span><span id="Linear_CMT-287"><a href="#Linear_CMT-287"><span class="linenos">287</span></a>
</span><span id="Linear_CMT-288"><a href="#Linear_CMT-288"><span class="linenos">288</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-289"><a href="#Linear_CMT-289"><span class="linenos">289</span></a><span class="sd">            llm_output (dict): The output from the LLM containing &#39;role&#39;, &#39;content&#39;, and &#39;tokens&#39;.</span>
</span><span id="Linear_CMT-290"><a href="#Linear_CMT-290"><span class="linenos">290</span></a><span class="sd">            input_msg_ref: Reference to the input messages for token increment calculation.</span>
</span><span id="Linear_CMT-291"><a href="#Linear_CMT-291"><span class="linenos">291</span></a><span class="sd">            auto_register_full_context (bool): Whether to register the output in the full context.</span>
</span><span id="Linear_CMT-292"><a href="#Linear_CMT-292"><span class="linenos">292</span></a>
</span><span id="Linear_CMT-293"><a href="#Linear_CMT-293"><span class="linenos">293</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-294"><a href="#Linear_CMT-294"><span class="linenos">294</span></a><span class="sd">            ExtendedMessage: The processed and extended message object.</span>
</span><span id="Linear_CMT-295"><a href="#Linear_CMT-295"><span class="linenos">295</span></a>
</span><span id="Linear_CMT-296"><a href="#Linear_CMT-296"><span class="linenos">296</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT-297"><a href="#Linear_CMT-297"><span class="linenos">297</span></a><span class="sd">            - Processes the LLM output and adds it to the conversation history.</span>
</span><span id="Linear_CMT-298"><a href="#Linear_CMT-298"><span class="linenos">298</span></a><span class="sd">            - Handles token processing and generation prompt management.</span>
</span><span id="Linear_CMT-299"><a href="#Linear_CMT-299"><span class="linenos">299</span></a><span class="sd">            - Ensures proper tokenization and context maintenance.</span>
</span><span id="Linear_CMT-300"><a href="#Linear_CMT-300"><span class="linenos">300</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-301"><a href="#Linear_CMT-301"><span class="linenos">301</span></a>        <span class="c1"># save basic</span>
</span><span id="Linear_CMT-302"><a href="#Linear_CMT-302"><span class="linenos">302</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">llm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="Linear_CMT-303"><a href="#Linear_CMT-303"><span class="linenos">303</span></a>        <span class="n">token_generator</span> <span class="o">=</span> <span class="s2">&quot;manual&quot;</span> <span class="k">if</span> <span class="s1">&#39;tokens&#39;</span> <span class="ow">in</span> <span class="n">llm_output</span> <span class="k">else</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="Linear_CMT-304"><a href="#Linear_CMT-304"><span class="linenos">304</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT-305"><a href="#Linear_CMT-305"><span class="linenos">305</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-306"><a href="#Linear_CMT-306"><span class="linenos">306</span></a>            <span class="n">role</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-307"><a href="#Linear_CMT-307"><span class="linenos">307</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-308"><a href="#Linear_CMT-308"><span class="linenos">308</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="n">token_generator</span><span class="p">,</span>
</span><span id="Linear_CMT-309"><a href="#Linear_CMT-309"><span class="linenos">309</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT-310"><a href="#Linear_CMT-310"><span class="linenos">310</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with LLM output details</span>
</span><span id="Linear_CMT-311"><a href="#Linear_CMT-311"><span class="linenos">311</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="Linear_CMT-312"><a href="#Linear_CMT-312"><span class="linenos">312</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context if auto_register_full_context is True</span>
</span><span id="Linear_CMT-313"><a href="#Linear_CMT-313"><span class="linenos">313</span></a>
</span><span id="Linear_CMT-314"><a href="#Linear_CMT-314"><span class="linenos">314</span></a>        <span class="c1"># check mistakes</span>
</span><span id="Linear_CMT-315"><a href="#Linear_CMT-315"><span class="linenos">315</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="Linear_CMT-316"><a href="#Linear_CMT-316"><span class="linenos">316</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">influence_extra_reward</span><span class="p">(</span><span class="n">llm_output</span><span class="p">)</span>  <span class="c1"># ⭐ Influence extra reward based on LLM output</span>
</span><span id="Linear_CMT-317"><a href="#Linear_CMT-317"><span class="linenos">317</span></a>
</span><span id="Linear_CMT-318"><a href="#Linear_CMT-318"><span class="linenos">318</span></a>        <span class="c1"># generate token</span>
</span><span id="Linear_CMT-319"><a href="#Linear_CMT-319"><span class="linenos">319</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span id="Linear_CMT-320"><a href="#Linear_CMT-320"><span class="linenos">320</span></a>            <span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="Linear_CMT-321"><a href="#Linear_CMT-321"><span class="linenos">321</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT-322"><a href="#Linear_CMT-322"><span class="linenos">322</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="Linear_CMT-323"><a href="#Linear_CMT-323"><span class="linenos">323</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT-324"><a href="#Linear_CMT-324"><span class="linenos">324</span></a>            <span class="c1"># completion_token_arr will contain generation_prompt header</span>
</span><span id="Linear_CMT-325"><a href="#Linear_CMT-325"><span class="linenos">325</span></a>            <span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">msg2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="Linear_CMT-326"><a href="#Linear_CMT-326"><span class="linenos">326</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;</span>
</span><span id="Linear_CMT-327"><a href="#Linear_CMT-327"><span class="linenos">327</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT-328"><a href="#Linear_CMT-328"><span class="linenos">328</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;&lt;|im_start|&gt;...&lt;|im_end|&gt;</span>
</span><span id="Linear_CMT-329"><a href="#Linear_CMT-329"><span class="linenos">329</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span> <span class="o">+</span> <span class="p">[</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>  <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]}</span> <span class="p">],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT-330"><a href="#Linear_CMT-330"><span class="linenos">330</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT-331"><a href="#Linear_CMT-331"><span class="linenos">331</span></a>            <span class="n">vllm_output_raw_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_id</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]]</span>
</span><span id="Linear_CMT-332"><a href="#Linear_CMT-332"><span class="linenos">332</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vllm_output_raw_token</span><span class="p">)</span>  <span class="c1"># ⭐ Increment the generated token count</span>
</span><span id="Linear_CMT-333"><a href="#Linear_CMT-333"><span class="linenos">333</span></a>            <span class="n">final_token_arr</span> <span class="o">=</span> <span class="n">replace_token_ids</span><span class="p">(</span><span class="n">place_holder</span><span class="o">=</span><span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">replace_with</span><span class="o">=</span><span class="n">vllm_output_raw_token</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">])</span>
</span><span id="Linear_CMT-334"><a href="#Linear_CMT-334"><span class="linenos">334</span></a>            <span class="k">return</span> <span class="n">final_token_arr</span>
</span><span id="Linear_CMT-335"><a href="#Linear_CMT-335"><span class="linenos">335</span></a>
</span><span id="Linear_CMT-336"><a href="#Linear_CMT-336"><span class="linenos">336</span></a>        <span class="k">if</span> <span class="n">token_generator</span> <span class="o">==</span> <span class="s2">&quot;manual&quot;</span><span class="p">:</span>
</span><span id="Linear_CMT-337"><a href="#Linear_CMT-337"><span class="linenos">337</span></a>            <span class="n">token_arr_method2</span> <span class="o">=</span> <span class="n">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span>  <span class="c1"># ⭐ Generate token increments using the VLLM response</span>
</span><span id="Linear_CMT-338"><a href="#Linear_CMT-338"><span class="linenos">338</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">token_arr_method2</span>  <span class="c1"># ⭐ Assign the generated token array to the ExtendedMessage</span>
</span><span id="Linear_CMT-339"><a href="#Linear_CMT-339"><span class="linenos">339</span></a>        <span class="k">return</span> <span class="n">ext_msg</span>
</span><span id="Linear_CMT-340"><a href="#Linear_CMT-340"><span class="linenos">340</span></a>
</span><span id="Linear_CMT-341"><a href="#Linear_CMT-341"><span class="linenos">341</span></a>
</span><span id="Linear_CMT-342"><a href="#Linear_CMT-342"><span class="linenos">342</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output_do_not_register_full_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">):</span>
</span><span id="Linear_CMT-343"><a href="#Linear_CMT-343"><span class="linenos">343</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-344"><a href="#Linear_CMT-344"><span class="linenos">344</span></a><span class="sd">        Saves the LLM output to the context without registering the full context.</span>
</span><span id="Linear_CMT-345"><a href="#Linear_CMT-345"><span class="linenos">345</span></a>
</span><span id="Linear_CMT-346"><a href="#Linear_CMT-346"><span class="linenos">346</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-347"><a href="#Linear_CMT-347"><span class="linenos">347</span></a><span class="sd">            llm_output: The output from the language model.</span>
</span><span id="Linear_CMT-348"><a href="#Linear_CMT-348"><span class="linenos">348</span></a><span class="sd">            input_msg_ref: Reference to the input message.</span>
</span><span id="Linear_CMT-349"><a href="#Linear_CMT-349"><span class="linenos">349</span></a>
</span><span id="Linear_CMT-350"><a href="#Linear_CMT-350"><span class="linenos">350</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-351"><a href="#Linear_CMT-351"><span class="linenos">351</span></a><span class="sd">            The result of saving the LLM output with the specified options.</span>
</span><span id="Linear_CMT-352"><a href="#Linear_CMT-352"><span class="linenos">352</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-353"><a href="#Linear_CMT-353"><span class="linenos">353</span></a>        <span class="k">return</span> <span class="n">Linear_CMT</span><span class="o">.</span><span class="n">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># ⭐ Save LLM output without full context registration</span>
</span><span id="Linear_CMT-354"><a href="#Linear_CMT-354"><span class="linenos">354</span></a>
</span><span id="Linear_CMT-355"><a href="#Linear_CMT-355"><span class="linenos">355</span></a>
</span><span id="Linear_CMT-356"><a href="#Linear_CMT-356"><span class="linenos">356</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_env_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_output</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_nothink</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="Linear_CMT-357"><a href="#Linear_CMT-357"><span class="linenos">357</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-358"><a href="#Linear_CMT-358"><span class="linenos">358</span></a><span class="sd">        Save and process environment output to the context.</span>
</span><span id="Linear_CMT-359"><a href="#Linear_CMT-359"><span class="linenos">359</span></a>
</span><span id="Linear_CMT-360"><a href="#Linear_CMT-360"><span class="linenos">360</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-361"><a href="#Linear_CMT-361"><span class="linenos">361</span></a><span class="sd">            env_output (dict): Environment output containing &#39;content&#39;</span>
</span><span id="Linear_CMT-362"><a href="#Linear_CMT-362"><span class="linenos">362</span></a><span class="sd">            input_msg_ref (List[dict], optional): Reference messages for token calculation</span>
</span><span id="Linear_CMT-363"><a href="#Linear_CMT-363"><span class="linenos">363</span></a><span class="sd">            add_nothink (bool, optional): Whether to append &#39;/no_think&#39; to the content</span>
</span><span id="Linear_CMT-364"><a href="#Linear_CMT-364"><span class="linenos">364</span></a>
</span><span id="Linear_CMT-365"><a href="#Linear_CMT-365"><span class="linenos">365</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT-366"><a href="#Linear_CMT-366"><span class="linenos">366</span></a><span class="sd">            - Clips environment output if it exceeds max_env_output_length</span>
</span><span id="Linear_CMT-367"><a href="#Linear_CMT-367"><span class="linenos">367</span></a><span class="sd">            - Processes the output as a user message in the conversation</span>
</span><span id="Linear_CMT-368"><a href="#Linear_CMT-368"><span class="linenos">368</span></a><span class="sd">            - Computes and stores token arrays for the environment response</span>
</span><span id="Linear_CMT-369"><a href="#Linear_CMT-369"><span class="linenos">369</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-370"><a href="#Linear_CMT-370"><span class="linenos">370</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="Linear_CMT-371"><a href="#Linear_CMT-371"><span class="linenos">371</span></a>        <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;error&#39;</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">):</span>
</span><span id="Linear_CMT-372"><a href="#Linear_CMT-372"><span class="linenos">372</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[Error from environment: </span><span class="si">{</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">]&quot;</span>
</span><span id="Linear_CMT-373"><a href="#Linear_CMT-373"><span class="linenos">373</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]):</span>
</span><span id="Linear_CMT-374"><a href="#Linear_CMT-374"><span class="linenos">374</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;[No content provided by the environment]&#39;</span>
</span><span id="Linear_CMT-375"><a href="#Linear_CMT-375"><span class="linenos">375</span></a>        <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="Linear_CMT-376"><a href="#Linear_CMT-376"><span class="linenos">376</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot; /no_think&quot;</span>
</span><span id="Linear_CMT-377"><a href="#Linear_CMT-377"><span class="linenos">377</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT-378"><a href="#Linear_CMT-378"><span class="linenos">378</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;env&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-379"><a href="#Linear_CMT-379"><span class="linenos">379</span></a>            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-380"><a href="#Linear_CMT-380"><span class="linenos">380</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT-381"><a href="#Linear_CMT-381"><span class="linenos">381</span></a>            <span class="n">clip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="Linear_CMT-382"><a href="#Linear_CMT-382"><span class="linenos">382</span></a>            <span class="n">clip_token_limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">,</span>
</span><span id="Linear_CMT-383"><a href="#Linear_CMT-383"><span class="linenos">383</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-384"><a href="#Linear_CMT-384"><span class="linenos">384</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT-385"><a href="#Linear_CMT-385"><span class="linenos">385</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with the environment content</span>
</span><span id="Linear_CMT-386"><a href="#Linear_CMT-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context</span>
</span><span id="Linear_CMT-387"><a href="#Linear_CMT-387"><span class="linenos">387</span></a>        <span class="k">return</span>
</span><span id="Linear_CMT-388"><a href="#Linear_CMT-388"><span class="linenos">388</span></a>
</span><span id="Linear_CMT-389"><a href="#Linear_CMT-389"><span class="linenos">389</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_role_content</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
</span><span id="Linear_CMT-390"><a href="#Linear_CMT-390"><span class="linenos">390</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-391"><a href="#Linear_CMT-391"><span class="linenos">391</span></a><span class="sd">        Converts a list of ExtendedMessage objects into a list of dictionaries with &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="Linear_CMT-392"><a href="#Linear_CMT-392"><span class="linenos">392</span></a>
</span><span id="Linear_CMT-393"><a href="#Linear_CMT-393"><span class="linenos">393</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-394"><a href="#Linear_CMT-394"><span class="linenos">394</span></a><span class="sd">            ext_msg_array (List[ExtendedMessage]): A list of ExtendedMessage objects.</span>
</span><span id="Linear_CMT-395"><a href="#Linear_CMT-395"><span class="linenos">395</span></a>
</span><span id="Linear_CMT-396"><a href="#Linear_CMT-396"><span class="linenos">396</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-397"><a href="#Linear_CMT-397"><span class="linenos">397</span></a><span class="sd">            List[dict]: A list of dictionaries, each containing &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="Linear_CMT-398"><a href="#Linear_CMT-398"><span class="linenos">398</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-399"><a href="#Linear_CMT-399"><span class="linenos">399</span></a>        <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span> <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_msg_array</span><span class="p">]</span>  <span class="c1"># ⭐ Convert each ExtendedMessage to a dictionary</span>
</span><span id="Linear_CMT-400"><a href="#Linear_CMT-400"><span class="linenos">400</span></a>
</span><span id="Linear_CMT-401"><a href="#Linear_CMT-401"><span class="linenos">401</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_world_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="Linear_CMT-402"><a href="#Linear_CMT-402"><span class="linenos">402</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-403"><a href="#Linear_CMT-403"><span class="linenos">403</span></a><span class="sd">        Process the latest model content before environment interaction.</span>
</span><span id="Linear_CMT-404"><a href="#Linear_CMT-404"><span class="linenos">404</span></a>
</span><span id="Linear_CMT-405"><a href="#Linear_CMT-405"><span class="linenos">405</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-406"><a href="#Linear_CMT-406"><span class="linenos">406</span></a><span class="sd">            str: Processed content, with code extracted from markdown code blocks if present</span>
</span><span id="Linear_CMT-407"><a href="#Linear_CMT-407"><span class="linenos">407</span></a><span class="sd">                 or the raw content if no code blocks are found</span>
</span><span id="Linear_CMT-408"><a href="#Linear_CMT-408"><span class="linenos">408</span></a>
</span><span id="Linear_CMT-409"><a href="#Linear_CMT-409"><span class="linenos">409</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT-410"><a href="#Linear_CMT-410"><span class="linenos">410</span></a><span class="sd">            - Extracts Python code from markdown code blocks (```python```)</span>
</span><span id="Linear_CMT-411"><a href="#Linear_CMT-411"><span class="linenos">411</span></a><span class="sd">            - Returns the raw content if no valid code blocks are found</span>
</span><span id="Linear_CMT-412"><a href="#Linear_CMT-412"><span class="linenos">412</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-413"><a href="#Linear_CMT-413"><span class="linenos">413</span></a>        <span class="n">latest_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
</span><span id="Linear_CMT-414"><a href="#Linear_CMT-414"><span class="linenos">414</span></a>        <span class="k">return</span> <span class="n">latest_content</span>
</span><span id="Linear_CMT-415"><a href="#Linear_CMT-415"><span class="linenos">415</span></a>
</span><span id="Linear_CMT-416"><a href="#Linear_CMT-416"><span class="linenos">416</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">author</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="Linear_CMT-417"><a href="#Linear_CMT-417"><span class="linenos">417</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-418"><a href="#Linear_CMT-418"><span class="linenos">418</span></a><span class="sd">        Filters the full context to include only messages from a specific author and returns a deep copy of the filtered list.</span>
</span><span id="Linear_CMT-419"><a href="#Linear_CMT-419"><span class="linenos">419</span></a>
</span><span id="Linear_CMT-420"><a href="#Linear_CMT-420"><span class="linenos">420</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-421"><a href="#Linear_CMT-421"><span class="linenos">421</span></a><span class="sd">            author (str): The name of the author whose messages are to be included in the result.</span>
</span><span id="Linear_CMT-422"><a href="#Linear_CMT-422"><span class="linenos">422</span></a>
</span><span id="Linear_CMT-423"><a href="#Linear_CMT-423"><span class="linenos">423</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-424"><a href="#Linear_CMT-424"><span class="linenos">424</span></a><span class="sd">            List[ExtendedMessage]: A deep copy of the list containing only the messages from the specified author.</span>
</span><span id="Linear_CMT-425"><a href="#Linear_CMT-425"><span class="linenos">425</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-426"><a href="#Linear_CMT-426"><span class="linenos">426</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="n">author</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and create a deep copy of the context</span>
</span><span id="Linear_CMT-427"><a href="#Linear_CMT-427"><span class="linenos">427</span></a>
</span><span id="Linear_CMT-428"><a href="#Linear_CMT-428"><span class="linenos">428</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_authors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">authors</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="Linear_CMT-429"><a href="#Linear_CMT-429"><span class="linenos">429</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-430"><a href="#Linear_CMT-430"><span class="linenos">430</span></a><span class="sd">        Filters the full context of messages, returning only those authored by the specified authors.</span>
</span><span id="Linear_CMT-431"><a href="#Linear_CMT-431"><span class="linenos">431</span></a>
</span><span id="Linear_CMT-432"><a href="#Linear_CMT-432"><span class="linenos">432</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-433"><a href="#Linear_CMT-433"><span class="linenos">433</span></a><span class="sd">            authors (str): A string of author names, separated by commas, indicating which authors&#39; messages to include.</span>
</span><span id="Linear_CMT-434"><a href="#Linear_CMT-434"><span class="linenos">434</span></a>
</span><span id="Linear_CMT-435"><a href="#Linear_CMT-435"><span class="linenos">435</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-436"><a href="#Linear_CMT-436"><span class="linenos">436</span></a><span class="sd">            List[ExtendedMessage]: A list of ExtendedMessage objects from the full context that match the specified authors.</span>
</span><span id="Linear_CMT-437"><a href="#Linear_CMT-437"><span class="linenos">437</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-438"><a href="#Linear_CMT-438"><span class="linenos">438</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="ow">in</span> <span class="n">authors</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and deep copy the relevant messages</span>
</span><span id="Linear_CMT-439"><a href="#Linear_CMT-439"><span class="linenos">439</span></a>
</span><span id="Linear_CMT-440"><a href="#Linear_CMT-440"><span class="linenos">440</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-441"><a href="#Linear_CMT-441"><span class="linenos">441</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-442"><a href="#Linear_CMT-442"><span class="linenos">442</span></a><span class="sd">        Tokenizes the full context into a format suitable for input to a language model, creating a sample with necessary attributes like input IDs, attention masks, and position IDs.</span>
</span><span id="Linear_CMT-443"><a href="#Linear_CMT-443"><span class="linenos">443</span></a>
</span><span id="Linear_CMT-444"><a href="#Linear_CMT-444"><span class="linenos">444</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-445"><a href="#Linear_CMT-445"><span class="linenos">445</span></a><span class="sd">            List[Sample]: An array containing a single Sample object, representing the tokenized context.</span>
</span><span id="Linear_CMT-446"><a href="#Linear_CMT-446"><span class="linenos">446</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-447"><a href="#Linear_CMT-447"><span class="linenos">447</span></a>        <span class="c1"># assert self.latest_llm_interaction_socket is None, &quot;unprocessed message buffer! forget to call `save_llm_output` after `prepare_next_llm_context`?&quot;</span>
</span><span id="Linear_CMT-448"><a href="#Linear_CMT-448"><span class="linenos">448</span></a>        <span class="n">sample_arr</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT-449"><a href="#Linear_CMT-449"><span class="linenos">449</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT-450"><a href="#Linear_CMT-450"><span class="linenos">450</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="Linear_CMT-451"><a href="#Linear_CMT-451"><span class="linenos">451</span></a>        <span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
</span><span id="Linear_CMT-452"><a href="#Linear_CMT-452"><span class="linenos">452</span></a>            <span class="n">data_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_id</span><span class="p">,</span>
</span><span id="Linear_CMT-453"><a href="#Linear_CMT-453"><span class="linenos">453</span></a>            <span class="n">rollout_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_id</span><span class="p">,</span>
</span><span id="Linear_CMT-454"><a href="#Linear_CMT-454"><span class="linenos">454</span></a>            <span class="n">task_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span>
</span><span id="Linear_CMT-455"><a href="#Linear_CMT-455"><span class="linenos">455</span></a>            <span class="n">minor_index_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="Linear_CMT-456"><a href="#Linear_CMT-456"><span class="linenos">456</span></a>            <span class="n">messages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">to_role_content</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">),</span>
</span><span id="Linear_CMT-457"><a href="#Linear_CMT-457"><span class="linenos">457</span></a>            <span class="n">input_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-458"><a href="#Linear_CMT-458"><span class="linenos">458</span></a>            <span class="n">prompt_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-459"><a href="#Linear_CMT-459"><span class="linenos">459</span></a>            <span class="n">response_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-460"><a href="#Linear_CMT-460"><span class="linenos">460</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-461"><a href="#Linear_CMT-461"><span class="linenos">461</span></a>            <span class="n">prompt_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-462"><a href="#Linear_CMT-462"><span class="linenos">462</span></a>            <span class="n">response_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-463"><a href="#Linear_CMT-463"><span class="linenos">463</span></a>            <span class="n">loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-464"><a href="#Linear_CMT-464"><span class="linenos">464</span></a>            <span class="n">prompt_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-465"><a href="#Linear_CMT-465"><span class="linenos">465</span></a>            <span class="n">response_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-466"><a href="#Linear_CMT-466"><span class="linenos">466</span></a>            <span class="n">position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-467"><a href="#Linear_CMT-467"><span class="linenos">467</span></a>            <span class="n">prompt_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-468"><a href="#Linear_CMT-468"><span class="linenos">468</span></a>            <span class="n">response_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT-469"><a href="#Linear_CMT-469"><span class="linenos">469</span></a>            <span class="n">reward_scores</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">model_dump</span><span class="p">(),</span> <span class="c1"># reward is duplicated in each sample</span>
</span><span id="Linear_CMT-470"><a href="#Linear_CMT-470"><span class="linenos">470</span></a>            <span class="n">max_prompt_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="Linear_CMT-471"><a href="#Linear_CMT-471"><span class="linenos">471</span></a>            <span class="n">max_response_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span><span class="p">,</span>
</span><span id="Linear_CMT-472"><a href="#Linear_CMT-472"><span class="linenos">472</span></a>            <span class="n">max_model_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="Linear_CMT-473"><a href="#Linear_CMT-473"><span class="linenos">473</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT-474"><a href="#Linear_CMT-474"><span class="linenos">474</span></a>        <span class="n">sample</span><span class="o">.</span><span class="n">truncate_output_ids</span><span class="p">()</span>  <span class="c1"># ⭐ Ensure the output IDs are within the allowed length</span>
</span><span id="Linear_CMT-475"><a href="#Linear_CMT-475"><span class="linenos">475</span></a>        <span class="n">sample_arr</span> <span class="o">+=</span> <span class="p">[</span><span class="n">sample</span><span class="p">]</span>
</span><span id="Linear_CMT-476"><a href="#Linear_CMT-476"><span class="linenos">476</span></a>        <span class="k">return</span> <span class="n">sample_arr</span>
</span><span id="Linear_CMT-477"><a href="#Linear_CMT-477"><span class="linenos">477</span></a>
</span><span id="Linear_CMT-478"><a href="#Linear_CMT-478"><span class="linenos">478</span></a>
</span><span id="Linear_CMT-479"><a href="#Linear_CMT-479"><span class="linenos">479</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_render_token_log</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT-480"><a href="#Linear_CMT-480"><span class="linenos">480</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT-481"><a href="#Linear_CMT-481"><span class="linenos">481</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="Linear_CMT-482"><a href="#Linear_CMT-482"><span class="linenos">482</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT-483"><a href="#Linear_CMT-483"><span class="linenos">483</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT-484"><a href="#Linear_CMT-484"><span class="linenos">484</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT-485"><a href="#Linear_CMT-485"><span class="linenos">485</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="Linear_CMT-486"><a href="#Linear_CMT-486"><span class="linenos">486</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-487"><a href="#Linear_CMT-487"><span class="linenos">487</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-488"><a href="#Linear_CMT-488"><span class="linenos">488</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-489"><a href="#Linear_CMT-489"><span class="linenos">489</span></a>        <span class="p">}</span>
</span><span id="Linear_CMT-490"><a href="#Linear_CMT-490"><span class="linenos">490</span></a>
</span><span id="Linear_CMT-491"><a href="#Linear_CMT-491"><span class="linenos">491</span></a>
</span><span id="Linear_CMT-492"><a href="#Linear_CMT-492"><span class="linenos">492</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">generate_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_id</span><span class="p">):</span>
</span><span id="Linear_CMT-493"><a href="#Linear_CMT-493"><span class="linenos">493</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-494"><a href="#Linear_CMT-494"><span class="linenos">494</span></a><span class="sd">        Generates and prints a log for the specified task, including detailed information about the tokenized steps,</span>
</span><span id="Linear_CMT-495"><a href="#Linear_CMT-495"><span class="linenos">495</span></a><span class="sd">        input IDs, loss mask colors, and rewards. The log is formatted into a nested JSON structure and printed.</span>
</span><span id="Linear_CMT-496"><a href="#Linear_CMT-496"><span class="linenos">496</span></a>
</span><span id="Linear_CMT-497"><a href="#Linear_CMT-497"><span class="linenos">497</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-498"><a href="#Linear_CMT-498"><span class="linenos">498</span></a><span class="sd">            task_id (str): The ID of the task for which the log is being generated.</span>
</span><span id="Linear_CMT-499"><a href="#Linear_CMT-499"><span class="linenos">499</span></a>
</span><span id="Linear_CMT-500"><a href="#Linear_CMT-500"><span class="linenos">500</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-501"><a href="#Linear_CMT-501"><span class="linenos">501</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT-502"><a href="#Linear_CMT-502"><span class="linenos">502</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-503"><a href="#Linear_CMT-503"><span class="linenos">503</span></a>        <span class="n">nested_items_print_buffer</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT-504"><a href="#Linear_CMT-504"><span class="linenos">504</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>  <span class="c1"># ⭐ Retrieve the full context for the task</span>
</span><span id="Linear_CMT-505"><a href="#Linear_CMT-505"><span class="linenos">505</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>  <span class="c1"># ⭐ Tokenize the extended steps</span>
</span><span id="Linear_CMT-506"><a href="#Linear_CMT-506"><span class="linenos">506</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Decode the tokenized input IDs to text</span>
</span><span id="Linear_CMT-507"><a href="#Linear_CMT-507"><span class="linenos">507</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Convert input IDs to strings</span>
</span><span id="Linear_CMT-508"><a href="#Linear_CMT-508"><span class="linenos">508</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Generate color array based on loss mask</span>
</span><span id="Linear_CMT-509"><a href="#Linear_CMT-509"><span class="linenos">509</span></a>        <span class="n">buffer</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="Linear_CMT-510"><a href="#Linear_CMT-510"><span class="linenos">510</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-511"><a href="#Linear_CMT-511"><span class="linenos">511</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-512"><a href="#Linear_CMT-512"><span class="linenos">512</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="Linear_CMT-513"><a href="#Linear_CMT-513"><span class="linenos">513</span></a>        <span class="p">}</span>
</span><span id="Linear_CMT-514"><a href="#Linear_CMT-514"><span class="linenos">514</span></a>        <span class="n">len_prompt_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of prompt IDs</span>
</span><span id="Linear_CMT-515"><a href="#Linear_CMT-515"><span class="linenos">515</span></a>        <span class="n">len_response_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of response IDs</span>
</span><span id="Linear_CMT-516"><a href="#Linear_CMT-516"><span class="linenos">516</span></a>        <span class="n">len_input_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of input IDs</span>
</span><span id="Linear_CMT-517"><a href="#Linear_CMT-517"><span class="linenos">517</span></a>        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the reward outcome</span>
</span><span id="Linear_CMT-518"><a href="#Linear_CMT-518"><span class="linenos">518</span></a>        <span class="n">task_outcome</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">success_rate</span><span class="p">)</span>  <span class="c1"># ⭐ Get the task success rate as a string</span>
</span><span id="Linear_CMT-519"><a href="#Linear_CMT-519"><span class="linenos">519</span></a>        <span class="n">final_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">)</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the final reward after applying the reward patch</span>
</span><span id="Linear_CMT-520"><a href="#Linear_CMT-520"><span class="linenos">520</span></a>        <span class="n">selectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_id</span><span class="p">,</span> <span class="n">task_outcome</span><span class="p">]</span>
</span><span id="Linear_CMT-521"><a href="#Linear_CMT-521"><span class="linenos">521</span></a>        <span class="n">nested_items_print_buffer</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">selectors</span><span class="p">)]</span> <span class="o">=</span> <span class="n">NestedJsonItem</span><span class="p">(</span>
</span><span id="Linear_CMT-522"><a href="#Linear_CMT-522"><span class="linenos">522</span></a>            <span class="n">item_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;item&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-523"><a href="#Linear_CMT-523"><span class="linenos">523</span></a>            <span class="n">outcome</span><span class="o">=</span><span class="n">task_outcome</span><span class="p">,</span>
</span><span id="Linear_CMT-524"><a href="#Linear_CMT-524"><span class="linenos">524</span></a>            <span class="n">len_prompt_ids</span><span class="o">=</span><span class="n">len_prompt_ids</span><span class="p">,</span>
</span><span id="Linear_CMT-525"><a href="#Linear_CMT-525"><span class="linenos">525</span></a>            <span class="n">len_response_ids</span><span class="o">=</span><span class="n">len_response_ids</span><span class="p">,</span>
</span><span id="Linear_CMT-526"><a href="#Linear_CMT-526"><span class="linenos">526</span></a>            <span class="n">len_input_ids</span><span class="o">=</span><span class="n">len_input_ids</span><span class="p">,</span>
</span><span id="Linear_CMT-527"><a href="#Linear_CMT-527"><span class="linenos">527</span></a>            <span class="n">reward</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-528"><a href="#Linear_CMT-528"><span class="linenos">528</span></a>            <span class="n">final_reward</span><span class="o">=</span><span class="n">final_reward</span><span class="p">,</span>
</span><span id="Linear_CMT-529"><a href="#Linear_CMT-529"><span class="linenos">529</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">SeqItem</span><span class="p">(</span>
</span><span id="Linear_CMT-530"><a href="#Linear_CMT-530"><span class="linenos">530</span></a>                <span class="n">text</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span>  <span class="c1"># text</span>
</span><span id="Linear_CMT-531"><a href="#Linear_CMT-531"><span class="linenos">531</span></a>                <span class="n">title</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span> <span class="c1"># mouse hover</span>
</span><span id="Linear_CMT-532"><a href="#Linear_CMT-532"><span class="linenos">532</span></a>                <span class="n">count</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;input_id_arr&#39;</span><span class="p">],</span> <span class="c1"># highlight text</span>
</span><span id="Linear_CMT-533"><a href="#Linear_CMT-533"><span class="linenos">533</span></a>                <span class="n">color</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;loss_mask_color_arr&#39;</span><span class="p">]</span>   <span class="c1"># color</span>
</span><span id="Linear_CMT-534"><a href="#Linear_CMT-534"><span class="linenos">534</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT-535"><a href="#Linear_CMT-535"><span class="linenos">535</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT-536"><a href="#Linear_CMT-536"><span class="linenos">536</span></a>        <span class="n">print_nested</span><span class="p">(</span><span class="n">nested_items_print_buffer</span><span class="p">,</span>  <span class="c1"># ⭐ Print the nested JSON buffer</span>
</span><span id="Linear_CMT-537"><a href="#Linear_CMT-537"><span class="linenos">537</span></a>            <span class="n">main_content</span><span class="o">=</span><span class="s2">&quot;This is the main content of the nested JSON&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-538"><a href="#Linear_CMT-538"><span class="linenos">538</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-539"><a href="#Linear_CMT-539"><span class="linenos">539</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;rollout&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-540"><a href="#Linear_CMT-540"><span class="linenos">540</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Linear_CMT-541"><a href="#Linear_CMT-541"><span class="linenos">541</span></a>            <span class="n">attach</span><span class="o">=</span><span class="s2">&quot;Copy Sample Message&quot;</span>
</span><span id="Linear_CMT-542"><a href="#Linear_CMT-542"><span class="linenos">542</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT-543"><a href="#Linear_CMT-543"><span class="linenos">543</span></a>        <span class="n">print_listofdict</span><span class="p">(</span>  <span class="c1"># ⭐ Print the list of dictionaries</span>
</span><span id="Linear_CMT-544"><a href="#Linear_CMT-544"><span class="linenos">544</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Linear_CMT-545"><a href="#Linear_CMT-545"><span class="linenos">545</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-546"><a href="#Linear_CMT-546"><span class="linenos">546</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;conversation&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT-547"><a href="#Linear_CMT-547"><span class="linenos">547</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Linear_CMT-548"><a href="#Linear_CMT-548"><span class="linenos">548</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT-549"><a href="#Linear_CMT-549"><span class="linenos">549</span></a>
</span><span id="Linear_CMT-550"><a href="#Linear_CMT-550"><span class="linenos">550</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
</span><span id="Linear_CMT-551"><a href="#Linear_CMT-551"><span class="linenos">551</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-552"><a href="#Linear_CMT-552"><span class="linenos">552</span></a><span class="sd">        Creates a deep copy of the provided reward and may modify it based on internal state.</span>
</span><span id="Linear_CMT-553"><a href="#Linear_CMT-553"><span class="linenos">553</span></a>
</span><span id="Linear_CMT-554"><a href="#Linear_CMT-554"><span class="linenos">554</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-555"><a href="#Linear_CMT-555"><span class="linenos">555</span></a><span class="sd">            reward (object): The reward object to be patched, which must have an &#39;outcome&#39; attribute.</span>
</span><span id="Linear_CMT-556"><a href="#Linear_CMT-556"><span class="linenos">556</span></a>
</span><span id="Linear_CMT-557"><a href="#Linear_CMT-557"><span class="linenos">557</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-558"><a href="#Linear_CMT-558"><span class="linenos">558</span></a><span class="sd">            object: The possibly modified deep copy of the original reward.</span>
</span><span id="Linear_CMT-559"><a href="#Linear_CMT-559"><span class="linenos">559</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-560"><a href="#Linear_CMT-560"><span class="linenos">560</span></a>        <span class="n">_reward</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>  <span class="c1"># ⭐ Create a deep copy of the reward to avoid modifying the original</span>
</span><span id="Linear_CMT-561"><a href="#Linear_CMT-561"><span class="linenos">561</span></a>        <span class="c1"># if self.compute_madness() &lt; 0: _reward.outcome = -1.0</span>
</span><span id="Linear_CMT-562"><a href="#Linear_CMT-562"><span class="linenos">562</span></a>        <span class="k">return</span> <span class="n">_reward</span>
</span><span id="Linear_CMT-563"><a href="#Linear_CMT-563"><span class="linenos">563</span></a>
</span><span id="Linear_CMT-564"><a href="#Linear_CMT-564"><span class="linenos">564</span></a>
</span><span id="Linear_CMT-565"><a href="#Linear_CMT-565"><span class="linenos">565</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_madness</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="Linear_CMT-566"><a href="#Linear_CMT-566"><span class="linenos">566</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-567"><a href="#Linear_CMT-567"><span class="linenos">567</span></a><span class="sd">        Evaluates the &#39;madness&#39; of the model&#39;s output based on the proportion of certain types of mistakes (e.g., special tokens, repeated characters, non-ASCII characters).</span>
</span><span id="Linear_CMT-568"><a href="#Linear_CMT-568"><span class="linenos">568</span></a>
</span><span id="Linear_CMT-569"><a href="#Linear_CMT-569"><span class="linenos">569</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-570"><a href="#Linear_CMT-570"><span class="linenos">570</span></a><span class="sd">            float: -1.0 if any mistake proportion is below the threshold, otherwise 0.0.</span>
</span><span id="Linear_CMT-571"><a href="#Linear_CMT-571"><span class="linenos">571</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-572"><a href="#Linear_CMT-572"><span class="linenos">572</span></a>        <span class="n">threshold</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.01</span>
</span><span id="Linear_CMT-573"><a href="#Linear_CMT-573"><span class="linenos">573</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="Linear_CMT-574"><a href="#Linear_CMT-574"><span class="linenos">574</span></a>            <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span> <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span>  <span class="c1"># ⭐ Check if any mistake proportion is below the threshold</span>
</span><span id="Linear_CMT-575"><a href="#Linear_CMT-575"><span class="linenos">575</span></a>        <span class="k">return</span> <span class="mf">0.0</span>
</span><span id="Linear_CMT-576"><a href="#Linear_CMT-576"><span class="linenos">576</span></a>
</span><span id="Linear_CMT-577"><a href="#Linear_CMT-577"><span class="linenos">577</span></a>
</span><span id="Linear_CMT-578"><a href="#Linear_CMT-578"><span class="linenos">578</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_steps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">],</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="Linear_CMT-579"><a href="#Linear_CMT-579"><span class="linenos">579</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT-580"><a href="#Linear_CMT-580"><span class="linenos">580</span></a><span class="sd">        Tokenizes the given extended messages, processes them to separate prompts and responses, and prepares the data for model training.</span>
</span><span id="Linear_CMT-581"><a href="#Linear_CMT-581"><span class="linenos">581</span></a><span class="sd">        It also handles the extraction and discarding of experience information if needed.</span>
</span><span id="Linear_CMT-582"><a href="#Linear_CMT-582"><span class="linenos">582</span></a>
</span><span id="Linear_CMT-583"><a href="#Linear_CMT-583"><span class="linenos">583</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT-584"><a href="#Linear_CMT-584"><span class="linenos">584</span></a><span class="sd">            ext_steps (List[ExtendedMessage]): A list of ExtendedMessage objects representing the conversation context.</span>
</span><span id="Linear_CMT-585"><a href="#Linear_CMT-585"><span class="linenos">585</span></a><span class="sd">            debug (bool, optional): A flag to enable debugging. Defaults to False.</span>
</span><span id="Linear_CMT-586"><a href="#Linear_CMT-586"><span class="linenos">586</span></a>
</span><span id="Linear_CMT-587"><a href="#Linear_CMT-587"><span class="linenos">587</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT-588"><a href="#Linear_CMT-588"><span class="linenos">588</span></a><span class="sd">            dict: A dictionary containing tokenized and processed data for model training.</span>
</span><span id="Linear_CMT-589"><a href="#Linear_CMT-589"><span class="linenos">589</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT-590"><a href="#Linear_CMT-590"><span class="linenos">590</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_position_id_with_mask</span>
</span><span id="Linear_CMT-591"><a href="#Linear_CMT-591"><span class="linenos">591</span></a>        <span class="n">ext_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_last_non_llm_msg</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">))</span>  <span class="c1"># ⭐ Remove the last non-LLM message</span>
</span><span id="Linear_CMT-592"><a href="#Linear_CMT-592"><span class="linenos">592</span></a>
</span><span id="Linear_CMT-593"><a href="#Linear_CMT-593"><span class="linenos">593</span></a>        <span class="n">exp_worker</span> <span class="o">=</span> <span class="n">ExperienceWorker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span><span id="Linear_CMT-594"><a href="#Linear_CMT-594"><span class="linenos">594</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">):</span>
</span><span id="Linear_CMT-595"><a href="#Linear_CMT-595"><span class="linenos">595</span></a>            <span class="n">experience</span><span class="p">,</span> <span class="n">new_content</span> <span class="o">=</span> <span class="n">exp_worker</span><span class="o">.</span><span class="n">manage_training_context</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</span><span id="Linear_CMT-596"><a href="#Linear_CMT-596"><span class="linenos">596</span></a>            <span class="k">if</span> <span class="n">experience</span><span class="p">:</span>
</span><span id="Linear_CMT-597"><a href="#Linear_CMT-597"><span class="linenos">597</span></a>                <span class="n">ext_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT-598"><a href="#Linear_CMT-598"><span class="linenos">598</span></a>                    <span class="n">author</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span><span class="p">,</span>
</span><span id="Linear_CMT-599"><a href="#Linear_CMT-599"><span class="linenos">599</span></a>                    <span class="n">role</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span>
</span><span id="Linear_CMT-600"><a href="#Linear_CMT-600"><span class="linenos">600</span></a>                    <span class="n">content</span><span class="o">=</span><span class="n">new_content</span><span class="p">,</span>
</span><span id="Linear_CMT-601"><a href="#Linear_CMT-601"><span class="linenos">601</span></a>                    <span class="n">token_generator</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
</span><span id="Linear_CMT-602"><a href="#Linear_CMT-602"><span class="linenos">602</span></a>                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT-603"><a href="#Linear_CMT-603"><span class="linenos">603</span></a>                    <span class="n">uuid</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">uuid</span><span class="p">,</span>
</span><span id="Linear_CMT-604"><a href="#Linear_CMT-604"><span class="linenos">604</span></a>                <span class="p">)</span>
</span><span id="Linear_CMT-605"><a href="#Linear_CMT-605"><span class="linenos">605</span></a>
</span><span id="Linear_CMT-606"><a href="#Linear_CMT-606"><span class="linenos">606</span></a>        <span class="c1"># mapping</span>
</span><span id="Linear_CMT-607"><a href="#Linear_CMT-607"><span class="linenos">607</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT-608"><a href="#Linear_CMT-608"><span class="linenos">608</span></a>        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT-609"><a href="#Linear_CMT-609"><span class="linenos">609</span></a>        <span class="n">loss_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT-610"><a href="#Linear_CMT-610"><span class="linenos">610</span></a>        <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="Linear_CMT-611"><a href="#Linear_CMT-611"><span class="linenos">611</span></a>        <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_steps</span><span class="p">:</span>
</span><span id="Linear_CMT-612"><a href="#Linear_CMT-612"><span class="linenos">612</span></a>            <span class="c1"># find split index, this have to be done before input_ids += ext_msg.token_arr</span>
</span><span id="Linear_CMT-613"><a href="#Linear_CMT-613"><span class="linenos">613</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">split_prompt_reponse_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">need_training</span><span class="p">):</span>
</span><span id="Linear_CMT-614"><a href="#Linear_CMT-614"><span class="linenos">614</span></a>                <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="Linear_CMT-615"><a href="#Linear_CMT-615"><span class="linenos">615</span></a>                <span class="k">assert</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="s1">&#39;llm&#39;</span><span class="p">,</span> <span class="s2">&quot;The first message after initialization should be from LLM, not from env or user&quot;</span>
</span><span id="Linear_CMT-616"><a href="#Linear_CMT-616"><span class="linenos">616</span></a>            <span class="n">input_ids</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span>
</span><span id="Linear_CMT-617"><a href="#Linear_CMT-617"><span class="linenos">617</span></a>            <span class="n">attention_mask</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span><span class="p">)</span>
</span><span id="Linear_CMT-618"><a href="#Linear_CMT-618"><span class="linenos">618</span></a>            <span class="n">loss_mask</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">get_loss_mask</span><span class="p">(</span><span class="n">blackout_token_combo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span><span class="p">)</span>
</span><span id="Linear_CMT-619"><a href="#Linear_CMT-619"><span class="linenos">619</span></a>
</span><span id="Linear_CMT-620"><a href="#Linear_CMT-620"><span class="linenos">620</span></a>        <span class="k">assert</span> <span class="n">split_prompt_reponse_index</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;split_prompt_reponse_index should not be -1, at least one message should be in the context&quot;</span>
</span><span id="Linear_CMT-621"><a href="#Linear_CMT-621"><span class="linenos">621</span></a>        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">compute_position_id_with_mask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ⭐ Compute position IDs with mask</span>
</span><span id="Linear_CMT-622"><a href="#Linear_CMT-622"><span class="linenos">622</span></a>
</span><span id="Linear_CMT-623"><a href="#Linear_CMT-623"><span class="linenos">623</span></a>        <span class="c1"># separate prompt and response</span>
</span><span id="Linear_CMT-624"><a href="#Linear_CMT-624"><span class="linenos">624</span></a>        <span class="n">prompt_ids</span> <span class="o">=</span>            <span class="n">input_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT-625"><a href="#Linear_CMT-625"><span class="linenos">625</span></a>        <span class="n">prompt_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT-626"><a href="#Linear_CMT-626"><span class="linenos">626</span></a>        <span class="n">prompt_position_ids</span> <span class="o">=</span>   <span class="n">position_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT-627"><a href="#Linear_CMT-627"><span class="linenos">627</span></a>        <span class="n">prompt_loss_mask</span> <span class="o">=</span>      <span class="n">loss_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT-628"><a href="#Linear_CMT-628"><span class="linenos">628</span></a>
</span><span id="Linear_CMT-629"><a href="#Linear_CMT-629"><span class="linenos">629</span></a>        <span class="n">response_ids</span> <span class="o">=</span>              <span class="n">input_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT-630"><a href="#Linear_CMT-630"><span class="linenos">630</span></a>        <span class="n">response_attention_mask</span> <span class="o">=</span>   <span class="n">attention_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT-631"><a href="#Linear_CMT-631"><span class="linenos">631</span></a>        <span class="n">response_position_ids</span> <span class="o">=</span>     <span class="n">position_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT-632"><a href="#Linear_CMT-632"><span class="linenos">632</span></a>        <span class="n">response_loss_mask</span> <span class="o">=</span>        <span class="n">loss_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT-633"><a href="#Linear_CMT-633"><span class="linenos">633</span></a>
</span><span id="Linear_CMT-634"><a href="#Linear_CMT-634"><span class="linenos">634</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT-635"><a href="#Linear_CMT-635"><span class="linenos">635</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span>
</span><span id="Linear_CMT-636"><a href="#Linear_CMT-636"><span class="linenos">636</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_ids</span>
</span><span id="Linear_CMT-637"><a href="#Linear_CMT-637"><span class="linenos">637</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_ids</span>
</span><span id="Linear_CMT-638"><a href="#Linear_CMT-638"><span class="linenos">638</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>
</span><span id="Linear_CMT-639"><a href="#Linear_CMT-639"><span class="linenos">639</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_attention_mask</span>
</span><span id="Linear_CMT-640"><a href="#Linear_CMT-640"><span class="linenos">640</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_attention_mask</span>
</span><span id="Linear_CMT-641"><a href="#Linear_CMT-641"><span class="linenos">641</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_mask</span>
</span><span id="Linear_CMT-642"><a href="#Linear_CMT-642"><span class="linenos">642</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_loss_mask</span>
</span><span id="Linear_CMT-643"><a href="#Linear_CMT-643"><span class="linenos">643</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_loss_mask</span>
</span><span id="Linear_CMT-644"><a href="#Linear_CMT-644"><span class="linenos">644</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">position_ids</span>
</span><span id="Linear_CMT-645"><a href="#Linear_CMT-645"><span class="linenos">645</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_position_ids</span>
</span><span id="Linear_CMT-646"><a href="#Linear_CMT-646"><span class="linenos">646</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_position_ids</span>
</span><span id="Linear_CMT-647"><a href="#Linear_CMT-647"><span class="linenos">647</span></a>
</span><span id="Linear_CMT-648"><a href="#Linear_CMT-648"><span class="linenos">648</span></a>        <span class="k">return</span> <span class="n">cmt_tokenized</span>
</span></pre></div>


            <div class="docstring"><p>A linear context manager template that handles the conversation flow between LLM and environment.
This class manages the context window, tokenization, and message history in a linear fashion.</p>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>config:</strong>  Configuration object containing environment and model settings</li>
<li><strong>tokenizer:</strong>  Tokenizer instance for processing text</li>
<li><strong>full_context (List[ExtendedMessage]):</strong>  List of all messages in the conversation</li>
<li><strong>current_context_status (str):</strong>  Current status of the context</li>
<li><strong>max_seq_length (int):</strong>  Maximum sequence length for the context window</li>
<li><strong>max_env_output_length (int):</strong>  Maximum length for environment outputs</li>
<li><strong>terminal_rewards_dict (dict):</strong>  Dictionary storing terminal rewards</li>
</ul>
</div>


                            <div id="Linear_CMT.__init__" class="classattr">
                                        <input id="Linear_CMT.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">Linear_CMT</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">config</span>, </span><span class="param"><span class="n">tokenizer</span></span>)</span>

                <label class="view-source-button" for="Linear_CMT.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.__init__-34"><a href="#Linear_CMT.__init__-34"><span class="linenos">34</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
</span><span id="Linear_CMT.__init__-35"><a href="#Linear_CMT.__init__-35"><span class="linenos">35</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.__init__-36"><a href="#Linear_CMT.__init__-36"><span class="linenos">36</span></a><span class="sd">        Initializes the Linear_CMT class with the provided configuration and tokenizer.</span>
</span><span id="Linear_CMT.__init__-37"><a href="#Linear_CMT.__init__-37"><span class="linenos">37</span></a>
</span><span id="Linear_CMT.__init__-38"><a href="#Linear_CMT.__init__-38"><span class="linenos">38</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.__init__-39"><a href="#Linear_CMT.__init__-39"><span class="linenos">39</span></a><span class="sd">            config: Configuration object containing environment and model settings.</span>
</span><span id="Linear_CMT.__init__-40"><a href="#Linear_CMT.__init__-40"><span class="linenos">40</span></a><span class="sd">            tokenizer: Tokenizer instance for processing text.</span>
</span><span id="Linear_CMT.__init__-41"><a href="#Linear_CMT.__init__-41"><span class="linenos">41</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.__init__-42"><a href="#Linear_CMT.__init__-42"><span class="linenos">42</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="Linear_CMT.__init__-43"><a href="#Linear_CMT.__init__-43"><span class="linenos">43</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="Linear_CMT.__init__-44"><a href="#Linear_CMT.__init__-44"><span class="linenos">44</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="Linear_CMT.__init__-45"><a href="#Linear_CMT.__init__-45"><span class="linenos">45</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># ⭐ Initialize the list to store all messages in the conversation</span>
</span><span id="Linear_CMT.__init__-46"><a href="#Linear_CMT.__init__-46"><span class="linenos">46</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_context_status</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT.__init__-47"><a href="#Linear_CMT.__init__-47"><span class="linenos">47</span></a>        <span class="n">max_response_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">response_length</span>
</span><span id="Linear_CMT.__init__-48"><a href="#Linear_CMT.__init__-48"><span class="linenos">48</span></a>        <span class="n">max_model_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_model_len</span>
</span><span id="Linear_CMT.__init__-49"><a href="#Linear_CMT.__init__-49"><span class="linenos">49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">max_model_len</span> <span class="o">-</span> <span class="n">max_response_length</span>  <span class="c1"># ⭐ Calculate the maximum sequence length for the context window</span>
</span><span id="Linear_CMT.__init__-50"><a href="#Linear_CMT.__init__-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_len</span>
</span><span id="Linear_CMT.__init__-51"><a href="#Linear_CMT.__init__-51"><span class="linenos">51</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&lt;|im_start|&gt;assistant</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Linear_CMT.__init__-52"><a href="#Linear_CMT.__init__-52"><span class="linenos">52</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT.__init__-53"><a href="#Linear_CMT.__init__-53"><span class="linenos">53</span></a>
</span><span id="Linear_CMT.__init__-54"><a href="#Linear_CMT.__init__-54"><span class="linenos">54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">terminal_rewards_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT.__init__-55"><a href="#Linear_CMT.__init__-55"><span class="linenos">55</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">discarded</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="Linear_CMT.__init__-56"><a href="#Linear_CMT.__init__-56"><span class="linenos">56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_terminated</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="Linear_CMT.__init__-57"><a href="#Linear_CMT.__init__-57"><span class="linenos">57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Reward</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="Linear_CMT.__init__-58"><a href="#Linear_CMT.__init__-58"><span class="linenos">58</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">context_time_cost</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT.__init__-59"><a href="#Linear_CMT.__init__-59"><span class="linenos">59</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT.__init__-60"><a href="#Linear_CMT.__init__-60"><span class="linenos">60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="Linear_CMT.__init__-61"><a href="#Linear_CMT.__init__-61"><span class="linenos">61</span></a>        <span class="c1"># self.task_train_exp_mode: str = &quot;&quot;</span>
</span><span id="Linear_CMT.__init__-62"><a href="#Linear_CMT.__init__-62"><span class="linenos">62</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_batch_success_rate</span><span class="p">:</span><span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="Linear_CMT.__init__-63"><a href="#Linear_CMT.__init__-63"><span class="linenos">63</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT.__init__-64"><a href="#Linear_CMT.__init__-64"><span class="linenos">64</span></a>        <span class="c1"># self.experiences = []</span>
</span><span id="Linear_CMT.__init__-65"><a href="#Linear_CMT.__init__-65"><span class="linenos">65</span></a>
</span><span id="Linear_CMT.__init__-66"><a href="#Linear_CMT.__init__-66"><span class="linenos">66</span></a>        <span class="c1"># log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.rollout.log_prob_max_token_len_per_gpu</span>
</span><span id="Linear_CMT.__init__-67"><a href="#Linear_CMT.__init__-67"><span class="linenos">67</span></a>        <span class="c1"># ref_log_prob_max_token_len_per_gpu: int = self.config.actor_rollout_ref.ref.log_prob_max_token_len_per_gpu</span>
</span><span id="Linear_CMT.__init__-68"><a href="#Linear_CMT.__init__-68"><span class="linenos">68</span></a>        <span class="c1"># actor_ppo_max_token_len_per_gpu: int = self.config.actor_rollout_ref.actor.ppo_max_token_len_per_gpu</span>
</span><span id="Linear_CMT.__init__-69"><a href="#Linear_CMT.__init__-69"><span class="linenos">69</span></a>        <span class="c1"># critic_ppo_max_token_len_per_gpu: int = self.config.critic.ppo_max_token_len_per_gpu</span>
</span><span id="Linear_CMT.__init__-70"><a href="#Linear_CMT.__init__-70"><span class="linenos">70</span></a>        <span class="c1"># assert log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT.__init__-71"><a href="#Linear_CMT.__init__-71"><span class="linenos">71</span></a>        <span class="c1"># assert critic_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT.__init__-72"><a href="#Linear_CMT.__init__-72"><span class="linenos">72</span></a>        <span class="c1"># assert actor_ppo_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT.__init__-73"><a href="#Linear_CMT.__init__-73"><span class="linenos">73</span></a>        <span class="c1"># assert ref_log_prob_max_token_len_per_gpu &gt;= max_model_len</span>
</span><span id="Linear_CMT.__init__-74"><a href="#Linear_CMT.__init__-74"><span class="linenos">74</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">&lt;=</span> <span class="n">max_model_len</span>  <span class="c1"># ⭐ Ensure the sum of prompt and response lengths does not exceed the maximum model length</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the Linear_CMT class with the provided configuration and tokenizer.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>config:</strong>  Configuration object containing environment and model settings.</li>
<li><strong>tokenizer:</strong>  Tokenizer instance for processing text.</li>
</ul>
</div>


                            </div>
                            <div id="Linear_CMT.config" class="classattr">
                                <div class="attr variable">
            <span class="name">config</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.config"></a>
    
    

                            </div>
                            <div id="Linear_CMT.tokenizer" class="classattr">
                                <div class="attr variable">
            <span class="name">tokenizer</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.tokenizer"></a>
    
    

                            </div>
                            <div id="Linear_CMT.full_context" class="classattr">
                                <div class="attr variable">
            <span class="name">full_context</span><span class="annotation">: List[<a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a>]</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.full_context"></a>
    
    

                            </div>
                            <div id="Linear_CMT.current_context_status" class="classattr">
                                <div class="attr variable">
            <span class="name">current_context_status</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.current_context_status"></a>
    
    

                            </div>
                            <div id="Linear_CMT.max_seq_length" class="classattr">
                                <div class="attr variable">
            <span class="name">max_seq_length</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.max_seq_length"></a>
    
    

                            </div>
                            <div id="Linear_CMT.max_env_output_length" class="classattr">
                                <div class="attr variable">
            <span class="name">max_env_output_length</span><span class="annotation">: int</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.max_env_output_length"></a>
    
    

                            </div>
                            <div id="Linear_CMT.blackout_token_combo" class="classattr">
                                <div class="attr variable">
            <span class="name">blackout_token_combo</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.blackout_token_combo"></a>
    
    

                            </div>
                            <div id="Linear_CMT.generated_token_cnt" class="classattr">
                                <div class="attr variable">
            <span class="name">generated_token_cnt</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.generated_token_cnt"></a>
    
    

                            </div>
                            <div id="Linear_CMT.terminal_rewards_dict" class="classattr">
                                <div class="attr variable">
            <span class="name">terminal_rewards_dict</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.terminal_rewards_dict"></a>
    
    

                            </div>
                            <div id="Linear_CMT.discarded" class="classattr">
                                <div class="attr variable">
            <span class="name">discarded</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.discarded"></a>
    
    

                            </div>
                            <div id="Linear_CMT.is_terminated" class="classattr">
                                <div class="attr variable">
            <span class="name">is_terminated</span>        =
<span class="default_value">False</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.is_terminated"></a>
    
    

                            </div>
                            <div id="Linear_CMT.reward" class="classattr">
                                <div class="attr variable">
            <span class="name">reward</span><span class="annotation">: Optional[<a href="../../schema/trajectory.html#Reward">agentevolver.schema.trajectory.Reward</a>]</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.reward"></a>
    
    

                            </div>
                            <div id="Linear_CMT.context_time_cost" class="classattr">
                                <div class="attr variable">
            <span class="name">context_time_cost</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.context_time_cost"></a>
    
    

                            </div>
                            <div id="Linear_CMT.tag" class="classattr">
                                <div class="attr variable">
            <span class="name">tag</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.tag"></a>
    
    

                            </div>
                            <div id="Linear_CMT.task_id" class="classattr">
                                <div class="attr variable">
            <span class="name">task_id</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.task_id"></a>
    
    

                            </div>
                            <div id="Linear_CMT.current_batch_success_rate" class="classattr">
                                <div class="attr variable">
            <span class="name">current_batch_success_rate</span><span class="annotation">: float</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.current_batch_success_rate"></a>
    
    

                            </div>
                            <div id="Linear_CMT.llm_output_mistakes" class="classattr">
                                <div class="attr variable">
            <span class="name">llm_output_mistakes</span>

        
    </div>
    <a class="headerlink" href="#Linear_CMT.llm_output_mistakes"></a>
    
    

                            </div>
                            <div id="Linear_CMT.prepare_previous_context" class="classattr">
                                        <input id="Linear_CMT.prepare_previous_context-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_previous_context</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.prepare_previous_context-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.prepare_previous_context"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.prepare_previous_context-77"><a href="#Linear_CMT.prepare_previous_context-77"><span class="linenos"> 77</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_previous_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">):</span>
</span><span id="Linear_CMT.prepare_previous_context-78"><a href="#Linear_CMT.prepare_previous_context-78"><span class="linenos"> 78</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_previous_context-79"><a href="#Linear_CMT.prepare_previous_context-79"><span class="linenos"> 79</span></a><span class="sd">        Prepare the input context for a future LLM call.</span>
</span><span id="Linear_CMT.prepare_previous_context-80"><a href="#Linear_CMT.prepare_previous_context-80"><span class="linenos"> 80</span></a>
</span><span id="Linear_CMT.prepare_previous_context-81"><a href="#Linear_CMT.prepare_previous_context-81"><span class="linenos"> 81</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.prepare_previous_context-82"><a href="#Linear_CMT.prepare_previous_context-82"><span class="linenos"> 82</span></a><span class="sd">            mod (str, optional): The mode to format the context. Defaults to &#39;future&#39;.</span>
</span><span id="Linear_CMT.prepare_previous_context-83"><a href="#Linear_CMT.prepare_previous_context-83"><span class="linenos"> 83</span></a><span class="sd">                                 - &#39;future&#39;: Uses `content_for_future` for each message.</span>
</span><span id="Linear_CMT.prepare_previous_context-84"><a href="#Linear_CMT.prepare_previous_context-84"><span class="linenos"> 84</span></a><span class="sd">                                 - &#39;raw&#39;: Uses `content` for each message.</span>
</span><span id="Linear_CMT.prepare_previous_context-85"><a href="#Linear_CMT.prepare_previous_context-85"><span class="linenos"> 85</span></a>
</span><span id="Linear_CMT.prepare_previous_context-86"><a href="#Linear_CMT.prepare_previous_context-86"><span class="linenos"> 86</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.prepare_previous_context-87"><a href="#Linear_CMT.prepare_previous_context-87"><span class="linenos"> 87</span></a><span class="sd">            list: Array of message dictionaries containing role and content, formatted for LLM input.</span>
</span><span id="Linear_CMT.prepare_previous_context-88"><a href="#Linear_CMT.prepare_previous_context-88"><span class="linenos"> 88</span></a>
</span><span id="Linear_CMT.prepare_previous_context-89"><a href="#Linear_CMT.prepare_previous_context-89"><span class="linenos"> 89</span></a><span class="sd">        Raises:</span>
</span><span id="Linear_CMT.prepare_previous_context-90"><a href="#Linear_CMT.prepare_previous_context-90"><span class="linenos"> 90</span></a><span class="sd">            ValueError: If an unknown mode is provided.</span>
</span><span id="Linear_CMT.prepare_previous_context-91"><a href="#Linear_CMT.prepare_previous_context-91"><span class="linenos"> 91</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_previous_context-92"><a href="#Linear_CMT.prepare_previous_context-92"><span class="linenos"> 92</span></a>        <span class="k">if</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;future&#39;</span><span class="p">:</span>
</span><span id="Linear_CMT.prepare_previous_context-93"><a href="#Linear_CMT.prepare_previous_context-93"><span class="linenos"> 93</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="Linear_CMT.prepare_previous_context-94"><a href="#Linear_CMT.prepare_previous_context-94"><span class="linenos"> 94</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content_for_future</span>
</span><span id="Linear_CMT.prepare_previous_context-95"><a href="#Linear_CMT.prepare_previous_context-95"><span class="linenos"> 95</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT.prepare_previous_context-96"><a href="#Linear_CMT.prepare_previous_context-96"><span class="linenos"> 96</span></a>            <span class="p">]</span>
</span><span id="Linear_CMT.prepare_previous_context-97"><a href="#Linear_CMT.prepare_previous_context-97"><span class="linenos"> 97</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="Linear_CMT.prepare_previous_context-98"><a href="#Linear_CMT.prepare_previous_context-98"><span class="linenos"> 98</span></a>
</span><span id="Linear_CMT.prepare_previous_context-99"><a href="#Linear_CMT.prepare_previous_context-99"><span class="linenos"> 99</span></a>        <span class="k">elif</span> <span class="n">mod</span> <span class="o">==</span> <span class="s1">&#39;raw&#39;</span><span class="p">:</span>
</span><span id="Linear_CMT.prepare_previous_context-100"><a href="#Linear_CMT.prepare_previous_context-100"><span class="linenos">100</span></a>            <span class="n">message_arr</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="Linear_CMT.prepare_previous_context-101"><a href="#Linear_CMT.prepare_previous_context-101"><span class="linenos">101</span></a>                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">c</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>  <span class="c1"># ⭐ Format message with content</span>
</span><span id="Linear_CMT.prepare_previous_context-102"><a href="#Linear_CMT.prepare_previous_context-102"><span class="linenos">102</span></a>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT.prepare_previous_context-103"><a href="#Linear_CMT.prepare_previous_context-103"><span class="linenos">103</span></a>            <span class="p">]</span>
</span><span id="Linear_CMT.prepare_previous_context-104"><a href="#Linear_CMT.prepare_previous_context-104"><span class="linenos">104</span></a>            <span class="k">return</span> <span class="n">message_arr</span>
</span><span id="Linear_CMT.prepare_previous_context-105"><a href="#Linear_CMT.prepare_previous_context-105"><span class="linenos">105</span></a>
</span><span id="Linear_CMT.prepare_previous_context-106"><a href="#Linear_CMT.prepare_previous_context-106"><span class="linenos">106</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="Linear_CMT.prepare_previous_context-107"><a href="#Linear_CMT.prepare_previous_context-107"><span class="linenos">107</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown mod </span><span class="si">{</span><span class="n">mod</span><span class="si">}</span><span class="s2"> in prepare_previous_context, only support &#39;future&#39; and &#39;raw&#39;&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Prepare the input context for a future LLM call.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>mod (str, optional):</strong>  The mode to format the context. Defaults to 'future'.
<ul>
<li>'future': Uses <code>content_for_future</code> for each message.</li>
<li>'raw': Uses <code>content</code> for each message.</li>
</ul></li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>list: Array of message dictionaries containing role and content, formatted for LLM input.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If an unknown mode is provided.</li>
</ul>
</div>


                            </div>
                            <div id="Linear_CMT.check_context_token_num_safe" class="classattr">
                                        <input id="Linear_CMT.check_context_token_num_safe-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">check_context_token_num_safe</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.check_context_token_num_safe-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.check_context_token_num_safe"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.check_context_token_num_safe-110"><a href="#Linear_CMT.check_context_token_num_safe-110"><span class="linenos">110</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">check_context_token_num_safe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
</span><span id="Linear_CMT.check_context_token_num_safe-111"><a href="#Linear_CMT.check_context_token_num_safe-111"><span class="linenos">111</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.check_context_token_num_safe-112"><a href="#Linear_CMT.check_context_token_num_safe-112"><span class="linenos">112</span></a><span class="sd">        Checks if the total number of tokens in the prepared context messages is within a safe limit.</span>
</span><span id="Linear_CMT.check_context_token_num_safe-113"><a href="#Linear_CMT.check_context_token_num_safe-113"><span class="linenos">113</span></a>
</span><span id="Linear_CMT.check_context_token_num_safe-114"><a href="#Linear_CMT.check_context_token_num_safe-114"><span class="linenos">114</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.check_context_token_num_safe-115"><a href="#Linear_CMT.check_context_token_num_safe-115"><span class="linenos">115</span></a><span class="sd">            messages (List[dict]): A list of message dictionaries to be checked.</span>
</span><span id="Linear_CMT.check_context_token_num_safe-116"><a href="#Linear_CMT.check_context_token_num_safe-116"><span class="linenos">116</span></a>
</span><span id="Linear_CMT.check_context_token_num_safe-117"><a href="#Linear_CMT.check_context_token_num_safe-117"><span class="linenos">117</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.check_context_token_num_safe-118"><a href="#Linear_CMT.check_context_token_num_safe-118"><span class="linenos">118</span></a><span class="sd">            bool: True if the total number of tokens is less than the maximum allowed sequence length, False otherwise.</span>
</span><span id="Linear_CMT.check_context_token_num_safe-119"><a href="#Linear_CMT.check_context_token_num_safe-119"><span class="linenos">119</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.check_context_token_num_safe-120"><a href="#Linear_CMT.check_context_token_num_safe-120"><span class="linenos">120</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">):</span>
</span><span id="Linear_CMT.check_context_token_num_safe-121"><a href="#Linear_CMT.check_context_token_num_safe-121"><span class="linenos">121</span></a>            <span class="n">prompt_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="Linear_CMT.check_context_token_num_safe-122"><a href="#Linear_CMT.check_context_token_num_safe-122"><span class="linenos">122</span></a>            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the total number of tokens in the messages</span>
</span><span id="Linear_CMT.check_context_token_num_safe-123"><a href="#Linear_CMT.check_context_token_num_safe-123"><span class="linenos">123</span></a>        <span class="n">messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">)</span>
</span><span id="Linear_CMT.check_context_token_num_safe-124"><a href="#Linear_CMT.check_context_token_num_safe-124"><span class="linenos">124</span></a>        <span class="k">return</span> <span class="n">get_seq_length</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_length</span>   <span class="c1"># self.config.env_engine.max_seq_length = 20480</span>
</span></pre></div>


            <div class="docstring"><p>Checks if the total number of tokens in the prepared context messages is within a safe limit.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>messages (List[dict]):</strong>  A list of message dictionaries to be checked.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>bool: True if the total number of tokens is less than the maximum allowed sequence length, False otherwise.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.get_inc" class="classattr">
                                        <input id="Linear_CMT.get_inc-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_inc</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">text_frag_from</span>, </span><span class="param"><span class="n">text_frag_to</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.get_inc-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.get_inc"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.get_inc-127"><a href="#Linear_CMT.get_inc-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_inc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_frag_from</span><span class="p">,</span> <span class="n">text_frag_to</span><span class="p">):</span>
</span><span id="Linear_CMT.get_inc-128"><a href="#Linear_CMT.get_inc-128"><span class="linenos">128</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.get_inc-129"><a href="#Linear_CMT.get_inc-129"><span class="linenos">129</span></a><span class="sd">        Get the incremental token array from text_frag_from to text_frag_to.</span>
</span><span id="Linear_CMT.get_inc-130"><a href="#Linear_CMT.get_inc-130"><span class="linenos">130</span></a>
</span><span id="Linear_CMT.get_inc-131"><a href="#Linear_CMT.get_inc-131"><span class="linenos">131</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.get_inc-132"><a href="#Linear_CMT.get_inc-132"><span class="linenos">132</span></a><span class="sd">            text_frag_from (str): The starting text fragment.</span>
</span><span id="Linear_CMT.get_inc-133"><a href="#Linear_CMT.get_inc-133"><span class="linenos">133</span></a><span class="sd">            text_frag_to (str): The ending text fragment.</span>
</span><span id="Linear_CMT.get_inc-134"><a href="#Linear_CMT.get_inc-134"><span class="linenos">134</span></a>
</span><span id="Linear_CMT.get_inc-135"><a href="#Linear_CMT.get_inc-135"><span class="linenos">135</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.get_inc-136"><a href="#Linear_CMT.get_inc-136"><span class="linenos">136</span></a><span class="sd">            Tuple[List[int], str]: A tuple containing the list of incremental token IDs and a message with token length details.</span>
</span><span id="Linear_CMT.get_inc-137"><a href="#Linear_CMT.get_inc-137"><span class="linenos">137</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.get_inc-138"><a href="#Linear_CMT.get_inc-138"><span class="linenos">138</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_from</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT.get_inc-139"><a href="#Linear_CMT.get_inc-139"><span class="linenos">139</span></a>        <span class="n">tokenizer_input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT.get_inc-140"><a href="#Linear_CMT.get_inc-140"><span class="linenos">140</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="n">tokenizer_input_ids</span>
</span><span id="Linear_CMT.get_inc-141"><a href="#Linear_CMT.get_inc-141"><span class="linenos">141</span></a>
</span><span id="Linear_CMT.get_inc-142"><a href="#Linear_CMT.get_inc-142"><span class="linenos">142</span></a>        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_frag_to</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT.get_inc-143"><a href="#Linear_CMT.get_inc-143"><span class="linenos">143</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT.get_inc-144"><a href="#Linear_CMT.get_inc-144"><span class="linenos">144</span></a>        <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># ⭐ Get the new tokens added in this step</span>
</span><span id="Linear_CMT.get_inc-145"><a href="#Linear_CMT.get_inc-145"><span class="linenos">145</span></a>        <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT.get_inc-146"><a href="#Linear_CMT.get_inc-146"><span class="linenos">146</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="Linear_CMT.get_inc-147"><a href="#Linear_CMT.get_inc-147"><span class="linenos">147</span></a>            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Linear_CMT.get_inc-148"><a href="#Linear_CMT.get_inc-148"><span class="linenos">148</span></a>            <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="Linear_CMT.get_inc-149"><a href="#Linear_CMT.get_inc-149"><span class="linenos">149</span></a>        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="Linear_CMT.get_inc-150"><a href="#Linear_CMT.get_inc-150"><span class="linenos">150</span></a>        <span class="c1"># print(msg)</span>
</span><span id="Linear_CMT.get_inc-151"><a href="#Linear_CMT.get_inc-151"><span class="linenos">151</span></a>        <span class="k">return</span> <span class="n">input_id_increment</span><span class="p">,</span> <span class="n">msg</span>
</span></pre></div>


            <div class="docstring"><p>Get the incremental token array from text_frag_from to text_frag_to.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>text_frag_from (str):</strong>  The starting text fragment.</li>
<li><strong>text_frag_to (str):</strong>  The ending text fragment.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Tuple[List[int], str]: A tuple containing the list of incremental token IDs and a message with token length details.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.remove_last_context" class="classattr">
                                        <input id="Linear_CMT.remove_last_context-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">remove_last_context</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.remove_last_context-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.remove_last_context"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.remove_last_context-153"><a href="#Linear_CMT.remove_last_context-153"><span class="linenos">153</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.remove_last_context-154"><a href="#Linear_CMT.remove_last_context-154"><span class="linenos">154</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.remove_last_context-155"><a href="#Linear_CMT.remove_last_context-155"><span class="linenos">155</span></a><span class="sd">        Removes the last message from the full context if it is not authored by the language model.</span>
</span><span id="Linear_CMT.remove_last_context-156"><a href="#Linear_CMT.remove_last_context-156"><span class="linenos">156</span></a>
</span><span id="Linear_CMT.remove_last_context-157"><a href="#Linear_CMT.remove_last_context-157"><span class="linenos">157</span></a><span class="sd">        This method checks the author of the last message in the `full_context` list. If the author is not &quot;llm&quot;,</span>
</span><span id="Linear_CMT.remove_last_context-158"><a href="#Linear_CMT.remove_last_context-158"><span class="linenos">158</span></a><span class="sd">        the last message is removed from the context. This is useful for managing the conversation history and</span>
</span><span id="Linear_CMT.remove_last_context-159"><a href="#Linear_CMT.remove_last_context-159"><span class="linenos">159</span></a><span class="sd">        ensuring that only relevant messages are kept in the context.</span>
</span><span id="Linear_CMT.remove_last_context-160"><a href="#Linear_CMT.remove_last_context-160"><span class="linenos">160</span></a>
</span><span id="Linear_CMT.remove_last_context-161"><a href="#Linear_CMT.remove_last_context-161"><span class="linenos">161</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.remove_last_context-162"><a href="#Linear_CMT.remove_last_context-162"><span class="linenos">162</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT.remove_last_context-163"><a href="#Linear_CMT.remove_last_context-163"><span class="linenos">163</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.remove_last_context-164"><a href="#Linear_CMT.remove_last_context-164"><span class="linenos">164</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># ⭐ Check if there are any messages in the context</span>
</span><span id="Linear_CMT.remove_last_context-165"><a href="#Linear_CMT.remove_last_context-165"><span class="linenos">165</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>  <span class="c1"># ⭐ Ensure the last message is not from the language model</span>
</span><span id="Linear_CMT.remove_last_context-166"><a href="#Linear_CMT.remove_last_context-166"><span class="linenos">166</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message from the context</span>
</span></pre></div>


            <div class="docstring"><p>Removes the last message from the full context if it is not authored by the language model.</p>

<p>This method checks the author of the last message in the <code><a href="#Linear_CMT.full_context">full_context</a></code> list. If the author is not "llm",
the last message is removed from the context. This is useful for managing the conversation history and
ensuring that only relevant messages are kept in the context.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.remove_last_non_llm_msg" class="classattr">
                                        <input id="Linear_CMT.remove_last_non_llm_msg-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">remove_last_non_llm_msg</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">ext_msg_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a></span><span class="p">]</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.remove_last_non_llm_msg-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.remove_last_non_llm_msg"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.remove_last_non_llm_msg-168"><a href="#Linear_CMT.remove_last_non_llm_msg-168"><span class="linenos">168</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">remove_last_non_llm_msg</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_list</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]):</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-169"><a href="#Linear_CMT.remove_last_non_llm_msg-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-170"><a href="#Linear_CMT.remove_last_non_llm_msg-170"><span class="linenos">170</span></a><span class="sd">        Removes the last message from the list if it is not authored by the language model (llm).</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-171"><a href="#Linear_CMT.remove_last_non_llm_msg-171"><span class="linenos">171</span></a>
</span><span id="Linear_CMT.remove_last_non_llm_msg-172"><a href="#Linear_CMT.remove_last_non_llm_msg-172"><span class="linenos">172</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-173"><a href="#Linear_CMT.remove_last_non_llm_msg-173"><span class="linenos">173</span></a><span class="sd">            ext_msg_list (List[ExtendedMessage]): The list of ExtendedMessage objects representing the conversation history.</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-174"><a href="#Linear_CMT.remove_last_non_llm_msg-174"><span class="linenos">174</span></a>
</span><span id="Linear_CMT.remove_last_non_llm_msg-175"><a href="#Linear_CMT.remove_last_non_llm_msg-175"><span class="linenos">175</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-176"><a href="#Linear_CMT.remove_last_non_llm_msg-176"><span class="linenos">176</span></a><span class="sd">            List[ExtendedMessage]: The updated list of ExtendedMessage objects with the last non-llm message removed if applicable.</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-177"><a href="#Linear_CMT.remove_last_non_llm_msg-177"><span class="linenos">177</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-178"><a href="#Linear_CMT.remove_last_non_llm_msg-178"><span class="linenos">178</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-179"><a href="#Linear_CMT.remove_last_non_llm_msg-179"><span class="linenos">179</span></a>            <span class="k">if</span> <span class="n">ext_msg_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">author</span> <span class="o">!=</span> <span class="s2">&quot;llm&quot;</span><span class="p">:</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-180"><a href="#Linear_CMT.remove_last_non_llm_msg-180"><span class="linenos">180</span></a>                <span class="n">ext_msg_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ⭐ Remove the last message if it is not from the llm</span>
</span><span id="Linear_CMT.remove_last_non_llm_msg-181"><a href="#Linear_CMT.remove_last_non_llm_msg-181"><span class="linenos">181</span></a>        <span class="k">return</span> <span class="n">ext_msg_list</span>
</span></pre></div>


            <div class="docstring"><p>Removes the last message from the list if it is not authored by the language model (llm).</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>ext_msg_list (List[ExtendedMessage]):</strong>  The list of ExtendedMessage objects representing the conversation history.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>List[ExtendedMessage]: The updated list of ExtendedMessage objects with the last non-llm message removed if applicable.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.steps" class="classattr">
                                        <input id="Linear_CMT.steps-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">steps</span>

                <label class="view-source-button" for="Linear_CMT.steps-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.steps"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.steps-185"><a href="#Linear_CMT.steps-185"><span class="linenos">185</span></a>    <span class="nd">@property</span>
</span><span id="Linear_CMT.steps-186"><a href="#Linear_CMT.steps-186"><span class="linenos">186</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">steps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.steps-187"><a href="#Linear_CMT.steps-187"><span class="linenos">187</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.steps-188"><a href="#Linear_CMT.steps-188"><span class="linenos">188</span></a><span class="sd">        Returns the prepared previous context with the mode set to &#39;future&#39;.</span>
</span><span id="Linear_CMT.steps-189"><a href="#Linear_CMT.steps-189"><span class="linenos">189</span></a>
</span><span id="Linear_CMT.steps-190"><a href="#Linear_CMT.steps-190"><span class="linenos">190</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.steps-191"><a href="#Linear_CMT.steps-191"><span class="linenos">191</span></a><span class="sd">            dict: The prepared previous context.</span>
</span><span id="Linear_CMT.steps-192"><a href="#Linear_CMT.steps-192"><span class="linenos">192</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.steps-193"><a href="#Linear_CMT.steps-193"><span class="linenos">193</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Get the prepared context in &#39;future&#39; mode</span>
</span></pre></div>


            <div class="docstring"><p>Returns the prepared previous context with the mode set to 'future'.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>dict: The prepared previous context.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.json" class="classattr">
                                        <input id="Linear_CMT.json-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">json</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.json-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.json"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.json-195"><a href="#Linear_CMT.json-195"><span class="linenos">195</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">json</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.json-196"><a href="#Linear_CMT.json-196"><span class="linenos">196</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.json-197"><a href="#Linear_CMT.json-197"><span class="linenos">197</span></a><span class="sd">        Converts the prepared previous context (with the mode set to &#39;future&#39;) into a JSON-formatted string.</span>
</span><span id="Linear_CMT.json-198"><a href="#Linear_CMT.json-198"><span class="linenos">198</span></a>
</span><span id="Linear_CMT.json-199"><a href="#Linear_CMT.json-199"><span class="linenos">199</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.json-200"><a href="#Linear_CMT.json-200"><span class="linenos">200</span></a><span class="sd">            str: A JSON-formatted string of the prepared previous context.</span>
</span><span id="Linear_CMT.json-201"><a href="#Linear_CMT.json-201"><span class="linenos">201</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.json-202"><a href="#Linear_CMT.json-202"><span class="linenos">202</span></a>        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">),</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># ⭐ Convert the context to a JSON string</span>
</span></pre></div>


            <div class="docstring"><p>Converts the prepared previous context (with the mode set to 'future') into a JSON-formatted string.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>str: A JSON-formatted string of the prepared previous context.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.prepare_next_llm_context" class="classattr">
                                        <input id="Linear_CMT.prepare_next_llm_context-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_next_llm_context</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.prepare_next_llm_context-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.prepare_next_llm_context"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.prepare_next_llm_context-204"><a href="#Linear_CMT.prepare_next_llm_context-204"><span class="linenos">204</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_next_llm_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.prepare_next_llm_context-205"><a href="#Linear_CMT.prepare_next_llm_context-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_next_llm_context-206"><a href="#Linear_CMT.prepare_next_llm_context-206"><span class="linenos">206</span></a><span class="sd">        Prepares the context for the next LLM (Language Model) interaction.</span>
</span><span id="Linear_CMT.prepare_next_llm_context-207"><a href="#Linear_CMT.prepare_next_llm_context-207"><span class="linenos">207</span></a>
</span><span id="Linear_CMT.prepare_next_llm_context-208"><a href="#Linear_CMT.prepare_next_llm_context-208"><span class="linenos">208</span></a><span class="sd">        This function calls `prepare_previous_context` with the &#39;future&#39; mode to set up the context.</span>
</span><span id="Linear_CMT.prepare_next_llm_context-209"><a href="#Linear_CMT.prepare_next_llm_context-209"><span class="linenos">209</span></a>
</span><span id="Linear_CMT.prepare_next_llm_context-210"><a href="#Linear_CMT.prepare_next_llm_context-210"><span class="linenos">210</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.prepare_next_llm_context-211"><a href="#Linear_CMT.prepare_next_llm_context-211"><span class="linenos">211</span></a><span class="sd">            The result of the `prepare_previous_context` function call.</span>
</span><span id="Linear_CMT.prepare_next_llm_context-212"><a href="#Linear_CMT.prepare_next_llm_context-212"><span class="linenos">212</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_next_llm_context-213"><a href="#Linear_CMT.prepare_next_llm_context-213"><span class="linenos">213</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_previous_context</span><span class="p">(</span><span class="n">mod</span><span class="o">=</span><span class="s1">&#39;future&#39;</span><span class="p">)</span>  <span class="c1"># ⭐ Prepares the context for the next LLM interaction</span>
</span></pre></div>


            <div class="docstring"><p>Prepares the context for the next LLM (Language Model) interaction.</p>

<p>This function calls <code><a href="#Linear_CMT.prepare_previous_context">prepare_previous_context</a></code> with the 'future' mode to set up the context.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The result of the <code><a href="#Linear_CMT.prepare_previous_context">prepare_previous_context</a></code> function call.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.save_init_input" class="classattr">
                                        <input id="Linear_CMT.save_init_input-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_init_input</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">init_input_arr</span><span class="p">:</span> <span class="nb">list</span>, </span><span class="param"><span class="n">add_nothink</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.save_init_input-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.save_init_input"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.save_init_input-216"><a href="#Linear_CMT.save_init_input-216"><span class="linenos">216</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_init_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_input_arr</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">add_nothink</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="Linear_CMT.save_init_input-217"><a href="#Linear_CMT.save_init_input-217"><span class="linenos">217</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_init_input-218"><a href="#Linear_CMT.save_init_input-218"><span class="linenos">218</span></a><span class="sd">        Save and process the initial input messages to the context.</span>
</span><span id="Linear_CMT.save_init_input-219"><a href="#Linear_CMT.save_init_input-219"><span class="linenos">219</span></a>
</span><span id="Linear_CMT.save_init_input-220"><a href="#Linear_CMT.save_init_input-220"><span class="linenos">220</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.save_init_input-221"><a href="#Linear_CMT.save_init_input-221"><span class="linenos">221</span></a><span class="sd">            init_input_arr (list): Array of initial input messages to be processed</span>
</span><span id="Linear_CMT.save_init_input-222"><a href="#Linear_CMT.save_init_input-222"><span class="linenos">222</span></a><span class="sd">                                  Each message should be a dict with &#39;role&#39; and &#39;content&#39;</span>
</span><span id="Linear_CMT.save_init_input-223"><a href="#Linear_CMT.save_init_input-223"><span class="linenos">223</span></a><span class="sd">            add_nothink (bool, optional): If True, appends &quot;/no_think&quot; to the last message&#39;s content. Defaults to False.</span>
</span><span id="Linear_CMT.save_init_input-224"><a href="#Linear_CMT.save_init_input-224"><span class="linenos">224</span></a>
</span><span id="Linear_CMT.save_init_input-225"><a href="#Linear_CMT.save_init_input-225"><span class="linenos">225</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT.save_init_input-226"><a href="#Linear_CMT.save_init_input-226"><span class="linenos">226</span></a><span class="sd">            - Initializes the context with the provided messages</span>
</span><span id="Linear_CMT.save_init_input-227"><a href="#Linear_CMT.save_init_input-227"><span class="linenos">227</span></a><span class="sd">            - Computes token arrays for each message</span>
</span><span id="Linear_CMT.save_init_input-228"><a href="#Linear_CMT.save_init_input-228"><span class="linenos">228</span></a><span class="sd">            - Validates that the context is empty before saving</span>
</span><span id="Linear_CMT.save_init_input-229"><a href="#Linear_CMT.save_init_input-229"><span class="linenos">229</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_init_input-230"><a href="#Linear_CMT.save_init_input-230"><span class="linenos">230</span></a>        <span class="c1"># save basic</span>
</span><span id="Linear_CMT.save_init_input-231"><a href="#Linear_CMT.save_init_input-231"><span class="linenos">231</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;full_context should be empty when saving init input&quot;</span>
</span><span id="Linear_CMT.save_init_input-232"><a href="#Linear_CMT.save_init_input-232"><span class="linenos">232</span></a>        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">llm_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">):</span>
</span><span id="Linear_CMT.save_init_input-233"><a href="#Linear_CMT.save_init_input-233"><span class="linenos">233</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="Linear_CMT.save_init_input-234"><a href="#Linear_CMT.save_init_input-234"><span class="linenos">234</span></a>                <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="Linear_CMT.save_init_input-235"><a href="#Linear_CMT.save_init_input-235"><span class="linenos">235</span></a>                    <span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">/no_think&quot;</span>
</span><span id="Linear_CMT.save_init_input-236"><a href="#Linear_CMT.save_init_input-236"><span class="linenos">236</span></a>            <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT.save_init_input-237"><a href="#Linear_CMT.save_init_input-237"><span class="linenos">237</span></a>                <span class="n">author</span><span class="o">=</span><span class="s2">&quot;initialization&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_init_input-238"><a href="#Linear_CMT.save_init_input-238"><span class="linenos">238</span></a>                <span class="n">role</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.save_init_input-239"><a href="#Linear_CMT.save_init_input-239"><span class="linenos">239</span></a>                <span class="n">content</span><span class="o">=</span><span class="n">llm_msg</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.save_init_input-240"><a href="#Linear_CMT.save_init_input-240"><span class="linenos">240</span></a>                <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;manual&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_init_input-241"><a href="#Linear_CMT.save_init_input-241"><span class="linenos">241</span></a>                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT.save_init_input-242"><a href="#Linear_CMT.save_init_input-242"><span class="linenos">242</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT.save_init_input-243"><a href="#Linear_CMT.save_init_input-243"><span class="linenos">243</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Adds the extended message to the full context</span>
</span><span id="Linear_CMT.save_init_input-244"><a href="#Linear_CMT.save_init_input-244"><span class="linenos">244</span></a>
</span><span id="Linear_CMT.save_init_input-245"><a href="#Linear_CMT.save_init_input-245"><span class="linenos">245</span></a>        <span class="c1"># compute token array for each message</span>
</span><span id="Linear_CMT.save_init_input-246"><a href="#Linear_CMT.save_init_input-246"><span class="linenos">246</span></a>        <span class="n">token_ids_acc</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT.save_init_input-247"><a href="#Linear_CMT.save_init_input-247"><span class="linenos">247</span></a>        <span class="k">for</span> <span class="n">llm_msg</span><span class="p">,</span> <span class="n">ext_msg</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">))):</span>
</span><span id="Linear_CMT.save_init_input-248"><a href="#Linear_CMT.save_init_input-248"><span class="linenos">248</span></a>            <span class="n">text_with_chat_template</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">init_input_arr</span><span class="p">[:(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT.save_init_input-249"><a href="#Linear_CMT.save_init_input-249"><span class="linenos">249</span></a>            <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_with_chat_template</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="Linear_CMT.save_init_input-250"><a href="#Linear_CMT.save_init_input-250"><span class="linenos">250</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer_output</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="Linear_CMT.save_init_input-251"><a href="#Linear_CMT.save_init_input-251"><span class="linenos">251</span></a>            <span class="c1"># attention_mask = outputs[&quot;attention_mask&quot;][0].tolist()</span>
</span><span id="Linear_CMT.save_init_input-252"><a href="#Linear_CMT.save_init_input-252"><span class="linenos">252</span></a>            <span class="n">input_id_increment</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">):]</span>  <span class="c1"># get the new tokens added in this step</span>
</span><span id="Linear_CMT.save_init_input-253"><a href="#Linear_CMT.save_init_input-253"><span class="linenos">253</span></a>            <span class="n">overlap_length</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT.save_init_input-254"><a href="#Linear_CMT.save_init_input-254"><span class="linenos">254</span></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)):</span>
</span><span id="Linear_CMT.save_init_input-255"><a href="#Linear_CMT.save_init_input-255"><span class="linenos">255</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">token_ids_acc</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span> <span class="n">overlap_length</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Linear_CMT.save_init_input-256"><a href="#Linear_CMT.save_init_input-256"><span class="linenos">256</span></a>                <span class="k">else</span><span class="p">:</span> <span class="k">break</span>
</span><span id="Linear_CMT.save_init_input-257"><a href="#Linear_CMT.save_init_input-257"><span class="linenos">257</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;previous token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">token_ids_acc</span><span class="p">)</span><span class="si">}</span><span class="s2">, overlap token length: </span><span class="si">{</span><span class="p">(</span><span class="n">overlap_length</span><span class="p">)</span><span class="si">}</span><span class="s2">, increment token length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_increment</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="Linear_CMT.save_init_input-258"><a href="#Linear_CMT.save_init_input-258"><span class="linenos">258</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">input_id_increment</span>  <span class="c1"># ⭐ Sets the token array for the extended message</span>
</span><span id="Linear_CMT.save_init_input-259"><a href="#Linear_CMT.save_init_input-259"><span class="linenos">259</span></a>            <span class="n">token_ids_acc</span> <span class="o">+=</span> <span class="n">input_ids</span>
</span><span id="Linear_CMT.save_init_input-260"><a href="#Linear_CMT.save_init_input-260"><span class="linenos">260</span></a>        <span class="k">return</span>
</span></pre></div>


            <div class="docstring"><p>Save and process the initial input messages to the context.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>init_input_arr (list):</strong>  Array of initial input messages to be processed
Each message should be a dict with 'role' and 'content'</li>
<li><strong>add_nothink (bool, optional):</strong>  If True, appends "/no_think" to the last message's content. Defaults to False.</li>
</ul>

<h6 id="note">Note:</h6>

<blockquote>
  <ul>
  <li>Initializes the context with the provided messages</li>
  <li>Computes token arrays for each message</li>
  <li>Validates that the context is empty before saving</li>
  </ul>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.influence_extra_reward" class="classattr">
                                        <input id="Linear_CMT.influence_extra_reward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">influence_extra_reward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">llm_output</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.influence_extra_reward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.influence_extra_reward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.influence_extra_reward-262"><a href="#Linear_CMT.influence_extra_reward-262"><span class="linenos">262</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">influence_extra_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">):</span>
</span><span id="Linear_CMT.influence_extra_reward-263"><a href="#Linear_CMT.influence_extra_reward-263"><span class="linenos">263</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.influence_extra_reward-264"><a href="#Linear_CMT.influence_extra_reward-264"><span class="linenos">264</span></a><span class="sd">        Evaluates the LLM output for repetition and applies a penalty reward.</span>
</span><span id="Linear_CMT.influence_extra_reward-265"><a href="#Linear_CMT.influence_extra_reward-265"><span class="linenos">265</span></a><span class="sd">        The penalty is logged if non-zero, and the minimum penalty value is stored in the mistakes dictionary.</span>
</span><span id="Linear_CMT.influence_extra_reward-266"><a href="#Linear_CMT.influence_extra_reward-266"><span class="linenos">266</span></a>
</span><span id="Linear_CMT.influence_extra_reward-267"><a href="#Linear_CMT.influence_extra_reward-267"><span class="linenos">267</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.influence_extra_reward-268"><a href="#Linear_CMT.influence_extra_reward-268"><span class="linenos">268</span></a><span class="sd">            llm_output (dict): The output from the language model, expected to contain a &#39;content&#39; key.</span>
</span><span id="Linear_CMT.influence_extra_reward-269"><a href="#Linear_CMT.influence_extra_reward-269"><span class="linenos">269</span></a>
</span><span id="Linear_CMT.influence_extra_reward-270"><a href="#Linear_CMT.influence_extra_reward-270"><span class="linenos">270</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.influence_extra_reward-271"><a href="#Linear_CMT.influence_extra_reward-271"><span class="linenos">271</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT.influence_extra_reward-272"><a href="#Linear_CMT.influence_extra_reward-272"><span class="linenos">272</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.influence_extra_reward-273"><a href="#Linear_CMT.influence_extra_reward-273"><span class="linenos">273</span></a>        <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">=</span> <span class="n">repetition_penalty_reward_scalar</span><span class="p">(</span><span class="n">completion</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the repetition penalty reward</span>
</span><span id="Linear_CMT.influence_extra_reward-274"><a href="#Linear_CMT.influence_extra_reward-274"><span class="linenos">274</span></a>        <span class="k">if</span> <span class="n">this_msg_repetition_penalty_reward</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="Linear_CMT.influence_extra_reward-275"><a href="#Linear_CMT.influence_extra_reward-275"><span class="linenos">275</span></a>            <span class="n">print_dict</span><span class="p">({</span>
</span><span id="Linear_CMT.influence_extra_reward-276"><a href="#Linear_CMT.influence_extra_reward-276"><span class="linenos">276</span></a>                <span class="s2">&quot;reason&quot;</span><span class="p">:</span> <span class="s2">&quot;repetition_penalty_reward&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.influence_extra_reward-277"><a href="#Linear_CMT.influence_extra_reward-277"><span class="linenos">277</span></a>                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.influence_extra_reward-278"><a href="#Linear_CMT.influence_extra_reward-278"><span class="linenos">278</span></a>                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span>
</span><span id="Linear_CMT.influence_extra_reward-279"><a href="#Linear_CMT.influence_extra_reward-279"><span class="linenos">279</span></a>            <span class="p">})</span>
</span><span id="Linear_CMT.influence_extra_reward-280"><a href="#Linear_CMT.influence_extra_reward-280"><span class="linenos">280</span></a>        <span class="k">if</span> <span class="s1">&#39;repetition_penalty_reward&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">:</span>
</span><span id="Linear_CMT.influence_extra_reward-281"><a href="#Linear_CMT.influence_extra_reward-281"><span class="linenos">281</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Linear_CMT.influence_extra_reward-282"><a href="#Linear_CMT.influence_extra_reward-282"><span class="linenos">282</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">this_msg_repetition_penalty_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="p">[</span><span class="s1">&#39;repetition_penalty_reward&#39;</span><span class="p">])</span>  <span class="c1"># ⭐ Update the mistakes dictionary with the minimum penalty</span>
</span></pre></div>


            <div class="docstring"><p>Evaluates the LLM output for repetition and applies a penalty reward.
The penalty is logged if non-zero, and the minimum penalty value is stored in the mistakes dictionary.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>llm_output (dict):</strong>  The output from the language model, expected to contain a 'content' key.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.save_llm_output" class="classattr">
                                        <input id="Linear_CMT.save_llm_output-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_llm_output</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">llm_output</span>, </span><span class="param"><span class="n">input_msg_ref</span>, </span><span class="param"><span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">True</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.save_llm_output-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.save_llm_output"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.save_llm_output-284"><a href="#Linear_CMT.save_llm_output-284"><span class="linenos">284</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="Linear_CMT.save_llm_output-285"><a href="#Linear_CMT.save_llm_output-285"><span class="linenos">285</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_llm_output-286"><a href="#Linear_CMT.save_llm_output-286"><span class="linenos">286</span></a><span class="sd">        Save the output from the LLM to the full context.</span>
</span><span id="Linear_CMT.save_llm_output-287"><a href="#Linear_CMT.save_llm_output-287"><span class="linenos">287</span></a>
</span><span id="Linear_CMT.save_llm_output-288"><a href="#Linear_CMT.save_llm_output-288"><span class="linenos">288</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.save_llm_output-289"><a href="#Linear_CMT.save_llm_output-289"><span class="linenos">289</span></a><span class="sd">            llm_output (dict): The output from the LLM containing &#39;role&#39;, &#39;content&#39;, and &#39;tokens&#39;.</span>
</span><span id="Linear_CMT.save_llm_output-290"><a href="#Linear_CMT.save_llm_output-290"><span class="linenos">290</span></a><span class="sd">            input_msg_ref: Reference to the input messages for token increment calculation.</span>
</span><span id="Linear_CMT.save_llm_output-291"><a href="#Linear_CMT.save_llm_output-291"><span class="linenos">291</span></a><span class="sd">            auto_register_full_context (bool): Whether to register the output in the full context.</span>
</span><span id="Linear_CMT.save_llm_output-292"><a href="#Linear_CMT.save_llm_output-292"><span class="linenos">292</span></a>
</span><span id="Linear_CMT.save_llm_output-293"><a href="#Linear_CMT.save_llm_output-293"><span class="linenos">293</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.save_llm_output-294"><a href="#Linear_CMT.save_llm_output-294"><span class="linenos">294</span></a><span class="sd">            ExtendedMessage: The processed and extended message object.</span>
</span><span id="Linear_CMT.save_llm_output-295"><a href="#Linear_CMT.save_llm_output-295"><span class="linenos">295</span></a>
</span><span id="Linear_CMT.save_llm_output-296"><a href="#Linear_CMT.save_llm_output-296"><span class="linenos">296</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT.save_llm_output-297"><a href="#Linear_CMT.save_llm_output-297"><span class="linenos">297</span></a><span class="sd">            - Processes the LLM output and adds it to the conversation history.</span>
</span><span id="Linear_CMT.save_llm_output-298"><a href="#Linear_CMT.save_llm_output-298"><span class="linenos">298</span></a><span class="sd">            - Handles token processing and generation prompt management.</span>
</span><span id="Linear_CMT.save_llm_output-299"><a href="#Linear_CMT.save_llm_output-299"><span class="linenos">299</span></a><span class="sd">            - Ensures proper tokenization and context maintenance.</span>
</span><span id="Linear_CMT.save_llm_output-300"><a href="#Linear_CMT.save_llm_output-300"><span class="linenos">300</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_llm_output-301"><a href="#Linear_CMT.save_llm_output-301"><span class="linenos">301</span></a>        <span class="c1"># save basic</span>
</span><span id="Linear_CMT.save_llm_output-302"><a href="#Linear_CMT.save_llm_output-302"><span class="linenos">302</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">llm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="Linear_CMT.save_llm_output-303"><a href="#Linear_CMT.save_llm_output-303"><span class="linenos">303</span></a>        <span class="n">token_generator</span> <span class="o">=</span> <span class="s2">&quot;manual&quot;</span> <span class="k">if</span> <span class="s1">&#39;tokens&#39;</span> <span class="ow">in</span> <span class="n">llm_output</span> <span class="k">else</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="Linear_CMT.save_llm_output-304"><a href="#Linear_CMT.save_llm_output-304"><span class="linenos">304</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT.save_llm_output-305"><a href="#Linear_CMT.save_llm_output-305"><span class="linenos">305</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_llm_output-306"><a href="#Linear_CMT.save_llm_output-306"><span class="linenos">306</span></a>            <span class="n">role</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.save_llm_output-307"><a href="#Linear_CMT.save_llm_output-307"><span class="linenos">307</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.save_llm_output-308"><a href="#Linear_CMT.save_llm_output-308"><span class="linenos">308</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="n">token_generator</span><span class="p">,</span>
</span><span id="Linear_CMT.save_llm_output-309"><a href="#Linear_CMT.save_llm_output-309"><span class="linenos">309</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT.save_llm_output-310"><a href="#Linear_CMT.save_llm_output-310"><span class="linenos">310</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with LLM output details</span>
</span><span id="Linear_CMT.save_llm_output-311"><a href="#Linear_CMT.save_llm_output-311"><span class="linenos">311</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="Linear_CMT.save_llm_output-312"><a href="#Linear_CMT.save_llm_output-312"><span class="linenos">312</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context if auto_register_full_context is True</span>
</span><span id="Linear_CMT.save_llm_output-313"><a href="#Linear_CMT.save_llm_output-313"><span class="linenos">313</span></a>
</span><span id="Linear_CMT.save_llm_output-314"><a href="#Linear_CMT.save_llm_output-314"><span class="linenos">314</span></a>        <span class="c1"># check mistakes</span>
</span><span id="Linear_CMT.save_llm_output-315"><a href="#Linear_CMT.save_llm_output-315"><span class="linenos">315</span></a>        <span class="k">if</span> <span class="n">auto_register_full_context</span><span class="p">:</span>
</span><span id="Linear_CMT.save_llm_output-316"><a href="#Linear_CMT.save_llm_output-316"><span class="linenos">316</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">influence_extra_reward</span><span class="p">(</span><span class="n">llm_output</span><span class="p">)</span>  <span class="c1"># ⭐ Influence extra reward based on LLM output</span>
</span><span id="Linear_CMT.save_llm_output-317"><a href="#Linear_CMT.save_llm_output-317"><span class="linenos">317</span></a>
</span><span id="Linear_CMT.save_llm_output-318"><a href="#Linear_CMT.save_llm_output-318"><span class="linenos">318</span></a>        <span class="c1"># generate token</span>
</span><span id="Linear_CMT.save_llm_output-319"><a href="#Linear_CMT.save_llm_output-319"><span class="linenos">319</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span id="Linear_CMT.save_llm_output-320"><a href="#Linear_CMT.save_llm_output-320"><span class="linenos">320</span></a>            <span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="Linear_CMT.save_llm_output-321"><a href="#Linear_CMT.save_llm_output-321"><span class="linenos">321</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT.save_llm_output-322"><a href="#Linear_CMT.save_llm_output-322"><span class="linenos">322</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="Linear_CMT.save_llm_output-323"><a href="#Linear_CMT.save_llm_output-323"><span class="linenos">323</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT.save_llm_output-324"><a href="#Linear_CMT.save_llm_output-324"><span class="linenos">324</span></a>            <span class="c1"># completion_token_arr will contain generation_prompt header</span>
</span><span id="Linear_CMT.save_llm_output-325"><a href="#Linear_CMT.save_llm_output-325"><span class="linenos">325</span></a>            <span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">msg2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_inc</span><span class="p">(</span>
</span><span id="Linear_CMT.save_llm_output-326"><a href="#Linear_CMT.save_llm_output-326"><span class="linenos">326</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;</span>
</span><span id="Linear_CMT.save_llm_output-327"><a href="#Linear_CMT.save_llm_output-327"><span class="linenos">327</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT.save_llm_output-328"><a href="#Linear_CMT.save_llm_output-328"><span class="linenos">328</span></a>                <span class="c1"># ...  &lt;|im_end|&gt;&lt;|im_start|&gt;...&lt;|im_end|&gt;</span>
</span><span id="Linear_CMT.save_llm_output-329"><a href="#Linear_CMT.save_llm_output-329"><span class="linenos">329</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">input_msg_ref</span> <span class="o">+</span> <span class="p">[</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;role&#39;</span><span class="p">],</span>  <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]}</span> <span class="p">],</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</span><span id="Linear_CMT.save_llm_output-330"><a href="#Linear_CMT.save_llm_output-330"><span class="linenos">330</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT.save_llm_output-331"><a href="#Linear_CMT.save_llm_output-331"><span class="linenos">331</span></a>            <span class="n">vllm_output_raw_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">token_id</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">llm_output</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">]]</span>
</span><span id="Linear_CMT.save_llm_output-332"><a href="#Linear_CMT.save_llm_output-332"><span class="linenos">332</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">generated_token_cnt</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vllm_output_raw_token</span><span class="p">)</span>  <span class="c1"># ⭐ Increment the generated token count</span>
</span><span id="Linear_CMT.save_llm_output-333"><a href="#Linear_CMT.save_llm_output-333"><span class="linenos">333</span></a>            <span class="n">final_token_arr</span> <span class="o">=</span> <span class="n">replace_token_ids</span><span class="p">(</span><span class="n">place_holder</span><span class="o">=</span><span class="n">completion_token_arr</span><span class="p">,</span> <span class="n">replace_with</span><span class="o">=</span><span class="n">vllm_output_raw_token</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">generation_prompt_token</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">])</span>
</span><span id="Linear_CMT.save_llm_output-334"><a href="#Linear_CMT.save_llm_output-334"><span class="linenos">334</span></a>            <span class="k">return</span> <span class="n">final_token_arr</span>
</span><span id="Linear_CMT.save_llm_output-335"><a href="#Linear_CMT.save_llm_output-335"><span class="linenos">335</span></a>
</span><span id="Linear_CMT.save_llm_output-336"><a href="#Linear_CMT.save_llm_output-336"><span class="linenos">336</span></a>        <span class="k">if</span> <span class="n">token_generator</span> <span class="o">==</span> <span class="s2">&quot;manual&quot;</span><span class="p">:</span>
</span><span id="Linear_CMT.save_llm_output-337"><a href="#Linear_CMT.save_llm_output-337"><span class="linenos">337</span></a>            <span class="n">token_arr_method2</span> <span class="o">=</span> <span class="n">get_token_inc_from_vllm_response</span><span class="p">(</span><span class="n">input_msg_ref</span><span class="p">)</span>  <span class="c1"># ⭐ Generate token increments using the VLLM response</span>
</span><span id="Linear_CMT.save_llm_output-338"><a href="#Linear_CMT.save_llm_output-338"><span class="linenos">338</span></a>            <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span> <span class="o">=</span> <span class="n">token_arr_method2</span>  <span class="c1"># ⭐ Assign the generated token array to the ExtendedMessage</span>
</span><span id="Linear_CMT.save_llm_output-339"><a href="#Linear_CMT.save_llm_output-339"><span class="linenos">339</span></a>        <span class="k">return</span> <span class="n">ext_msg</span>
</span></pre></div>


            <div class="docstring"><p>Save the output from the LLM to the full context.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>llm_output (dict):</strong>  The output from the LLM containing 'role', 'content', and 'tokens'.</li>
<li><strong>input_msg_ref:</strong>  Reference to the input messages for token increment calculation.</li>
<li><strong>auto_register_full_context (bool):</strong>  Whether to register the output in the full context.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ExtendedMessage: The processed and extended message object.</p>
</blockquote>

<h6 id="note">Note:</h6>

<blockquote>
  <ul>
  <li>Processes the LLM output and adds it to the conversation history.</li>
  <li>Handles token processing and generation prompt management.</li>
  <li>Ensures proper tokenization and context maintenance.</li>
  </ul>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.save_llm_output_do_not_register_full_context" class="classattr">
                                        <input id="Linear_CMT.save_llm_output_do_not_register_full_context-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_llm_output_do_not_register_full_context</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">llm_output</span>, </span><span class="param"><span class="n">input_msg_ref</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.save_llm_output_do_not_register_full_context-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.save_llm_output_do_not_register_full_context"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-342"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-342"><span class="linenos">342</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_llm_output_do_not_register_full_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">):</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-343"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-343"><span class="linenos">343</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-344"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-344"><span class="linenos">344</span></a><span class="sd">        Saves the LLM output to the context without registering the full context.</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-345"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-345"><span class="linenos">345</span></a>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-346"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-346"><span class="linenos">346</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-347"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-347"><span class="linenos">347</span></a><span class="sd">            llm_output: The output from the language model.</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-348"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-348"><span class="linenos">348</span></a><span class="sd">            input_msg_ref: Reference to the input message.</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-349"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-349"><span class="linenos">349</span></a>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-350"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-350"><span class="linenos">350</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-351"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-351"><span class="linenos">351</span></a><span class="sd">            The result of saving the LLM output with the specified options.</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-352"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-352"><span class="linenos">352</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_llm_output_do_not_register_full_context-353"><a href="#Linear_CMT.save_llm_output_do_not_register_full_context-353"><span class="linenos">353</span></a>        <span class="k">return</span> <span class="n">Linear_CMT</span><span class="o">.</span><span class="n">save_llm_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">llm_output</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">,</span> <span class="n">auto_register_full_context</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># ⭐ Save LLM output without full context registration</span>
</span></pre></div>


            <div class="docstring"><p>Saves the LLM output to the context without registering the full context.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>llm_output:</strong>  The output from the language model.</li>
<li><strong>input_msg_ref:</strong>  Reference to the input message.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The result of saving the LLM output with the specified options.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.save_env_output" class="classattr">
                                        <input id="Linear_CMT.save_env_output-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_env_output</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">env_output</span><span class="p">:</span> <span class="nb">dict</span>,</span><span class="param">	<span class="n">input_msg_ref</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">add_nothink</span><span class="o">=</span><span class="kc">False</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.save_env_output-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.save_env_output"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.save_env_output-356"><a href="#Linear_CMT.save_env_output-356"><span class="linenos">356</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_env_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_output</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">input_msg_ref</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_nothink</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="Linear_CMT.save_env_output-357"><a href="#Linear_CMT.save_env_output-357"><span class="linenos">357</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_env_output-358"><a href="#Linear_CMT.save_env_output-358"><span class="linenos">358</span></a><span class="sd">        Save and process environment output to the context.</span>
</span><span id="Linear_CMT.save_env_output-359"><a href="#Linear_CMT.save_env_output-359"><span class="linenos">359</span></a>
</span><span id="Linear_CMT.save_env_output-360"><a href="#Linear_CMT.save_env_output-360"><span class="linenos">360</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.save_env_output-361"><a href="#Linear_CMT.save_env_output-361"><span class="linenos">361</span></a><span class="sd">            env_output (dict): Environment output containing &#39;content&#39;</span>
</span><span id="Linear_CMT.save_env_output-362"><a href="#Linear_CMT.save_env_output-362"><span class="linenos">362</span></a><span class="sd">            input_msg_ref (List[dict], optional): Reference messages for token calculation</span>
</span><span id="Linear_CMT.save_env_output-363"><a href="#Linear_CMT.save_env_output-363"><span class="linenos">363</span></a><span class="sd">            add_nothink (bool, optional): Whether to append &#39;/no_think&#39; to the content</span>
</span><span id="Linear_CMT.save_env_output-364"><a href="#Linear_CMT.save_env_output-364"><span class="linenos">364</span></a>
</span><span id="Linear_CMT.save_env_output-365"><a href="#Linear_CMT.save_env_output-365"><span class="linenos">365</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT.save_env_output-366"><a href="#Linear_CMT.save_env_output-366"><span class="linenos">366</span></a><span class="sd">            - Clips environment output if it exceeds max_env_output_length</span>
</span><span id="Linear_CMT.save_env_output-367"><a href="#Linear_CMT.save_env_output-367"><span class="linenos">367</span></a><span class="sd">            - Processes the output as a user message in the conversation</span>
</span><span id="Linear_CMT.save_env_output-368"><a href="#Linear_CMT.save_env_output-368"><span class="linenos">368</span></a><span class="sd">            - Computes and stores token arrays for the environment response</span>
</span><span id="Linear_CMT.save_env_output-369"><a href="#Linear_CMT.save_env_output-369"><span class="linenos">369</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.save_env_output-370"><a href="#Linear_CMT.save_env_output-370"><span class="linenos">370</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
</span><span id="Linear_CMT.save_env_output-371"><a href="#Linear_CMT.save_env_output-371"><span class="linenos">371</span></a>        <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;error&#39;</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">):</span>
</span><span id="Linear_CMT.save_env_output-372"><a href="#Linear_CMT.save_env_output-372"><span class="linenos">372</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[Error from environment: </span><span class="si">{</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">]&quot;</span>
</span><span id="Linear_CMT.save_env_output-373"><a href="#Linear_CMT.save_env_output-373"><span class="linenos">373</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="s1">&#39;content&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">env_output</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]):</span>
</span><span id="Linear_CMT.save_env_output-374"><a href="#Linear_CMT.save_env_output-374"><span class="linenos">374</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;[No content provided by the environment]&#39;</span>
</span><span id="Linear_CMT.save_env_output-375"><a href="#Linear_CMT.save_env_output-375"><span class="linenos">375</span></a>        <span class="k">if</span> <span class="n">add_nothink</span><span class="p">:</span>
</span><span id="Linear_CMT.save_env_output-376"><a href="#Linear_CMT.save_env_output-376"><span class="linenos">376</span></a>            <span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot; /no_think&quot;</span>
</span><span id="Linear_CMT.save_env_output-377"><a href="#Linear_CMT.save_env_output-377"><span class="linenos">377</span></a>        <span class="n">ext_msg</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT.save_env_output-378"><a href="#Linear_CMT.save_env_output-378"><span class="linenos">378</span></a>            <span class="n">author</span><span class="o">=</span><span class="s2">&quot;env&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-379"><a href="#Linear_CMT.save_env_output-379"><span class="linenos">379</span></a>            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-380"><a href="#Linear_CMT.save_env_output-380"><span class="linenos">380</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">env_output</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">],</span>
</span><span id="Linear_CMT.save_env_output-381"><a href="#Linear_CMT.save_env_output-381"><span class="linenos">381</span></a>            <span class="n">clip</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-382"><a href="#Linear_CMT.save_env_output-382"><span class="linenos">382</span></a>            <span class="n">clip_token_limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_env_output_length</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-383"><a href="#Linear_CMT.save_env_output-383"><span class="linenos">383</span></a>            <span class="n">token_generator</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-384"><a href="#Linear_CMT.save_env_output-384"><span class="linenos">384</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT.save_env_output-385"><a href="#Linear_CMT.save_env_output-385"><span class="linenos">385</span></a>        <span class="p">)</span>  <span class="c1"># ⭐ Create an ExtendedMessage object with the environment content</span>
</span><span id="Linear_CMT.save_env_output-386"><a href="#Linear_CMT.save_env_output-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="o">+=</span> <span class="p">[</span><span class="n">ext_msg</span><span class="p">]</span>  <span class="c1"># ⭐ Add the ExtendedMessage to the full context</span>
</span><span id="Linear_CMT.save_env_output-387"><a href="#Linear_CMT.save_env_output-387"><span class="linenos">387</span></a>        <span class="k">return</span>
</span></pre></div>


            <div class="docstring"><p>Save and process environment output to the context.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>env_output (dict):</strong>  Environment output containing 'content'</li>
<li><strong>input_msg_ref (List[dict], optional):</strong>  Reference messages for token calculation</li>
<li><strong>add_nothink (bool, optional):</strong>  Whether to append '/no_think' to the content</li>
</ul>

<h6 id="note">Note:</h6>

<blockquote>
  <ul>
  <li>Clips environment output if it exceeds max_env_output_length</li>
  <li>Processes the output as a user message in the conversation</li>
  <li>Computes and stores token arrays for the environment response</li>
  </ul>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.to_role_content" class="classattr">
                                        <input id="Linear_CMT.to_role_content-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_role_content</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">ext_msg_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a></span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.to_role_content-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.to_role_content"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.to_role_content-389"><a href="#Linear_CMT.to_role_content-389"><span class="linenos">389</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to_role_content</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_msg_array</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
</span><span id="Linear_CMT.to_role_content-390"><a href="#Linear_CMT.to_role_content-390"><span class="linenos">390</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.to_role_content-391"><a href="#Linear_CMT.to_role_content-391"><span class="linenos">391</span></a><span class="sd">        Converts a list of ExtendedMessage objects into a list of dictionaries with &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="Linear_CMT.to_role_content-392"><a href="#Linear_CMT.to_role_content-392"><span class="linenos">392</span></a>
</span><span id="Linear_CMT.to_role_content-393"><a href="#Linear_CMT.to_role_content-393"><span class="linenos">393</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.to_role_content-394"><a href="#Linear_CMT.to_role_content-394"><span class="linenos">394</span></a><span class="sd">            ext_msg_array (List[ExtendedMessage]): A list of ExtendedMessage objects.</span>
</span><span id="Linear_CMT.to_role_content-395"><a href="#Linear_CMT.to_role_content-395"><span class="linenos">395</span></a>
</span><span id="Linear_CMT.to_role_content-396"><a href="#Linear_CMT.to_role_content-396"><span class="linenos">396</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.to_role_content-397"><a href="#Linear_CMT.to_role_content-397"><span class="linenos">397</span></a><span class="sd">            List[dict]: A list of dictionaries, each containing &#39;role&#39; and &#39;content&#39; keys.</span>
</span><span id="Linear_CMT.to_role_content-398"><a href="#Linear_CMT.to_role_content-398"><span class="linenos">398</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.to_role_content-399"><a href="#Linear_CMT.to_role_content-399"><span class="linenos">399</span></a>        <span class="k">return</span> <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">}</span> <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_msg_array</span><span class="p">]</span>  <span class="c1"># ⭐ Convert each ExtendedMessage to a dictionary</span>
</span></pre></div>


            <div class="docstring"><p>Converts a list of ExtendedMessage objects into a list of dictionaries with 'role' and 'content' keys.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>ext_msg_array (List[ExtendedMessage]):</strong>  A list of ExtendedMessage objects.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>List[dict]: A list of dictionaries, each containing 'role' and 'content' keys.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.prepare_world_interaction" class="classattr">
                                        <input id="Linear_CMT.prepare_world_interaction-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_world_interaction</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.prepare_world_interaction-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.prepare_world_interaction"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.prepare_world_interaction-401"><a href="#Linear_CMT.prepare_world_interaction-401"><span class="linenos">401</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_world_interaction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="Linear_CMT.prepare_world_interaction-402"><a href="#Linear_CMT.prepare_world_interaction-402"><span class="linenos">402</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_world_interaction-403"><a href="#Linear_CMT.prepare_world_interaction-403"><span class="linenos">403</span></a><span class="sd">        Process the latest model content before environment interaction.</span>
</span><span id="Linear_CMT.prepare_world_interaction-404"><a href="#Linear_CMT.prepare_world_interaction-404"><span class="linenos">404</span></a>
</span><span id="Linear_CMT.prepare_world_interaction-405"><a href="#Linear_CMT.prepare_world_interaction-405"><span class="linenos">405</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.prepare_world_interaction-406"><a href="#Linear_CMT.prepare_world_interaction-406"><span class="linenos">406</span></a><span class="sd">            str: Processed content, with code extracted from markdown code blocks if present</span>
</span><span id="Linear_CMT.prepare_world_interaction-407"><a href="#Linear_CMT.prepare_world_interaction-407"><span class="linenos">407</span></a><span class="sd">                 or the raw content if no code blocks are found</span>
</span><span id="Linear_CMT.prepare_world_interaction-408"><a href="#Linear_CMT.prepare_world_interaction-408"><span class="linenos">408</span></a>
</span><span id="Linear_CMT.prepare_world_interaction-409"><a href="#Linear_CMT.prepare_world_interaction-409"><span class="linenos">409</span></a><span class="sd">        Note:</span>
</span><span id="Linear_CMT.prepare_world_interaction-410"><a href="#Linear_CMT.prepare_world_interaction-410"><span class="linenos">410</span></a><span class="sd">            - Extracts Python code from markdown code blocks (```python```)</span>
</span><span id="Linear_CMT.prepare_world_interaction-411"><a href="#Linear_CMT.prepare_world_interaction-411"><span class="linenos">411</span></a><span class="sd">            - Returns the raw content if no valid code blocks are found</span>
</span><span id="Linear_CMT.prepare_world_interaction-412"><a href="#Linear_CMT.prepare_world_interaction-412"><span class="linenos">412</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.prepare_world_interaction-413"><a href="#Linear_CMT.prepare_world_interaction-413"><span class="linenos">413</span></a>        <span class="n">latest_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
</span><span id="Linear_CMT.prepare_world_interaction-414"><a href="#Linear_CMT.prepare_world_interaction-414"><span class="linenos">414</span></a>        <span class="k">return</span> <span class="n">latest_content</span>
</span></pre></div>


            <div class="docstring"><p>Process the latest model content before environment interaction.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>str: Processed content, with code extracted from markdown code blocks if present
       or the raw content if no code blocks are found</p>
</blockquote>

<h6 id="note">Note:</h6>

<blockquote>
  <ul>
  <li>Extracts Python code from markdown code blocks (<code>python</code>)</li>
  <li>Returns the raw content if no valid code blocks are found</li>
  </ul>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.filter_context_via_author" class="classattr">
                                        <input id="Linear_CMT.filter_context_via_author-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">filter_context_via_author</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">author</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="n"><a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a></span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.filter_context_via_author-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.filter_context_via_author"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.filter_context_via_author-416"><a href="#Linear_CMT.filter_context_via_author-416"><span class="linenos">416</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">author</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="Linear_CMT.filter_context_via_author-417"><a href="#Linear_CMT.filter_context_via_author-417"><span class="linenos">417</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.filter_context_via_author-418"><a href="#Linear_CMT.filter_context_via_author-418"><span class="linenos">418</span></a><span class="sd">        Filters the full context to include only messages from a specific author and returns a deep copy of the filtered list.</span>
</span><span id="Linear_CMT.filter_context_via_author-419"><a href="#Linear_CMT.filter_context_via_author-419"><span class="linenos">419</span></a>
</span><span id="Linear_CMT.filter_context_via_author-420"><a href="#Linear_CMT.filter_context_via_author-420"><span class="linenos">420</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.filter_context_via_author-421"><a href="#Linear_CMT.filter_context_via_author-421"><span class="linenos">421</span></a><span class="sd">            author (str): The name of the author whose messages are to be included in the result.</span>
</span><span id="Linear_CMT.filter_context_via_author-422"><a href="#Linear_CMT.filter_context_via_author-422"><span class="linenos">422</span></a>
</span><span id="Linear_CMT.filter_context_via_author-423"><a href="#Linear_CMT.filter_context_via_author-423"><span class="linenos">423</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.filter_context_via_author-424"><a href="#Linear_CMT.filter_context_via_author-424"><span class="linenos">424</span></a><span class="sd">            List[ExtendedMessage]: A deep copy of the list containing only the messages from the specified author.</span>
</span><span id="Linear_CMT.filter_context_via_author-425"><a href="#Linear_CMT.filter_context_via_author-425"><span class="linenos">425</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.filter_context_via_author-426"><a href="#Linear_CMT.filter_context_via_author-426"><span class="linenos">426</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="n">author</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and create a deep copy of the context</span>
</span></pre></div>


            <div class="docstring"><p>Filters the full context to include only messages from a specific author and returns a deep copy of the filtered list.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>author (str):</strong>  The name of the author whose messages are to be included in the result.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>List[ExtendedMessage]: A deep copy of the list containing only the messages from the specified author.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.filter_context_via_authors" class="classattr">
                                        <input id="Linear_CMT.filter_context_via_authors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">filter_context_via_authors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">authors</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">List</span><span class="p">[</span><span class="n"><a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a></span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.filter_context_via_authors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.filter_context_via_authors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.filter_context_via_authors-428"><a href="#Linear_CMT.filter_context_via_authors-428"><span class="linenos">428</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">filter_context_via_authors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">authors</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">]:</span>
</span><span id="Linear_CMT.filter_context_via_authors-429"><a href="#Linear_CMT.filter_context_via_authors-429"><span class="linenos">429</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.filter_context_via_authors-430"><a href="#Linear_CMT.filter_context_via_authors-430"><span class="linenos">430</span></a><span class="sd">        Filters the full context of messages, returning only those authored by the specified authors.</span>
</span><span id="Linear_CMT.filter_context_via_authors-431"><a href="#Linear_CMT.filter_context_via_authors-431"><span class="linenos">431</span></a>
</span><span id="Linear_CMT.filter_context_via_authors-432"><a href="#Linear_CMT.filter_context_via_authors-432"><span class="linenos">432</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.filter_context_via_authors-433"><a href="#Linear_CMT.filter_context_via_authors-433"><span class="linenos">433</span></a><span class="sd">            authors (str): A string of author names, separated by commas, indicating which authors&#39; messages to include.</span>
</span><span id="Linear_CMT.filter_context_via_authors-434"><a href="#Linear_CMT.filter_context_via_authors-434"><span class="linenos">434</span></a>
</span><span id="Linear_CMT.filter_context_via_authors-435"><a href="#Linear_CMT.filter_context_via_authors-435"><span class="linenos">435</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.filter_context_via_authors-436"><a href="#Linear_CMT.filter_context_via_authors-436"><span class="linenos">436</span></a><span class="sd">            List[ExtendedMessage]: A list of ExtendedMessage objects from the full context that match the specified authors.</span>
</span><span id="Linear_CMT.filter_context_via_authors-437"><a href="#Linear_CMT.filter_context_via_authors-437"><span class="linenos">437</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.filter_context_via_authors-438"><a href="#Linear_CMT.filter_context_via_authors-438"><span class="linenos">438</span></a>        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">([</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_context</span> <span class="k">if</span> <span class="n">c</span><span class="o">.</span><span class="n">author</span> <span class="ow">in</span> <span class="n">authors</span> <span class="p">])</span>  <span class="c1"># ⭐ Filter and deep copy the relevant messages</span>
</span></pre></div>


            <div class="docstring"><p>Filters the full context of messages, returning only those authored by the specified authors.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>authors (str):</strong>  A string of author names, separated by commas, indicating which authors' messages to include.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>List[ExtendedMessage]: A list of ExtendedMessage objects from the full context that match the specified authors.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.group_tokenize" class="classattr">
                                        <input id="Linear_CMT.group_tokenize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">group_tokenize</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.group_tokenize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.group_tokenize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.group_tokenize-440"><a href="#Linear_CMT.group_tokenize-440"><span class="linenos">440</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.group_tokenize-441"><a href="#Linear_CMT.group_tokenize-441"><span class="linenos">441</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.group_tokenize-442"><a href="#Linear_CMT.group_tokenize-442"><span class="linenos">442</span></a><span class="sd">        Tokenizes the full context into a format suitable for input to a language model, creating a sample with necessary attributes like input IDs, attention masks, and position IDs.</span>
</span><span id="Linear_CMT.group_tokenize-443"><a href="#Linear_CMT.group_tokenize-443"><span class="linenos">443</span></a>
</span><span id="Linear_CMT.group_tokenize-444"><a href="#Linear_CMT.group_tokenize-444"><span class="linenos">444</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.group_tokenize-445"><a href="#Linear_CMT.group_tokenize-445"><span class="linenos">445</span></a><span class="sd">            List[Sample]: An array containing a single Sample object, representing the tokenized context.</span>
</span><span id="Linear_CMT.group_tokenize-446"><a href="#Linear_CMT.group_tokenize-446"><span class="linenos">446</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.group_tokenize-447"><a href="#Linear_CMT.group_tokenize-447"><span class="linenos">447</span></a>        <span class="c1"># assert self.latest_llm_interaction_socket is None, &quot;unprocessed message buffer! forget to call `save_llm_output` after `prepare_next_llm_context`?&quot;</span>
</span><span id="Linear_CMT.group_tokenize-448"><a href="#Linear_CMT.group_tokenize-448"><span class="linenos">448</span></a>        <span class="n">sample_arr</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT.group_tokenize-449"><a href="#Linear_CMT.group_tokenize-449"><span class="linenos">449</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT.group_tokenize-450"><a href="#Linear_CMT.group_tokenize-450"><span class="linenos">450</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="Linear_CMT.group_tokenize-451"><a href="#Linear_CMT.group_tokenize-451"><span class="linenos">451</span></a>        <span class="n">sample</span> <span class="o">=</span> <span class="n">Sample</span><span class="p">(</span>
</span><span id="Linear_CMT.group_tokenize-452"><a href="#Linear_CMT.group_tokenize-452"><span class="linenos">452</span></a>            <span class="n">data_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data_id</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-453"><a href="#Linear_CMT.group_tokenize-453"><span class="linenos">453</span></a>            <span class="n">rollout_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_id</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-454"><a href="#Linear_CMT.group_tokenize-454"><span class="linenos">454</span></a>            <span class="n">task_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">task_id</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-455"><a href="#Linear_CMT.group_tokenize-455"><span class="linenos">455</span></a>            <span class="n">minor_index_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-456"><a href="#Linear_CMT.group_tokenize-456"><span class="linenos">456</span></a>            <span class="n">messages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">to_role_content</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">),</span>
</span><span id="Linear_CMT.group_tokenize-457"><a href="#Linear_CMT.group_tokenize-457"><span class="linenos">457</span></a>            <span class="n">input_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-458"><a href="#Linear_CMT.group_tokenize-458"><span class="linenos">458</span></a>            <span class="n">prompt_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-459"><a href="#Linear_CMT.group_tokenize-459"><span class="linenos">459</span></a>            <span class="n">response_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-460"><a href="#Linear_CMT.group_tokenize-460"><span class="linenos">460</span></a>            <span class="n">attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-461"><a href="#Linear_CMT.group_tokenize-461"><span class="linenos">461</span></a>            <span class="n">prompt_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-462"><a href="#Linear_CMT.group_tokenize-462"><span class="linenos">462</span></a>            <span class="n">response_attention_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-463"><a href="#Linear_CMT.group_tokenize-463"><span class="linenos">463</span></a>            <span class="n">loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-464"><a href="#Linear_CMT.group_tokenize-464"><span class="linenos">464</span></a>            <span class="n">prompt_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-465"><a href="#Linear_CMT.group_tokenize-465"><span class="linenos">465</span></a>            <span class="n">response_loss_mask</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-466"><a href="#Linear_CMT.group_tokenize-466"><span class="linenos">466</span></a>            <span class="n">position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-467"><a href="#Linear_CMT.group_tokenize-467"><span class="linenos">467</span></a>            <span class="n">prompt_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-468"><a href="#Linear_CMT.group_tokenize-468"><span class="linenos">468</span></a>            <span class="n">response_position_ids</span><span class="o">=</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">],</span>
</span><span id="Linear_CMT.group_tokenize-469"><a href="#Linear_CMT.group_tokenize-469"><span class="linenos">469</span></a>            <span class="n">reward_scores</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">model_dump</span><span class="p">(),</span> <span class="c1"># reward is duplicated in each sample</span>
</span><span id="Linear_CMT.group_tokenize-470"><a href="#Linear_CMT.group_tokenize-470"><span class="linenos">470</span></a>            <span class="n">max_prompt_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-471"><a href="#Linear_CMT.group_tokenize-471"><span class="linenos">471</span></a>            <span class="n">max_response_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-472"><a href="#Linear_CMT.group_tokenize-472"><span class="linenos">472</span></a>            <span class="n">max_model_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_response_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_prompt_length</span><span class="p">,</span>
</span><span id="Linear_CMT.group_tokenize-473"><a href="#Linear_CMT.group_tokenize-473"><span class="linenos">473</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT.group_tokenize-474"><a href="#Linear_CMT.group_tokenize-474"><span class="linenos">474</span></a>        <span class="n">sample</span><span class="o">.</span><span class="n">truncate_output_ids</span><span class="p">()</span>  <span class="c1"># ⭐ Ensure the output IDs are within the allowed length</span>
</span><span id="Linear_CMT.group_tokenize-475"><a href="#Linear_CMT.group_tokenize-475"><span class="linenos">475</span></a>        <span class="n">sample_arr</span> <span class="o">+=</span> <span class="p">[</span><span class="n">sample</span><span class="p">]</span>
</span><span id="Linear_CMT.group_tokenize-476"><a href="#Linear_CMT.group_tokenize-476"><span class="linenos">476</span></a>        <span class="k">return</span> <span class="n">sample_arr</span>
</span></pre></div>


            <div class="docstring"><p>Tokenizes the full context into a format suitable for input to a language model, creating a sample with necessary attributes like input IDs, attention masks, and position IDs.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>List[Sample]: An array containing a single Sample object, representing the tokenized context.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.group_render_token_log" class="classattr">
                                        <input id="Linear_CMT.group_render_token_log-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">group_render_token_log</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.group_render_token_log-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.group_render_token_log"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.group_render_token_log-479"><a href="#Linear_CMT.group_render_token_log-479"><span class="linenos">479</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">group_render_token_log</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Linear_CMT.group_render_token_log-480"><a href="#Linear_CMT.group_render_token_log-480"><span class="linenos">480</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>
</span><span id="Linear_CMT.group_render_token_log-481"><a href="#Linear_CMT.group_render_token_log-481"><span class="linenos">481</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>
</span><span id="Linear_CMT.group_render_token_log-482"><a href="#Linear_CMT.group_render_token_log-482"><span class="linenos">482</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT.group_render_token_log-483"><a href="#Linear_CMT.group_render_token_log-483"><span class="linenos">483</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT.group_render_token_log-484"><a href="#Linear_CMT.group_render_token_log-484"><span class="linenos">484</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>
</span><span id="Linear_CMT.group_render_token_log-485"><a href="#Linear_CMT.group_render_token_log-485"><span class="linenos">485</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="Linear_CMT.group_render_token_log-486"><a href="#Linear_CMT.group_render_token_log-486"><span class="linenos">486</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.group_render_token_log-487"><a href="#Linear_CMT.group_render_token_log-487"><span class="linenos">487</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.group_render_token_log-488"><a href="#Linear_CMT.group_render_token_log-488"><span class="linenos">488</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.group_render_token_log-489"><a href="#Linear_CMT.group_render_token_log-489"><span class="linenos">489</span></a>        <span class="p">}</span>
</span></pre></div>


    

                            </div>
                            <div id="Linear_CMT.generate_log" class="classattr">
                                        <input id="Linear_CMT.generate_log-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">generate_log</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">task_id</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.generate_log-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.generate_log"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.generate_log-492"><a href="#Linear_CMT.generate_log-492"><span class="linenos">492</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">generate_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_id</span><span class="p">):</span>
</span><span id="Linear_CMT.generate_log-493"><a href="#Linear_CMT.generate_log-493"><span class="linenos">493</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.generate_log-494"><a href="#Linear_CMT.generate_log-494"><span class="linenos">494</span></a><span class="sd">        Generates and prints a log for the specified task, including detailed information about the tokenized steps,</span>
</span><span id="Linear_CMT.generate_log-495"><a href="#Linear_CMT.generate_log-495"><span class="linenos">495</span></a><span class="sd">        input IDs, loss mask colors, and rewards. The log is formatted into a nested JSON structure and printed.</span>
</span><span id="Linear_CMT.generate_log-496"><a href="#Linear_CMT.generate_log-496"><span class="linenos">496</span></a>
</span><span id="Linear_CMT.generate_log-497"><a href="#Linear_CMT.generate_log-497"><span class="linenos">497</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.generate_log-498"><a href="#Linear_CMT.generate_log-498"><span class="linenos">498</span></a><span class="sd">            task_id (str): The ID of the task for which the log is being generated.</span>
</span><span id="Linear_CMT.generate_log-499"><a href="#Linear_CMT.generate_log-499"><span class="linenos">499</span></a>
</span><span id="Linear_CMT.generate_log-500"><a href="#Linear_CMT.generate_log-500"><span class="linenos">500</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.generate_log-501"><a href="#Linear_CMT.generate_log-501"><span class="linenos">501</span></a><span class="sd">            None</span>
</span><span id="Linear_CMT.generate_log-502"><a href="#Linear_CMT.generate_log-502"><span class="linenos">502</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.generate_log-503"><a href="#Linear_CMT.generate_log-503"><span class="linenos">503</span></a>        <span class="n">nested_items_print_buffer</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT.generate_log-504"><a href="#Linear_CMT.generate_log-504"><span class="linenos">504</span></a>        <span class="n">ext_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_context</span>  <span class="c1"># ⭐ Retrieve the full context for the task</span>
</span><span id="Linear_CMT.generate_log-505"><a href="#Linear_CMT.generate_log-505"><span class="linenos">505</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_steps</span><span class="p">(</span><span class="n">ext_steps</span><span class="o">=</span><span class="n">ext_steps</span><span class="p">)</span>  <span class="c1"># ⭐ Tokenize the extended steps</span>
</span><span id="Linear_CMT.generate_log-506"><a href="#Linear_CMT.generate_log-506"><span class="linenos">506</span></a>        <span class="n">text_arr</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Decode the tokenized input IDs to text</span>
</span><span id="Linear_CMT.generate_log-507"><a href="#Linear_CMT.generate_log-507"><span class="linenos">507</span></a>        <span class="n">input_id_arr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Convert input IDs to strings</span>
</span><span id="Linear_CMT.generate_log-508"><a href="#Linear_CMT.generate_log-508"><span class="linenos">508</span></a>        <span class="n">loss_mask_color_arr</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#09ABCF&quot;</span> <span class="k">if</span> <span class="n">mask</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;#D98510&quot;</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]]</span>  <span class="c1"># ⭐ Generate color array based on loss mask</span>
</span><span id="Linear_CMT.generate_log-509"><a href="#Linear_CMT.generate_log-509"><span class="linenos">509</span></a>        <span class="n">buffer</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="Linear_CMT.generate_log-510"><a href="#Linear_CMT.generate_log-510"><span class="linenos">510</span></a>            <span class="s2">&quot;text_arr&quot;</span><span class="p">:</span> <span class="n">text_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-511"><a href="#Linear_CMT.generate_log-511"><span class="linenos">511</span></a>            <span class="s2">&quot;input_id_arr&quot;</span><span class="p">:</span> <span class="n">input_id_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-512"><a href="#Linear_CMT.generate_log-512"><span class="linenos">512</span></a>            <span class="s2">&quot;loss_mask_color_arr&quot;</span><span class="p">:</span> <span class="n">loss_mask_color_arr</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-513"><a href="#Linear_CMT.generate_log-513"><span class="linenos">513</span></a>        <span class="p">}</span>
</span><span id="Linear_CMT.generate_log-514"><a href="#Linear_CMT.generate_log-514"><span class="linenos">514</span></a>        <span class="n">len_prompt_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of prompt IDs</span>
</span><span id="Linear_CMT.generate_log-515"><a href="#Linear_CMT.generate_log-515"><span class="linenos">515</span></a>        <span class="n">len_response_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of response IDs</span>
</span><span id="Linear_CMT.generate_log-516"><a href="#Linear_CMT.generate_log-516"><span class="linenos">516</span></a>        <span class="n">len_input_ids</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>  <span class="c1"># ⭐ Calculate the length of input IDs</span>
</span><span id="Linear_CMT.generate_log-517"><a href="#Linear_CMT.generate_log-517"><span class="linenos">517</span></a>        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the reward outcome</span>
</span><span id="Linear_CMT.generate_log-518"><a href="#Linear_CMT.generate_log-518"><span class="linenos">518</span></a>        <span class="n">task_outcome</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="o">.</span><span class="n">success_rate</span><span class="p">)</span>  <span class="c1"># ⭐ Get the task success rate as a string</span>
</span><span id="Linear_CMT.generate_log-519"><a href="#Linear_CMT.generate_log-519"><span class="linenos">519</span></a>        <span class="n">final_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">)</span><span class="o">.</span><span class="n">outcome</span>  <span class="c1"># ⭐ Get the final reward after applying the reward patch</span>
</span><span id="Linear_CMT.generate_log-520"><a href="#Linear_CMT.generate_log-520"><span class="linenos">520</span></a>        <span class="n">selectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_id</span><span class="p">,</span> <span class="n">task_outcome</span><span class="p">]</span>
</span><span id="Linear_CMT.generate_log-521"><a href="#Linear_CMT.generate_log-521"><span class="linenos">521</span></a>        <span class="n">nested_items_print_buffer</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">selectors</span><span class="p">)]</span> <span class="o">=</span> <span class="n">NestedJsonItem</span><span class="p">(</span>
</span><span id="Linear_CMT.generate_log-522"><a href="#Linear_CMT.generate_log-522"><span class="linenos">522</span></a>            <span class="n">item_id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;item&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-523"><a href="#Linear_CMT.generate_log-523"><span class="linenos">523</span></a>            <span class="n">outcome</span><span class="o">=</span><span class="n">task_outcome</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-524"><a href="#Linear_CMT.generate_log-524"><span class="linenos">524</span></a>            <span class="n">len_prompt_ids</span><span class="o">=</span><span class="n">len_prompt_ids</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-525"><a href="#Linear_CMT.generate_log-525"><span class="linenos">525</span></a>            <span class="n">len_response_ids</span><span class="o">=</span><span class="n">len_response_ids</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-526"><a href="#Linear_CMT.generate_log-526"><span class="linenos">526</span></a>            <span class="n">len_input_ids</span><span class="o">=</span><span class="n">len_input_ids</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-527"><a href="#Linear_CMT.generate_log-527"><span class="linenos">527</span></a>            <span class="n">reward</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-528"><a href="#Linear_CMT.generate_log-528"><span class="linenos">528</span></a>            <span class="n">final_reward</span><span class="o">=</span><span class="n">final_reward</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-529"><a href="#Linear_CMT.generate_log-529"><span class="linenos">529</span></a>            <span class="n">content</span><span class="o">=</span><span class="n">SeqItem</span><span class="p">(</span>
</span><span id="Linear_CMT.generate_log-530"><a href="#Linear_CMT.generate_log-530"><span class="linenos">530</span></a>                <span class="n">text</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span>  <span class="c1"># text</span>
</span><span id="Linear_CMT.generate_log-531"><a href="#Linear_CMT.generate_log-531"><span class="linenos">531</span></a>                <span class="n">title</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;text_arr&#39;</span><span class="p">],</span> <span class="c1"># mouse hover</span>
</span><span id="Linear_CMT.generate_log-532"><a href="#Linear_CMT.generate_log-532"><span class="linenos">532</span></a>                <span class="n">count</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;input_id_arr&#39;</span><span class="p">],</span> <span class="c1"># highlight text</span>
</span><span id="Linear_CMT.generate_log-533"><a href="#Linear_CMT.generate_log-533"><span class="linenos">533</span></a>                <span class="n">color</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="s1">&#39;loss_mask_color_arr&#39;</span><span class="p">]</span>   <span class="c1"># color</span>
</span><span id="Linear_CMT.generate_log-534"><a href="#Linear_CMT.generate_log-534"><span class="linenos">534</span></a>            <span class="p">)</span>
</span><span id="Linear_CMT.generate_log-535"><a href="#Linear_CMT.generate_log-535"><span class="linenos">535</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT.generate_log-536"><a href="#Linear_CMT.generate_log-536"><span class="linenos">536</span></a>        <span class="n">print_nested</span><span class="p">(</span><span class="n">nested_items_print_buffer</span><span class="p">,</span>  <span class="c1"># ⭐ Print the nested JSON buffer</span>
</span><span id="Linear_CMT.generate_log-537"><a href="#Linear_CMT.generate_log-537"><span class="linenos">537</span></a>            <span class="n">main_content</span><span class="o">=</span><span class="s2">&quot;This is the main content of the nested JSON&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-538"><a href="#Linear_CMT.generate_log-538"><span class="linenos">538</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-539"><a href="#Linear_CMT.generate_log-539"><span class="linenos">539</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;rollout&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-540"><a href="#Linear_CMT.generate_log-540"><span class="linenos">540</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-541"><a href="#Linear_CMT.generate_log-541"><span class="linenos">541</span></a>            <span class="n">attach</span><span class="o">=</span><span class="s2">&quot;Copy Sample Message&quot;</span>
</span><span id="Linear_CMT.generate_log-542"><a href="#Linear_CMT.generate_log-542"><span class="linenos">542</span></a>        <span class="p">)</span>
</span><span id="Linear_CMT.generate_log-543"><a href="#Linear_CMT.generate_log-543"><span class="linenos">543</span></a>        <span class="n">print_listofdict</span><span class="p">(</span>  <span class="c1"># ⭐ Print the list of dictionaries</span>
</span><span id="Linear_CMT.generate_log-544"><a href="#Linear_CMT.generate_log-544"><span class="linenos">544</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-545"><a href="#Linear_CMT.generate_log-545"><span class="linenos">545</span></a>            <span class="n">header</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training task </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s2"> (Final Reward </span><span class="si">{</span><span class="n">final_reward</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-546"><a href="#Linear_CMT.generate_log-546"><span class="linenos">546</span></a>            <span class="n">mod</span><span class="o">=</span><span class="s2">&quot;conversation&quot;</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-547"><a href="#Linear_CMT.generate_log-547"><span class="linenos">547</span></a>            <span class="n">narrow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Linear_CMT.generate_log-548"><a href="#Linear_CMT.generate_log-548"><span class="linenos">548</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Generates and prints a log for the specified task, including detailed information about the tokenized steps,
input IDs, loss mask colors, and rewards. The log is formatted into a nested JSON structure and printed.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>task_id (str):</strong>  The ID of the task for which the log is being generated.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.reward_patch" class="classattr">
                                        <input id="Linear_CMT.reward_patch-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reward_patch</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">reward</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Linear_CMT.reward_patch-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.reward_patch"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.reward_patch-550"><a href="#Linear_CMT.reward_patch-550"><span class="linenos">550</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reward_patch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
</span><span id="Linear_CMT.reward_patch-551"><a href="#Linear_CMT.reward_patch-551"><span class="linenos">551</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.reward_patch-552"><a href="#Linear_CMT.reward_patch-552"><span class="linenos">552</span></a><span class="sd">        Creates a deep copy of the provided reward and may modify it based on internal state.</span>
</span><span id="Linear_CMT.reward_patch-553"><a href="#Linear_CMT.reward_patch-553"><span class="linenos">553</span></a>
</span><span id="Linear_CMT.reward_patch-554"><a href="#Linear_CMT.reward_patch-554"><span class="linenos">554</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.reward_patch-555"><a href="#Linear_CMT.reward_patch-555"><span class="linenos">555</span></a><span class="sd">            reward (object): The reward object to be patched, which must have an &#39;outcome&#39; attribute.</span>
</span><span id="Linear_CMT.reward_patch-556"><a href="#Linear_CMT.reward_patch-556"><span class="linenos">556</span></a>
</span><span id="Linear_CMT.reward_patch-557"><a href="#Linear_CMT.reward_patch-557"><span class="linenos">557</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.reward_patch-558"><a href="#Linear_CMT.reward_patch-558"><span class="linenos">558</span></a><span class="sd">            object: The possibly modified deep copy of the original reward.</span>
</span><span id="Linear_CMT.reward_patch-559"><a href="#Linear_CMT.reward_patch-559"><span class="linenos">559</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.reward_patch-560"><a href="#Linear_CMT.reward_patch-560"><span class="linenos">560</span></a>        <span class="n">_reward</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>  <span class="c1"># ⭐ Create a deep copy of the reward to avoid modifying the original</span>
</span><span id="Linear_CMT.reward_patch-561"><a href="#Linear_CMT.reward_patch-561"><span class="linenos">561</span></a>        <span class="c1"># if self.compute_madness() &lt; 0: _reward.outcome = -1.0</span>
</span><span id="Linear_CMT.reward_patch-562"><a href="#Linear_CMT.reward_patch-562"><span class="linenos">562</span></a>        <span class="k">return</span> <span class="n">_reward</span>
</span></pre></div>


            <div class="docstring"><p>Creates a deep copy of the provided reward and may modify it based on internal state.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>reward (object):</strong>  The reward object to be patched, which must have an 'outcome' attribute.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>object: The possibly modified deep copy of the original reward.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.compute_madness" class="classattr">
                                        <input id="Linear_CMT.compute_madness-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_madness</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="nb">float</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.compute_madness-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.compute_madness"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.compute_madness-565"><a href="#Linear_CMT.compute_madness-565"><span class="linenos">565</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_madness</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="Linear_CMT.compute_madness-566"><a href="#Linear_CMT.compute_madness-566"><span class="linenos">566</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.compute_madness-567"><a href="#Linear_CMT.compute_madness-567"><span class="linenos">567</span></a><span class="sd">        Evaluates the &#39;madness&#39; of the model&#39;s output based on the proportion of certain types of mistakes (e.g., special tokens, repeated characters, non-ASCII characters).</span>
</span><span id="Linear_CMT.compute_madness-568"><a href="#Linear_CMT.compute_madness-568"><span class="linenos">568</span></a>
</span><span id="Linear_CMT.compute_madness-569"><a href="#Linear_CMT.compute_madness-569"><span class="linenos">569</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.compute_madness-570"><a href="#Linear_CMT.compute_madness-570"><span class="linenos">570</span></a><span class="sd">            float: -1.0 if any mistake proportion is below the threshold, otherwise 0.0.</span>
</span><span id="Linear_CMT.compute_madness-571"><a href="#Linear_CMT.compute_madness-571"><span class="linenos">571</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.compute_madness-572"><a href="#Linear_CMT.compute_madness-572"><span class="linenos">572</span></a>        <span class="n">threshold</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.01</span>
</span><span id="Linear_CMT.compute_madness-573"><a href="#Linear_CMT.compute_madness-573"><span class="linenos">573</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm_output_mistakes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="Linear_CMT.compute_madness-574"><a href="#Linear_CMT.compute_madness-574"><span class="linenos">574</span></a>            <span class="k">if</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span> <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span>  <span class="c1"># ⭐ Check if any mistake proportion is below the threshold</span>
</span><span id="Linear_CMT.compute_madness-575"><a href="#Linear_CMT.compute_madness-575"><span class="linenos">575</span></a>        <span class="k">return</span> <span class="mf">0.0</span>
</span></pre></div>


            <div class="docstring"><p>Evaluates the 'madness' of the model's output based on the proportion of certain types of mistakes (e.g., special tokens, repeated characters, non-ASCII characters).</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>float: -1.0 if any mistake proportion is below the threshold, otherwise 0.0.</p>
</blockquote>
</div>


                            </div>
                            <div id="Linear_CMT.tokenize_steps" class="classattr">
                                        <input id="Linear_CMT.tokenize_steps-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">tokenize_steps</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">ext_steps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n"><a href="cmt_base.html#ExtendedMessage">agentevolver.module.context_manager.cmt_base.ExtendedMessage</a></span><span class="p">]</span>,</span><span class="param">	<span class="n">debug</span><span class="o">=</span><span class="kc">False</span></span><span class="return-annotation">) -> <span class="nb">dict</span>:</span></span>

                <label class="view-source-button" for="Linear_CMT.tokenize_steps-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Linear_CMT.tokenize_steps"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Linear_CMT.tokenize_steps-578"><a href="#Linear_CMT.tokenize_steps-578"><span class="linenos">578</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ext_steps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExtendedMessage</span><span class="p">],</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="Linear_CMT.tokenize_steps-579"><a href="#Linear_CMT.tokenize_steps-579"><span class="linenos">579</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Linear_CMT.tokenize_steps-580"><a href="#Linear_CMT.tokenize_steps-580"><span class="linenos">580</span></a><span class="sd">        Tokenizes the given extended messages, processes them to separate prompts and responses, and prepares the data for model training.</span>
</span><span id="Linear_CMT.tokenize_steps-581"><a href="#Linear_CMT.tokenize_steps-581"><span class="linenos">581</span></a><span class="sd">        It also handles the extraction and discarding of experience information if needed.</span>
</span><span id="Linear_CMT.tokenize_steps-582"><a href="#Linear_CMT.tokenize_steps-582"><span class="linenos">582</span></a>
</span><span id="Linear_CMT.tokenize_steps-583"><a href="#Linear_CMT.tokenize_steps-583"><span class="linenos">583</span></a><span class="sd">        Args:</span>
</span><span id="Linear_CMT.tokenize_steps-584"><a href="#Linear_CMT.tokenize_steps-584"><span class="linenos">584</span></a><span class="sd">            ext_steps (List[ExtendedMessage]): A list of ExtendedMessage objects representing the conversation context.</span>
</span><span id="Linear_CMT.tokenize_steps-585"><a href="#Linear_CMT.tokenize_steps-585"><span class="linenos">585</span></a><span class="sd">            debug (bool, optional): A flag to enable debugging. Defaults to False.</span>
</span><span id="Linear_CMT.tokenize_steps-586"><a href="#Linear_CMT.tokenize_steps-586"><span class="linenos">586</span></a>
</span><span id="Linear_CMT.tokenize_steps-587"><a href="#Linear_CMT.tokenize_steps-587"><span class="linenos">587</span></a><span class="sd">        Returns:</span>
</span><span id="Linear_CMT.tokenize_steps-588"><a href="#Linear_CMT.tokenize_steps-588"><span class="linenos">588</span></a><span class="sd">            dict: A dictionary containing tokenized and processed data for model training.</span>
</span><span id="Linear_CMT.tokenize_steps-589"><a href="#Linear_CMT.tokenize_steps-589"><span class="linenos">589</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Linear_CMT.tokenize_steps-590"><a href="#Linear_CMT.tokenize_steps-590"><span class="linenos">590</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_position_id_with_mask</span>
</span><span id="Linear_CMT.tokenize_steps-591"><a href="#Linear_CMT.tokenize_steps-591"><span class="linenos">591</span></a>        <span class="n">ext_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_last_non_llm_msg</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">))</span>  <span class="c1"># ⭐ Remove the last non-LLM message</span>
</span><span id="Linear_CMT.tokenize_steps-592"><a href="#Linear_CMT.tokenize_steps-592"><span class="linenos">592</span></a>
</span><span id="Linear_CMT.tokenize_steps-593"><a href="#Linear_CMT.tokenize_steps-593"><span class="linenos">593</span></a>        <span class="n">exp_worker</span> <span class="o">=</span> <span class="n">ExperienceWorker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-594"><a href="#Linear_CMT.tokenize_steps-594"><span class="linenos">594</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ext_steps</span><span class="p">):</span>
</span><span id="Linear_CMT.tokenize_steps-595"><a href="#Linear_CMT.tokenize_steps-595"><span class="linenos">595</span></a>            <span class="n">experience</span><span class="p">,</span> <span class="n">new_content</span> <span class="o">=</span> <span class="n">exp_worker</span><span class="o">.</span><span class="n">manage_training_context</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">content_for_future</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-596"><a href="#Linear_CMT.tokenize_steps-596"><span class="linenos">596</span></a>            <span class="k">if</span> <span class="n">experience</span><span class="p">:</span>
</span><span id="Linear_CMT.tokenize_steps-597"><a href="#Linear_CMT.tokenize_steps-597"><span class="linenos">597</span></a>                <span class="n">ext_steps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ExtendedMessage</span><span class="p">(</span>
</span><span id="Linear_CMT.tokenize_steps-598"><a href="#Linear_CMT.tokenize_steps-598"><span class="linenos">598</span></a>                    <span class="n">author</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-599"><a href="#Linear_CMT.tokenize_steps-599"><span class="linenos">599</span></a>                    <span class="n">role</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-600"><a href="#Linear_CMT.tokenize_steps-600"><span class="linenos">600</span></a>                    <span class="n">content</span><span class="o">=</span><span class="n">new_content</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-601"><a href="#Linear_CMT.tokenize_steps-601"><span class="linenos">601</span></a>                    <span class="n">token_generator</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-602"><a href="#Linear_CMT.tokenize_steps-602"><span class="linenos">602</span></a>                    <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-603"><a href="#Linear_CMT.tokenize_steps-603"><span class="linenos">603</span></a>                    <span class="n">uuid</span><span class="o">=</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">uuid</span><span class="p">,</span>
</span><span id="Linear_CMT.tokenize_steps-604"><a href="#Linear_CMT.tokenize_steps-604"><span class="linenos">604</span></a>                <span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-605"><a href="#Linear_CMT.tokenize_steps-605"><span class="linenos">605</span></a>
</span><span id="Linear_CMT.tokenize_steps-606"><a href="#Linear_CMT.tokenize_steps-606"><span class="linenos">606</span></a>        <span class="c1"># mapping</span>
</span><span id="Linear_CMT.tokenize_steps-607"><a href="#Linear_CMT.tokenize_steps-607"><span class="linenos">607</span></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT.tokenize_steps-608"><a href="#Linear_CMT.tokenize_steps-608"><span class="linenos">608</span></a>        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT.tokenize_steps-609"><a href="#Linear_CMT.tokenize_steps-609"><span class="linenos">609</span></a>        <span class="n">loss_mask</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Linear_CMT.tokenize_steps-610"><a href="#Linear_CMT.tokenize_steps-610"><span class="linenos">610</span></a>        <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="Linear_CMT.tokenize_steps-611"><a href="#Linear_CMT.tokenize_steps-611"><span class="linenos">611</span></a>        <span class="k">for</span> <span class="n">ext_msg</span> <span class="ow">in</span> <span class="n">ext_steps</span><span class="p">:</span>
</span><span id="Linear_CMT.tokenize_steps-612"><a href="#Linear_CMT.tokenize_steps-612"><span class="linenos">612</span></a>            <span class="c1"># find split index, this have to be done before input_ids += ext_msg.token_arr</span>
</span><span id="Linear_CMT.tokenize_steps-613"><a href="#Linear_CMT.tokenize_steps-613"><span class="linenos">613</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">split_prompt_reponse_index</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">need_training</span><span class="p">):</span>
</span><span id="Linear_CMT.tokenize_steps-614"><a href="#Linear_CMT.tokenize_steps-614"><span class="linenos">614</span></a>                <span class="n">split_prompt_reponse_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-615"><a href="#Linear_CMT.tokenize_steps-615"><span class="linenos">615</span></a>                <span class="k">assert</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">author</span> <span class="o">==</span> <span class="s1">&#39;llm&#39;</span><span class="p">,</span> <span class="s2">&quot;The first message after initialization should be from LLM, not from env or user&quot;</span>
</span><span id="Linear_CMT.tokenize_steps-616"><a href="#Linear_CMT.tokenize_steps-616"><span class="linenos">616</span></a>            <span class="n">input_ids</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span>
</span><span id="Linear_CMT.tokenize_steps-617"><a href="#Linear_CMT.tokenize_steps-617"><span class="linenos">617</span></a>            <span class="n">attention_mask</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ext_msg</span><span class="o">.</span><span class="n">token_arr</span><span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-618"><a href="#Linear_CMT.tokenize_steps-618"><span class="linenos">618</span></a>            <span class="n">loss_mask</span> <span class="o">+=</span> <span class="n">ext_msg</span><span class="o">.</span><span class="n">get_loss_mask</span><span class="p">(</span><span class="n">blackout_token_combo</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">blackout_token_combo</span><span class="p">)</span>
</span><span id="Linear_CMT.tokenize_steps-619"><a href="#Linear_CMT.tokenize_steps-619"><span class="linenos">619</span></a>
</span><span id="Linear_CMT.tokenize_steps-620"><a href="#Linear_CMT.tokenize_steps-620"><span class="linenos">620</span></a>        <span class="k">assert</span> <span class="n">split_prompt_reponse_index</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;split_prompt_reponse_index should not be -1, at least one message should be in the context&quot;</span>
</span><span id="Linear_CMT.tokenize_steps-621"><a href="#Linear_CMT.tokenize_steps-621"><span class="linenos">621</span></a>        <span class="n">position_ids</span> <span class="o">=</span> <span class="n">compute_position_id_with_mask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ⭐ Compute position IDs with mask</span>
</span><span id="Linear_CMT.tokenize_steps-622"><a href="#Linear_CMT.tokenize_steps-622"><span class="linenos">622</span></a>
</span><span id="Linear_CMT.tokenize_steps-623"><a href="#Linear_CMT.tokenize_steps-623"><span class="linenos">623</span></a>        <span class="c1"># separate prompt and response</span>
</span><span id="Linear_CMT.tokenize_steps-624"><a href="#Linear_CMT.tokenize_steps-624"><span class="linenos">624</span></a>        <span class="n">prompt_ids</span> <span class="o">=</span>            <span class="n">input_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT.tokenize_steps-625"><a href="#Linear_CMT.tokenize_steps-625"><span class="linenos">625</span></a>        <span class="n">prompt_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT.tokenize_steps-626"><a href="#Linear_CMT.tokenize_steps-626"><span class="linenos">626</span></a>        <span class="n">prompt_position_ids</span> <span class="o">=</span>   <span class="n">position_ids</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT.tokenize_steps-627"><a href="#Linear_CMT.tokenize_steps-627"><span class="linenos">627</span></a>        <span class="n">prompt_loss_mask</span> <span class="o">=</span>      <span class="n">loss_mask</span><span class="p">[:</span><span class="n">split_prompt_reponse_index</span><span class="p">]</span>
</span><span id="Linear_CMT.tokenize_steps-628"><a href="#Linear_CMT.tokenize_steps-628"><span class="linenos">628</span></a>
</span><span id="Linear_CMT.tokenize_steps-629"><a href="#Linear_CMT.tokenize_steps-629"><span class="linenos">629</span></a>        <span class="n">response_ids</span> <span class="o">=</span>              <span class="n">input_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT.tokenize_steps-630"><a href="#Linear_CMT.tokenize_steps-630"><span class="linenos">630</span></a>        <span class="n">response_attention_mask</span> <span class="o">=</span>   <span class="n">attention_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT.tokenize_steps-631"><a href="#Linear_CMT.tokenize_steps-631"><span class="linenos">631</span></a>        <span class="n">response_position_ids</span> <span class="o">=</span>     <span class="n">position_ids</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT.tokenize_steps-632"><a href="#Linear_CMT.tokenize_steps-632"><span class="linenos">632</span></a>        <span class="n">response_loss_mask</span> <span class="o">=</span>        <span class="n">loss_mask</span><span class="p">[</span><span class="n">split_prompt_reponse_index</span><span class="p">:]</span>
</span><span id="Linear_CMT.tokenize_steps-633"><a href="#Linear_CMT.tokenize_steps-633"><span class="linenos">633</span></a>
</span><span id="Linear_CMT.tokenize_steps-634"><a href="#Linear_CMT.tokenize_steps-634"><span class="linenos">634</span></a>        <span class="n">cmt_tokenized</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Linear_CMT.tokenize_steps-635"><a href="#Linear_CMT.tokenize_steps-635"><span class="linenos">635</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ids</span>
</span><span id="Linear_CMT.tokenize_steps-636"><a href="#Linear_CMT.tokenize_steps-636"><span class="linenos">636</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_ids</span>
</span><span id="Linear_CMT.tokenize_steps-637"><a href="#Linear_CMT.tokenize_steps-637"><span class="linenos">637</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_ids</span>
</span><span id="Linear_CMT.tokenize_steps-638"><a href="#Linear_CMT.tokenize_steps-638"><span class="linenos">638</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>
</span><span id="Linear_CMT.tokenize_steps-639"><a href="#Linear_CMT.tokenize_steps-639"><span class="linenos">639</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_attention_mask</span>
</span><span id="Linear_CMT.tokenize_steps-640"><a href="#Linear_CMT.tokenize_steps-640"><span class="linenos">640</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_attention_mask</span>
</span><span id="Linear_CMT.tokenize_steps-641"><a href="#Linear_CMT.tokenize_steps-641"><span class="linenos">641</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_mask</span>
</span><span id="Linear_CMT.tokenize_steps-642"><a href="#Linear_CMT.tokenize_steps-642"><span class="linenos">642</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_loss_mask</span>
</span><span id="Linear_CMT.tokenize_steps-643"><a href="#Linear_CMT.tokenize_steps-643"><span class="linenos">643</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_loss_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_loss_mask</span>
</span><span id="Linear_CMT.tokenize_steps-644"><a href="#Linear_CMT.tokenize_steps-644"><span class="linenos">644</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">position_ids</span>
</span><span id="Linear_CMT.tokenize_steps-645"><a href="#Linear_CMT.tokenize_steps-645"><span class="linenos">645</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;prompt_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_position_ids</span>
</span><span id="Linear_CMT.tokenize_steps-646"><a href="#Linear_CMT.tokenize_steps-646"><span class="linenos">646</span></a>        <span class="n">cmt_tokenized</span><span class="p">[</span><span class="s2">&quot;response_position_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response_position_ids</span>
</span><span id="Linear_CMT.tokenize_steps-647"><a href="#Linear_CMT.tokenize_steps-647"><span class="linenos">647</span></a>
</span><span id="Linear_CMT.tokenize_steps-648"><a href="#Linear_CMT.tokenize_steps-648"><span class="linenos">648</span></a>        <span class="k">return</span> <span class="n">cmt_tokenized</span>
</span></pre></div>


            <div class="docstring"><p>Tokenizes the given extended messages, processes them to separate prompts and responses, and prepares the data for model training.
It also handles the extraction and discarding of experience information if needed.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>ext_steps (List[ExtendedMessage]):</strong>  A list of ExtendedMessage objects representing the conversation context.</li>
<li><strong>debug (bool, optional):</strong>  A flag to enable debugging. Defaults to False.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>dict: A dictionary containing tokenized and processed data for model training.</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="../../schema/trajectory.html#Trajectory">agentevolver.schema.trajectory.Trajectory</a></dt>
                                <dd id="Linear_CMT.data_id" class="variable"><a href="../../schema/trajectory.html#Trajectory.data_id">data_id</a></dd>
                <dd id="Linear_CMT.rollout_id" class="variable"><a href="../../schema/trajectory.html#Trajectory.rollout_id">rollout_id</a></dd>
                <dd id="Linear_CMT.query" class="variable"><a href="../../schema/trajectory.html#Trajectory.query">query</a></dd>
                <dd id="Linear_CMT.metadata" class="variable"><a href="../../schema/trajectory.html#Trajectory.metadata">metadata</a></dd>
                <dd id="Linear_CMT.success" class="variable"><a href="../../schema/trajectory.html#Trajectory.success">success</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>