<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 16.0.0"/>
    <title>agentevolver.module.trainer.ae_ray_trainer API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:27px;vertical-align:bottom;width:50px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../trainer.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;agentevolver.module.trainer</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="function" href="#parse_reward_from_dataproto">parse_reward_from_dataproto</a>
            </li>
            <li>
                    <a class="function" href="#create_rl_sampler">create_rl_sampler</a>
            </li>
            <li>
                    <a class="function" href="#union_gen_batch_via_task_id">union_gen_batch_via_task_id</a>
            </li>
            <li>
                    <a class="function" href="#compute_grpo_outcome_advantage">compute_grpo_outcome_advantage</a>
            </li>
            <li>
                    <a class="function" href="#compute_advantage">compute_advantage</a>
            </li>
            <li>
                    <a class="class" href="#AgentEvolverRayPPOTrainer">AgentEvolverRayPPOTrainer</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#AgentEvolverRayPPOTrainer.__init__">AgentEvolverRayPPOTrainer</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.tokenizer">tokenizer</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.processor">processor</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.config">config</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.reward_fn">reward_fn</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.val_reward_fn">val_reward_fn</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.hybrid_engine">hybrid_engine</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.role_worker_mapping">role_worker_mapping</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.resource_pool_manager">resource_pool_manager</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.use_reference_policy">use_reference_policy</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.use_rm">use_rm</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.ray_worker_group_cls">ray_worker_group_cls</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.device_name">device_name</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.validation_generations_logger">validation_generations_logger</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.ref_in_actor">ref_in_actor</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.env_manager">env_manager</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.thread_pool">thread_pool</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.train_task_manager">train_task_manager</a>
                        </li>
                        <li>
                                <a class="variable" href="#AgentEvolverRayPPOTrainer.val_task_manager">val_task_manager</a>
                        </li>
                        <li>
                                <a class="function" href="#AgentEvolverRayPPOTrainer.init_workers">init_workers</a>
                        </li>
                        <li>
                                <a class="function" href="#AgentEvolverRayPPOTrainer.initialize_exp_pool">initialize_exp_pool</a>
                        </li>
                        <li>
                                <a class="function" href="#AgentEvolverRayPPOTrainer.fit">fit</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22160%22%20viewBox%3D%220%200%20150%2080%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M132.316%2048.886c.276-4.679%202.342-6.698%204.409-7.982s4.27-1.165%206.751-1.055c1.586.07%203.044.156%204.222-.482%201.142-.619%202.026-1.932%202.162-3.739.268-3.576-1.929-5.368-5.006-5.551s-7.599.524-10.517%201.606c-4.455%201.652-8.588%206.606-9.552%208.992s-2.342%206.193-1.745%2010.873%202.664%209.221%205.878%2011.79%205.878%203.808%2010.103%204.312%203.444.229%206.062.229%205.006-2.202%204.914-4.909-2.296-5.001-4.501-4.863-3.077.505-5.281.229-7.715-2.064-7.899-9.451z%22%20fill%3D%22%23198754%22/%3E%3Ccircle%20cx%3D%22101.504%22%20cy%3D%2248.943%22%20r%3D%2214.208%22%20fill%3D%22none%22%20stroke%3D%22%23198754%22%20stroke-width%3D%229.354%22/%3E%3Cpath%20d%3D%22M87.81.002c-3.637.065-5.001.454-7.014%201.232s-3.443%201.363-6.3%204.282c-1.723%201.76-3.148%205.019-3.776%207.329-.413%201.521-.316%202.63-.316%202.63l-.195%2034.612c.065%205.774-6.755%208.305-9.612%208.37s-9.678-1.038-9.743-9.408%207.128-9.521%208.362-9.521c1.413-.13%202.526-.021%203.718-.016%202.071.009%204.157-.778%204.092-4.671s-4.157-4.736-4.157-4.736c-6.3-.843-11.43%202.206-11.43%202.206S40.917%2038.15%2041.372%2049.634%2051.568%2068.19%2061.311%2068.125s18.316-7.007%2018.445-17.193l.13-22.772c.046-2.291%202.683-3.644%204.476-4.203.745-.232%201.694-.274%201.694-.274l10.457-.13s4.871-.324%207.729-3.114%204.352-6.294%204.352-6.294.974-3.049.13-4.606-.195-1.233-2.792-3.309-8.573-4.477-8.573-4.477S91.447-.063%2087.81.002zM0%2047.169l.065%2028.417S0%2080.127%204.481%2079.997s5.072-3.866%205.049-4.152l-.113-28.482s1.624-7.656%209.937-7.721%2010.002%206.942%2010.002%208.499-.909%2010.51-9.093%2010.51c-.948%200-2.99-.567-4.145-.272-3.919%201-3.194%204.554-3.194%204.554s.065%205.061%207.404%204.996%2018.575-6.034%2018.575-19.074S26.953%2030.04%2019.549%2029.91%201.234%2035.296%200%2047.169z%22%20fill%3D%22%23198754%22/%3E%3Cg%20transform%3D%22matrix%28.325601%200%200%20.325256%20-10.32669%20-45.802786%29%22%3E%3Ccircle%20cx%3D%22297.554%22%20cy%3D%22172.286%22%20r%3D%2216.5%22%20fill%3D%22%23fff%22/%3E%3Cellipse%20cx%3D%22297.709%22%20cy%3D%22172.642%22%20rx%3D%2211.071%22%20ry%3D%2210.871%22%20fill%3D%22%23105a48%22/%3E%3Ccircle%20cx%3D%22304.104%22%20cy%3D%22167.667%22%20r%3D%224.5%22%20fill%3D%22%23fff%22/%3E%3C/g%3E%3Cpath%20d%3D%22M94.661%2017.032l.893-1.476s.99.714%201.916.925%201.575.114%202.955.114l14.565-.162c1.283-.032%203.085-.762%203.02-3.293s-.373-3.503-.373-3.503l1.283-.487s.52.503.877%201.573.309%201.995.292%202.66-.227%201.541-.227%201.541%201.564-.308%202.359-1.038.823-.779%201.489-1.508.812-.86.812-.86.552-.13.877.26.341.957.065%201.46-1.672%202.206-3.247%203.066-2.76%201.427-3.929%201.768-3.848.73-7.063.714l-10.944-.114s-2.143-.081-3.02-.373-2.241-.973-2.598-1.265z%22%20fill%3D%22%23d36d49%22/%3E%3Cg%20fill%3D%22%23105a48%22%3E%3Cellipse%20cx%3D%2293.052%22%20cy%3D%2243.567%22%20rx%3D%22.869%22%20ry%3D%221.014%22%20transform%3D%22rotate%28341.022%29%22/%3E%3Cellipse%20cx%3D%22104.3%22%20cy%3D%22-16.184%22%20rx%3D%22.865%22%20ry%3D%221.009%22%20transform%3D%22rotate%2814.786%29%22/%3E%3C/g%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../../agentevolver.html">agentevolver</a><wbr>.<a href="./../../module.html">module</a><wbr>.<a href="./../trainer.html">trainer</a><wbr>.ae_ray_trainer    </h1>

                        <div class="docstring"><p>FSDP PPO Trainer with Ray-based single controller.
This trainer supports model-agonistic model initialization with huggingface</p>
</div>

                        <input id="mod-ae_ray_trainer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-ae_ray_trainer-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">   1</span></a><span class="c1"># Copyright 2024 Bytedance Ltd. and/or its affiliates</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">   2</span></a><span class="c1"># Modifications copyright 2025 Alibaba Tongyi EconML Lab. and/or its affiliates</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">   3</span></a><span class="c1">#</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">   4</span></a><span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">   5</span></a><span class="c1"># you may not use this file except in compliance with the License.</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">   6</span></a><span class="c1"># You may obtain a copy of the License at</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">   7</span></a><span class="c1">#</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">   8</span></a><span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">   9</span></a><span class="c1">#</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">  10</span></a><span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">  11</span></a><span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">  12</span></a><span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">  13</span></a><span class="c1"># See the License for the specific language governing permissions and</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">  14</span></a><span class="c1"># limitations under the License.</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">  15</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">  16</span></a><span class="sd">FSDP PPO Trainer with Ray-based single controller.</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">  17</span></a><span class="sd">This trainer supports model-agonistic model initialization with huggingface</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">  18</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">  19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos">  20</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">  21</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">uuid</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">  22</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">  23</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">concurrent.futures.thread</span><span class="w"> </span><span class="kn">import</span> <span class="n">ThreadPoolExecutor</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">  24</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">  25</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">pprint</span><span class="w"> </span><span class="kn">import</span> <span class="n">pprint</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">  26</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">  27</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">  28</span></a>
</span><span id="L-29"><a href="#L-29"><span class="linenos">  29</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">  30</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">  31</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">ray</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">  32</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos">  33</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">  34</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">  35</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span><span class="p">,</span> <span class="n">open_dict</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">  36</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">  37</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">SequentialSampler</span><span class="p">,</span><span class="n">IterableDataset</span><span class="p">,</span><span class="n">Dataset</span><span class="p">,</span><span class="n">Sampler</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos">  38</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">torchdata.stateful_dataloader</span><span class="w"> </span><span class="kn">import</span> <span class="n">StatefulDataLoader</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos">  39</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.client.env_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">EnvClient</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">  40</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager.task_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoReloadDataset</span><span class="p">,</span> <span class="n">FullDataset</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">  41</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProto</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos">  42</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.single_controller.ray</span><span class="w"> </span><span class="kn">import</span> <span class="n">RayClassWithInitArgs</span><span class="p">,</span> <span class="n">create_colocated_worker_cls</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos">  43</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.single_controller.ray.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">RayWorkerGroup</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">  44</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.ppo</span><span class="w"> </span><span class="kn">import</span> <span class="n">core_algos</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos">  45</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.ppo.core_algos</span><span class="w"> </span><span class="kn">import</span> <span class="n">agg_loss</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">  46</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.metric_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">compute_data_metrics</span><span class="p">,</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">  47</span></a>                                           <span class="n">compute_throughout_metrics</span><span class="p">,</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos">  48</span></a>                                           <span class="n">compute_timing_metrics</span><span class="p">,</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos">  49</span></a>                                           <span class="n">process_validation_metrics</span><span class="p">)</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos">  50</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.ppo.ray_trainer</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">AdvantageEstimator</span><span class="p">,</span> <span class="n">RayPPOTrainer</span><span class="p">,</span> <span class="n">ResourcePoolManager</span><span class="p">,</span> <span class="n">WorkerType</span><span class="p">,</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">  51</span></a>                                          <span class="n">_timer</span><span class="p">,</span> <span class="n">apply_kl_penalty</span><span class="p">,</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos">  52</span></a>                                          <span class="n">compute_response_mask</span><span class="p">,</span> <span class="n">Role</span><span class="p">)</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos">  53</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.ppo.reward</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_reward</span><span class="p">,</span> <span class="n">compute_reward_async</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos">  54</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.dataset.rl_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">RLHFDataset</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos">  55</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.metric</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce_metrics</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos">  56</span></a>
</span><span id="L-57"><a href="#L-57"><span class="linenos">  57</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.client.llm_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">DashScopeClient</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos">  58</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.client.em_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">EMClient</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos">  59</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.env_manager.env_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParallelEnvManager</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos">  60</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">adapter</span> <span class="k">as</span> <span class="n">task_adapter</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos">  61</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">TaskManager</span><span class="p">,</span><span class="n">NaiveTaskObjectiveRetrieval</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos">  62</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.schema.task</span><span class="w"> </span><span class="kn">import</span> <span class="n">Task</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos">  63</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.schema.trajectory</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trajectory</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos">  64</span></a>
</span><span id="L-65"><a href="#L-65"><span class="linenos">  65</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">ValidationGenerationsLogger</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos">  66</span></a>
</span><span id="L-67"><a href="#L-67"><span class="linenos">  67</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.adv_processor.adca_grpo_pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">apply_adca_grpo</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos">  68</span></a>
</span><span id="L-69"><a href="#L-69"><span class="linenos">  69</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.exp_manager.exp_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExperienceManager</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">  70</span></a>
</span><span id="L-71"><a href="#L-71"><span class="linenos">  71</span></a>
</span><span id="L-72"><a href="#L-72"><span class="linenos">  72</span></a><span class="k">def</span><span class="w"> </span><span class="nf">parse_reward_from_dataproto</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">  73</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos">  74</span></a><span class="sd">    Compute reward for a batch of data.</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">  75</span></a>
</span><span id="L-76"><a href="#L-76"><span class="linenos">  76</span></a><span class="sd">    Args:</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos">  77</span></a><span class="sd">        data: DataProto object containing the input data.</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos">  78</span></a><span class="sd">        return_dict: Whether to return a dictionary or just the reward tensor.</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">  79</span></a>
</span><span id="L-80"><a href="#L-80"><span class="linenos">  80</span></a><span class="sd">    Returns:</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">  81</span></a><span class="sd">        Tensor of shape (bs, response_len) if return_dict is False,</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos">  82</span></a><span class="sd">        or a dict with &#39;reward_tensor&#39; and &#39;reward_extra_info&#39;.</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">  83</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">  84</span></a>    <span class="c1"># Within DataFlow, world.execute() will pass a float score, which will be contained in the DataProto.non_tensor_batch(&#39;reward_scores&#39;)</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos">  85</span></a>
</span><span id="L-86"><a href="#L-86"><span class="linenos">  86</span></a>    <span class="c1"># Initialize reward tensor</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">  87</span></a>    <span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (bs, reslen)  # ‚≠ê Initialize the reward tensor</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">  88</span></a>    <span class="n">reward_extra_info</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos">  89</span></a>
</span><span id="L-90"><a href="#L-90"><span class="linenos">  90</span></a>    <span class="c1"># Batch-level processing</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos">  91</span></a>    <span class="n">prompt_ids_batch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span>  <span class="c1"># (bs, prompt_len)</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos">  92</span></a>    <span class="n">prompt_lengths</span> <span class="o">=</span> <span class="n">prompt_ids_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos">  93</span></a>
</span><span id="L-94"><a href="#L-94"><span class="linenos">  94</span></a>    <span class="c1"># Get attention masks for all items</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">  95</span></a>    <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>  <span class="c1"># (bs, total_len)</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos">  96</span></a>    <span class="n">response_lengths</span> <span class="o">=</span> <span class="n">attention_masks</span><span class="p">[:,</span> <span class="n">prompt_lengths</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (bs, )</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos">  97</span></a>
</span><span id="L-98"><a href="#L-98"><span class="linenos">  98</span></a>    <span class="c1"># Get reward scores</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">  99</span></a>    <span class="n">reward_scores_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;outcome&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_scores&quot;</span><span class="p">]]</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos"> 100</span></a>    <span class="n">reward_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">reward_scores_list</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">reward_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (bs, )  # ‚≠ê Convert reward scores to a tensor</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos"> 101</span></a>
</span><span id="L-102"><a href="#L-102"><span class="linenos"> 102</span></a>    <span class="c1"># Use advanced indexing to assign rewards</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos"> 103</span></a>    <span class="n">reward_tensor</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)),</span> <span class="n">response_lengths</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_scores</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos"> 104</span></a>
</span><span id="L-105"><a href="#L-105"><span class="linenos"> 105</span></a>    <span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos"> 106</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos"> 107</span></a>            <span class="s2">&quot;reward_tensor&quot;</span><span class="p">:</span> <span class="n">reward_tensor</span><span class="p">,</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos"> 108</span></a>            <span class="s2">&quot;reward_extra_info&quot;</span><span class="p">:</span> <span class="n">reward_extra_info</span><span class="p">,</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos"> 109</span></a>        <span class="p">}</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos"> 110</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos"> 111</span></a>        <span class="k">return</span> <span class="n">reward_tensor</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos"> 112</span></a>
</span><span id="L-113"><a href="#L-113"><span class="linenos"> 113</span></a>
</span><span id="L-114"><a href="#L-114"><span class="linenos"> 114</span></a><span class="k">def</span><span class="w"> </span><span class="nf">create_rl_sampler</span><span class="p">(</span><span class="n">data_config</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos"> 115</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a sampler for the dataset.</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos"> 116</span></a>
</span><span id="L-117"><a href="#L-117"><span class="linenos"> 117</span></a><span class="sd">    Arguments:</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos"> 118</span></a><span class="sd">        data_config: The data config.</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos"> 119</span></a><span class="sd">        dataset (Dataset): The dataset.</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos"> 120</span></a>
</span><span id="L-121"><a href="#L-121"><span class="linenos"> 121</span></a><span class="sd">    Returns:</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos"> 122</span></a><span class="sd">        sampler (Sampler): The sampler.</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos"> 123</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos"> 124</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos"> 125</span></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos"> 126</span></a>
</span><span id="L-127"><a href="#L-127"><span class="linenos"> 127</span></a>    <span class="c1"># use sampler for better ckpt resume</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos"> 128</span></a>    <span class="k">if</span> <span class="n">data_config</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos"> 129</span></a>        <span class="n">train_dataloader_generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos"> 130</span></a>        <span class="n">train_dataloader_generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">data_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos"> 131</span></a>        <span class="n">sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">train_dataloader_generator</span><span class="p">)</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos"> 132</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos"> 133</span></a>        <span class="n">sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos"> 134</span></a>
</span><span id="L-135"><a href="#L-135"><span class="linenos"> 135</span></a>    <span class="k">return</span> <span class="n">sampler</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos"> 136</span></a>
</span><span id="L-137"><a href="#L-137"><span class="linenos"> 137</span></a><span class="k">def</span><span class="w"> </span><span class="nf">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">gen_batch_output</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">):</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos"> 138</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos"> 139</span></a><span class="sd">    Merges the `gen_batch_output` with the `batch` based on the `task_id`.</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos"> 140</span></a>
</span><span id="L-141"><a href="#L-141"><span class="linenos"> 141</span></a><span class="sd">    Args:</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos"> 142</span></a><span class="sd">        tasks (list): A list of task objects, each containing a `task_id`.</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos"> 143</span></a><span class="sd">        batch (DataProto): The original batch of data.</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos"> 144</span></a><span class="sd">        gen_batch_output (DataProto): The generated batch output that needs to be merged.</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos"> 145</span></a>
</span><span id="L-146"><a href="#L-146"><span class="linenos"> 146</span></a><span class="sd">    Returns:</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos"> 147</span></a><span class="sd">        DataProto: The final merged batch.</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos"> 148</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos"> 149</span></a>    <span class="n">map_task_id_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="o">.</span><span class="n">task_id</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="p">)}</span>  <span class="c1"># ‚≠ê Create a mapping from task_id to its index in tasks</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos"> 150</span></a>    <span class="n">gen_task_task_ids</span> <span class="o">=</span> <span class="n">gen_batch_output</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;task_ids&#39;</span><span class="p">]</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos"> 151</span></a>    <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_task_id_to_index</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">gen_task_task_ids</span><span class="p">]</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos"> 152</span></a>    <span class="n">batch_extend</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">select_idxs</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos"> 153</span></a>    <span class="n">batch_final</span> <span class="o">=</span> <span class="n">batch_extend</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_batch_output</span><span class="p">)</span>  <span class="c1"># ‚≠ê Merge the selected part of the batch with the gen_batch_output</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos"> 154</span></a>    <span class="k">return</span> <span class="n">batch_final</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos"> 155</span></a>
</span><span id="L-156"><a href="#L-156"><span class="linenos"> 156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos"> 157</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_grpo_outcome_advantage</span><span class="p">(</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos"> 158</span></a>    <span class="n">token_level_rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos"> 159</span></a>    <span class="n">response_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos"> 160</span></a>    <span class="n">index</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos"> 161</span></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos"> 162</span></a>    <span class="n">norm_adv_by_std_in_grpo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos"> 163</span></a><span class="p">):</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos"> 164</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos"> 165</span></a><span class="sd">    Compute advantage for GRPO, operating only on Outcome reward</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos"> 166</span></a><span class="sd">    (with only one scalar reward for each response).</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos"> 167</span></a>
</span><span id="L-168"><a href="#L-168"><span class="linenos"> 168</span></a><span class="sd">    Args:</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos"> 169</span></a><span class="sd">        token_level_rewards: `(torch.Tensor)`</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos"> 170</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos"> 171</span></a><span class="sd">        response_mask: `(torch.Tensor)`</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos"> 172</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos"> 173</span></a><span class="sd">        norm_adv_by_std_in_grpo: (bool)</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos"> 174</span></a><span class="sd">            whether to scale the GRPO advantage.</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos"> 175</span></a><span class="sd">            If True, the advantage is scaled by the std, as in the original GRPO.</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos"> 176</span></a><span class="sd">            If False, the advantage is not scaled, as in Dr.GRPO (https://arxiv.org/abs/2503.20783).</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos"> 177</span></a>
</span><span id="L-178"><a href="#L-178"><span class="linenos"> 178</span></a><span class="sd">    Returns:</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos"> 179</span></a><span class="sd">        advantages: `(torch.Tensor)`</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos"> 180</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos"> 181</span></a><span class="sd">        Returns: `(torch.Tensor)`</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos"> 182</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos"> 183</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos"> 184</span></a>    <span class="n">scores</span> <span class="o">=</span> <span class="n">token_level_rewards</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos"> 185</span></a>
</span><span id="L-186"><a href="#L-186"><span class="linenos"> 186</span></a>    <span class="n">id2score</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos"> 187</span></a>    <span class="n">id2mean</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos"> 188</span></a>    <span class="n">id2std</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos"> 189</span></a>
</span><span id="L-190"><a href="#L-190"><span class="linenos"> 190</span></a>    <span class="k">if</span> <span class="n">scores</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">!=</span><span class="mi">1</span><span class="p">:</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos"> 191</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;scores.dim()!=1&quot;</span><span class="p">)</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos"> 192</span></a>
</span><span id="L-193"><a href="#L-193"><span class="linenos"> 193</span></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos"> 194</span></a>        <span class="n">bsz</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos"> 195</span></a>        
</span><span id="L-196"><a href="#L-196"><span class="linenos"> 196</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bsz</span><span class="p">):</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos"> 197</span></a>            <span class="n">id2score</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos"> 198</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">id2score</span><span class="p">:</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos"> 199</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos"> 200</span></a>                <span class="n">id2mean</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos"> 201</span></a>                <span class="n">id2std</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos"> 202</span></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos"> 203</span></a>                <span class="n">id2mean</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos"> 204</span></a>                <span class="n">id2std</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">]]))</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos"> 205</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos"> 206</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;no score in prompt index: </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos"> 207</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bsz</span><span class="p">):</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos"> 208</span></a>            <span class="k">if</span> <span class="n">norm_adv_by_std_in_grpo</span><span class="p">:</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos"> 209</span></a>                <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">id2mean</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span> <span class="o">/</span> <span class="p">(</span><span class="n">id2std</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos"> 210</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos"> 211</span></a>                <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">id2mean</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos"> 212</span></a>                <span class="c1"># no std</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos"> 213</span></a>                <span class="c1"># if llm judge output similar rewards for undistinguishable samples, we may want to reduce its weight according to the batch std</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos"> 214</span></a>                <span class="c1"># scores[i] = scores[i] / (batch_std + epsilon)</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos"> 215</span></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">response_mask</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos"> 216</span></a>
</span><span id="L-217"><a href="#L-217"><span class="linenos"> 217</span></a>    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">scores</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos"> 218</span></a>
</span><span id="L-219"><a href="#L-219"><span class="linenos"> 219</span></a>
</span><span id="L-220"><a href="#L-220"><span class="linenos"> 220</span></a>
</span><span id="L-221"><a href="#L-221"><span class="linenos"> 221</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_advantage</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">adv_estimator</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">multi_turn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos"> 222</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos"> 223</span></a><span class="sd">    Compute advantage estimates for policy optimization.</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos"> 224</span></a>
</span><span id="L-225"><a href="#L-225"><span class="linenos"> 225</span></a><span class="sd">    This function computes advantage estimates using various estimators like GAE, GRPO, REINFORCE++, etc.</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos"> 226</span></a><span class="sd">    The advantage estimates are used to guide policy optimization in RL algorithms.</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos"> 227</span></a>
</span><span id="L-228"><a href="#L-228"><span class="linenos"> 228</span></a><span class="sd">    Args:</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos"> 229</span></a><span class="sd">        data (DataProto): The data containing batched model outputs and inputs.</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos"> 230</span></a><span class="sd">        adv_estimator: The advantage estimator to use (e.g., GAE, GRPO, REINFORCE++).</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos"> 231</span></a><span class="sd">        gamma (float, optional): Discount factor for future rewards. Defaults to 1.0.</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos"> 232</span></a><span class="sd">        lam (float, optional): Lambda parameter for GAE. Defaults to 1.0.</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos"> 233</span></a><span class="sd">        num_repeat (int, optional): Number of times to repeat the computation. Defaults to 1.</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos"> 234</span></a><span class="sd">        multi_turn (bool, optional): Whether the data is from a multi-turn conversation. Defaults to False.</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos"> 235</span></a><span class="sd">        norm_adv_by_std_in_grpo (bool, optional): Whether to normalize advantages by standard deviation in GRPO. Defaults to True.</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos"> 236</span></a><span class="sd">        config (dict, optional): Configuration dictionary for algorithm settings. Defaults to None.</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos"> 237</span></a>
</span><span id="L-238"><a href="#L-238"><span class="linenos"> 238</span></a><span class="sd">    Returns:</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos"> 239</span></a><span class="sd">        DataProto: The updated data with computed advantages and returns.</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos"> 240</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos"> 241</span></a>    <span class="c1"># Back-compatible with trainers that do not compute response mask in fit</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos"> 242</span></a>    <span class="k">if</span> <span class="s2">&quot;response_mask&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos"> 243</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos"> 244</span></a>    <span class="c1"># prepare response group</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos"> 245</span></a>    <span class="k">if</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos"> 246</span></a>        <span class="c1"># Compute advantages and returns using Generalized Advantage Estimation (GAE)</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos"> 247</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_gae_advantage_return</span><span class="p">(</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos"> 248</span></a>            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos"> 249</span></a>            <span class="n">values</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">],</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos"> 250</span></a>            <span class="n">response_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos"> 251</span></a>            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos"> 252</span></a>            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos"> 253</span></a>        <span class="p">)</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos"> 254</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos"> 255</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos"> 256</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_pf_ppo&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos"> 257</span></a>            <span class="n">data</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_pf_ppo_reweight_data</span><span class="p">(</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos"> 258</span></a>                <span class="n">data</span><span class="p">,</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos"> 259</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pf_ppo_reweight_method&quot;</span><span class="p">,</span> <span class="s2">&quot;pow&quot;</span><span class="p">),</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos"> 260</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pf_ppo_weight_pow&quot;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos"> 261</span></a>            <span class="p">)</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos"> 262</span></a>    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">:</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos"> 263</span></a>        <span class="c1"># Initialize the mask for GRPO calculation</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos"> 264</span></a>        <span class="n">grpo_calculation_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos"> 265</span></a>        <span class="k">if</span> <span class="n">multi_turn</span><span class="p">:</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos"> 266</span></a>            <span class="c1"># If multi-turn, replace the mask with the relevant part of loss_mask</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos"> 267</span></a>            <span class="c1"># Get length from the initial response mask</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos"> 268</span></a>            <span class="n">response_length</span> <span class="o">=</span> <span class="n">grpo_calculation_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos"> 269</span></a>            <span class="c1"># This mask is the one intended for GRPO</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos"> 270</span></a>            <span class="n">grpo_calculation_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">][:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos"> 271</span></a>        <span class="c1"># Call compute_grpo_outcome_advantage with parameters matching its definition</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos"> 272</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">compute_grpo_outcome_advantage</span><span class="p">(</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos"> 273</span></a>            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos"> 274</span></a>            <span class="n">response_mask</span><span class="o">=</span><span class="n">grpo_calculation_mask</span><span class="p">,</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos"> 275</span></a>            <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">],</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos"> 276</span></a>            <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="n">norm_adv_by_std_in_grpo</span><span class="p">,</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos"> 277</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Compute advantages and returns for GRPO</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos"> 278</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos"> 279</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos"> 280</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos"> 281</span></a>        <span class="c1"># handle all other adv estimator type other than GAE and GRPO</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos"> 282</span></a>        <span class="n">adv_estimator_fn</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_adv_estimator_fn</span><span class="p">(</span><span class="n">adv_estimator</span><span class="p">)</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos"> 283</span></a>        <span class="n">adv_kwargs</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos"> 284</span></a>            <span class="s2">&quot;token_level_rewards&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos"> 285</span></a>            <span class="s2">&quot;response_mask&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos"> 286</span></a>            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos"> 287</span></a>        <span class="p">}</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos"> 288</span></a>        <span class="k">if</span> <span class="s2">&quot;uid&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>  <span class="c1"># optional</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos"> 289</span></a>            <span class="n">adv_kwargs</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos"> 290</span></a>        <span class="k">if</span> <span class="s2">&quot;reward_baselines&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">:</span>  <span class="c1"># optional</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos"> 291</span></a>            <span class="n">adv_kwargs</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos"> 292</span></a>
</span><span id="L-293"><a href="#L-293"><span class="linenos"> 293</span></a>        <span class="c1"># calculate advantage estimator</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos"> 294</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">adv_estimator_fn</span><span class="p">(</span><span class="o">**</span><span class="n">adv_kwargs</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute advantages and returns for other estimators</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos"> 295</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos"> 296</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos"> 297</span></a>    <span class="k">return</span> <span class="n">data</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos"> 298</span></a>
</span><span id="L-299"><a href="#L-299"><span class="linenos"> 299</span></a>
</span><span id="L-300"><a href="#L-300"><span class="linenos"> 300</span></a><span class="k">class</span><span class="w"> </span><span class="nc">AgentEvolverRayPPOTrainer</span><span class="p">(</span><span class="n">RayPPOTrainer</span><span class="p">):</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos"> 301</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos"> 302</span></a><span class="sd">    Note that this trainer runs on the driver process on a single CPU/GPU node.</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos"> 303</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos"> 304</span></a>
</span><span id="L-305"><a href="#L-305"><span class="linenos"> 305</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos"> 306</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos"> 307</span></a>        <span class="n">config</span><span class="p">,</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos"> 308</span></a>        <span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos"> 309</span></a>        <span class="n">role_worker_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Role</span><span class="p">,</span> <span class="n">WorkerType</span><span class="p">],</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos"> 310</span></a>        <span class="n">resource_pool_manager</span><span class="p">:</span> <span class="n">ResourcePoolManager</span><span class="p">,</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos"> 311</span></a>        <span class="n">train_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos"> 312</span></a>        <span class="n">val_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos"> 313</span></a>        <span class="n">ray_worker_group_cls</span><span class="p">:</span> <span class="n">RayWorkerGroup</span> <span class="o">=</span> <span class="n">RayWorkerGroup</span><span class="p">,</span> <span class="c1"># type: ignore</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos"> 314</span></a>        <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos"> 315</span></a>        <span class="n">reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos"> 316</span></a>        <span class="n">val_reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos"> 317</span></a>        <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos"> 318</span></a>        <span class="n">shuffle_trainset</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos"> 319</span></a>        <span class="n">device_name</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos"> 320</span></a>    <span class="p">):</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos"> 321</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos"> 322</span></a><span class="sd">        Initialize distributed PPO trainer with Ray backend.</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos"> 323</span></a>
</span><span id="L-324"><a href="#L-324"><span class="linenos"> 324</span></a><span class="sd">        Args:</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos"> 325</span></a><span class="sd">            config: Configuration object containing various settings.</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos"> 326</span></a><span class="sd">            tokenizer: Tokenizer used for processing text.</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos"> 327</span></a><span class="sd">            role_worker_mapping (dict[Role, WorkerType]): Mapping of roles to worker types.</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos"> 328</span></a><span class="sd">            resource_pool_manager (ResourcePoolManager): Manager for resource pools.</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos"> 329</span></a><span class="sd">            train_task_manager (TaskManager): Task manager for training tasks.</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos"> 330</span></a><span class="sd">            val_task_manager (TaskManager): Task manager for validation tasks.</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos"> 331</span></a><span class="sd">            ray_worker_group_cls (RayWorkerGroup, optional): Class for Ray worker groups. Defaults to RayWorkerGroup.</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos"> 332</span></a><span class="sd">            processor (optional): Processor for additional data processing.</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos"> 333</span></a><span class="sd">            reward_fn (optional): Function to compute rewards.</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos"> 334</span></a><span class="sd">            val_reward_fn (optional): Function to compute validation rewards.</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos"> 335</span></a><span class="sd">            collate_fn (optional): Function to collate data.</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos"> 336</span></a><span class="sd">            shuffle_trainset (bool, optional): Whether to shuffle the training dataset. Defaults to False.</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos"> 337</span></a><span class="sd">            device_name (str, optional): Name of the device to use. Defaults to &quot;cuda&quot;.</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos"> 338</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos"> 339</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="L-340"><a href="#L-340"><span class="linenos"> 340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos"> 341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos"> 342</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">reward_fn</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos"> 343</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">val_reward_fn</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos"> 344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos"> 345</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">hybrid_engine</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos"> 346</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">,</span> <span class="s2">&quot;Currently, only support hybrid engine&quot;</span>  <span class="c1"># ‚≠ê Ensure the hybrid engine is supported</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos"> 347</span></a>
</span><span id="L-348"><a href="#L-348"><span class="linenos"> 348</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos"> 349</span></a>            <span class="k">assert</span> <span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">role_worker_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">=}</span><span class="s2">&quot;</span>  <span class="c1"># ‚≠ê Ensure ActorRollout role is present in the mapping</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos"> 350</span></a>
</span><span id="L-351"><a href="#L-351"><span class="linenos"> 351</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span> <span class="o">=</span> <span class="n">role_worker_mapping</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos"> 352</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span> <span class="o">=</span> <span class="n">resource_pool_manager</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos"> 353</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos"> 354</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos"> 355</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span> <span class="o">=</span> <span class="n">ray_worker_group_cls</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos"> 356</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_name</span> <span class="o">=</span> <span class="n">device_name</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos"> 357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_generations_logger</span> <span class="o">=</span> <span class="n">ValidationGenerationsLogger</span><span class="p">()</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos"> 358</span></a>
</span><span id="L-359"><a href="#L-359"><span class="linenos"> 359</span></a>        <span class="c1"># if ref_in_actor is True, the reference policy will be actor without lora applied</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos"> 360</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos"> 361</span></a>
</span><span id="L-362"><a href="#L-362"><span class="linenos"> 362</span></a>        <span class="c1"># define in-reward KL control</span>
</span><span id="L-363"><a href="#L-363"><span class="linenos"> 363</span></a>        <span class="c1"># kl loss control currently not suppoorted</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos"> 364</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos"> 365</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_kl_controller</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_ctrl</span><span class="p">)</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos"> 366</span></a>
</span><span id="L-367"><a href="#L-367"><span class="linenos"> 367</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos"> 368</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos"> 369</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos"> 370</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">,</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos"> 371</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO_PASSK</span><span class="p">,</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos"> 372</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS</span><span class="p">,</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos"> 373</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">,</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos"> 374</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">RLOO</span><span class="p">,</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos"> 375</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">OPO</span><span class="p">,</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos"> 376</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS_BASELINE</span><span class="p">,</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos"> 377</span></a>        <span class="p">]:</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos"> 378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos"> 379</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos"> 380</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos"> 381</span></a>
</span><span id="L-382"><a href="#L-382"><span class="linenos"> 382</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_config</span><span class="p">()</span>
</span><span id="L-383"><a href="#L-383"><span class="linenos"> 383</span></a>
</span><span id="L-384"><a href="#L-384"><span class="linenos"> 384</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="p">:</span> <span class="n">ParallelEnvManager</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos"> 385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span><span class="p">:</span> <span class="n">ThreadPoolExecutor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos"> 386</span></a>
</span><span id="L-387"><a href="#L-387"><span class="linenos"> 387</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">=</span><span class="n">train_task_manager</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos"> 388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">=</span><span class="n">val_task_manager</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos"> 389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos"> 390</span></a>
</span><span id="L-391"><a href="#L-391"><span class="linenos"> 391</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_create_dataloader_from_manager</span><span class="p">(</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">shuffle_trainset</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create dataloader from the provided manager</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos"> 392</span></a>
</span><span id="L-393"><a href="#L-393"><span class="linenos"> 393</span></a>
</span><span id="L-394"><a href="#L-394"><span class="linenos"> 394</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos"> 395</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos"> 396</span></a><span class="sd">        Initializes distributed training workers using the Ray backend.</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos"> 397</span></a>
</span><span id="L-398"><a href="#L-398"><span class="linenos"> 398</span></a><span class="sd">        This function creates:</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos"> 399</span></a><span class="sd">        1. Ray resource pools from configuration</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos"> 400</span></a><span class="sd">        2. Worker groups for each role (actor, critic, etc.)</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos"> 401</span></a>
</span><span id="L-402"><a href="#L-402"><span class="linenos"> 402</span></a><span class="sd">        Args:</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos"> 403</span></a><span class="sd">            None</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos"> 404</span></a>
</span><span id="L-405"><a href="#L-405"><span class="linenos"> 405</span></a><span class="sd">        Returns:</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos"> 406</span></a><span class="sd">            None</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos"> 407</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos"> 408</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">create_resource_pool</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the resource pools</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos"> 409</span></a>
</span><span id="L-410"><a href="#L-410"><span class="linenos"> 410</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span> <span class="o">=</span> <span class="p">{</span><span class="n">pool</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">pool</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos"> 411</span></a>
</span><span id="L-412"><a href="#L-412"><span class="linenos"> 412</span></a>        <span class="c1"># create actor and rollout</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos"> 413</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos"> 414</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">)</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos"> 415</span></a>            <span class="n">actor_rollout_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos"> 416</span></a>                <span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">],</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos"> 417</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos"> 418</span></a>                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">,</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos"> 419</span></a>            <span class="p">)</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos"> 420</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">actor_rollout_cls</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos"> 421</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos"> 422</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos"> 423</span></a>
</span><span id="L-424"><a href="#L-424"><span class="linenos"> 424</span></a>        <span class="c1"># create critic</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos"> 425</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos"> 426</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">)</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos"> 427</span></a>            <span class="n">critic_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="p">)</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos"> 428</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">critic_cls</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos"> 429</span></a>
</span><span id="L-430"><a href="#L-430"><span class="linenos"> 430</span></a>        <span class="c1"># create reference policy if needed</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos"> 431</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos"> 432</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">)</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos"> 433</span></a>            <span class="n">ref_policy_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">],</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos"> 434</span></a>                                                  <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span> <span class="n">role</span><span class="o">=</span><span class="s2">&quot;ref&quot;</span><span class="p">)</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos"> 435</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_policy_cls</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos"> 436</span></a>
</span><span id="L-437"><a href="#L-437"><span class="linenos"> 437</span></a>        <span class="c1"># create a reward model if reward_fn is None</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos"> 438</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos"> 439</span></a>            <span class="c1"># we create a RM here</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos"> 440</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">)</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos"> 441</span></a>            <span class="n">rm_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos"> 442</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rm_cls</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos"> 443</span></a>
</span><span id="L-444"><a href="#L-444"><span class="linenos"> 444</span></a>        <span class="c1"># initialize WorkerGroup</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos"> 445</span></a>        <span class="c1"># NOTE: if you want to use a different resource pool for each role, which can support different parallel size,</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos"> 446</span></a>        <span class="c1"># you should not use `create_colocated_worker_cls`.</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos"> 447</span></a>        <span class="c1"># Instead, directly pass different resource pool to different worker groups.</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos"> 448</span></a>        <span class="c1"># See https://github.com/volcengine/verl/blob/master/examples/ray/tutorial.ipynb for more information.</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos"> 449</span></a>        <span class="n">all_wg</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos"> 450</span></a>        <span class="n">wg_kwargs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Setting up kwargs for RayWorkerGroup</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos"> 451</span></a>        <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos"> 452</span></a>            <span class="n">wg_kwargs</span><span class="p">[</span><span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">ray_wait_register_center_timeout</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos"> 453</span></a>
</span><span id="L-454"><a href="#L-454"><span class="linenos"> 454</span></a>        <span class="k">for</span> <span class="n">resource_pool</span><span class="p">,</span> <span class="n">class_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos"> 455</span></a>            <span class="n">worker_dict_cls</span> <span class="o">=</span> <span class="n">create_colocated_worker_cls</span><span class="p">(</span><span class="n">class_dict</span><span class="o">=</span><span class="n">class_dict</span><span class="p">)</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos"> 456</span></a>            <span class="n">wg_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span><span class="p">(</span><span class="n">resource_pool</span><span class="o">=</span><span class="n">resource_pool</span><span class="p">,</span> <span class="n">ray_cls_with_init</span><span class="o">=</span><span class="n">worker_dict_cls</span><span class="p">,</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos"> 457</span></a>                                                <span class="n">device_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="o">**</span><span class="n">wg_kwargs</span><span class="p">)</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos"> 458</span></a>            <span class="n">spawn_wg</span> <span class="o">=</span> <span class="n">wg_dict</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">prefix_set</span><span class="o">=</span><span class="n">class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos"> 459</span></a>            <span class="n">all_wg</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">spawn_wg</span><span class="p">)</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos"> 460</span></a>
</span><span id="L-461"><a href="#L-461"><span class="linenos"> 461</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos"> 462</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span>
</span><span id="L-463"><a href="#L-463"><span class="linenos"> 463</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the critic model</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos"> 464</span></a>
</span><span id="L-465"><a href="#L-465"><span class="linenos"> 465</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos"> 466</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos"> 467</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reference policy model</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos"> 468</span></a>
</span><span id="L-469"><a href="#L-469"><span class="linenos"> 469</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos"> 470</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos"> 471</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reward model</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos"> 472</span></a>
</span><span id="L-473"><a href="#L-473"><span class="linenos"> 473</span></a>        <span class="c1"># we should create rollout at the end so that vllm can have a better estimation of kv cache memory</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos"> 474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos"> 475</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the actor rollout model</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos"> 476</span></a>
</span><span id="L-477"><a href="#L-477"><span class="linenos"> 477</span></a>        <span class="c1"># create async rollout manager and request scheduler</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos"> 478</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos"> 479</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;async&quot;</span><span class="p">:</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos"> 480</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.trainer.ae_async_llm_server_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaAsyncLLMServerManager</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos"> 481</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos"> 482</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span> <span class="o">=</span> <span class="n">BaAsyncLLMServerManager</span><span class="p">(</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos"> 483</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos"> 484</span></a>                <span class="n">worker_group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create the asynchronous rollout manager</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos"> 485</span></a>
</span><span id="L-486"><a href="#L-486"><span class="linenos"> 486</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos"> 487</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos"> 488</span></a>
</span><span id="L-489"><a href="#L-489"><span class="linenos"> 489</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span> <span class="o">=</span> <span class="n">ParallelEnvManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">async_rollout_manager</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="p">,</span> <span class="n">max_parallel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_worker</span><span class="p">)</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos"> 490</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">thread_pool</span><span class="o">.</span><span class="n">max_workers</span><span class="p">)</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos"> 491</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span> <span class="o">=</span> <span class="n">ExperienceManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos"> 492</span></a>
</span><span id="L-493"><a href="#L-493"><span class="linenos"> 493</span></a>
</span><span id="L-494"><a href="#L-494"><span class="linenos"> 494</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_create_dataloader_from_manager</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">,</span> <span class="n">shuffle_trainset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos"> 495</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos"> 496</span></a><span class="sd">        Creates the train and validation dataloaders.</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos"> 497</span></a>
</span><span id="L-498"><a href="#L-498"><span class="linenos"> 498</span></a><span class="sd">        1. Check the existence of train and val files and load local tasks from them. If no files given, load tasks from environment (train and val/dev splits).</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos"> 499</span></a><span class="sd">        2. Use task manager to generate synthetic tasks for trainset, and load the original val dataset.</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos"> 500</span></a><span class="sd">        3. Use task manager to mix tasks from different sources.</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos"> 501</span></a><span class="sd">        4. Adapt datasets and create dataloaders used in the trainer.</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos"> 502</span></a>
</span><span id="L-503"><a href="#L-503"><span class="linenos"> 503</span></a><span class="sd">        Args:</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos"> 504</span></a><span class="sd">            collate_fn (callable): The function to use for collating data into batches.</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos"> 505</span></a><span class="sd">            shuffle_trainset (bool, optional): Whether to shuffle the training set. Defaults to True.</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos"> 506</span></a>
</span><span id="L-507"><a href="#L-507"><span class="linenos"> 507</span></a><span class="sd">        Returns:</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos"> 508</span></a><span class="sd">            None</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos"> 509</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos"> 510</span></a>        <span class="c1"># TODO: we have to make sure the batch size is divisible by the dp size</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos"> 511</span></a>        <span class="k">if</span> <span class="n">collate_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos"> 512</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.dataset.rl_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">collate_fn</span> <span class="k">as</span> <span class="n">default_collate_fn</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos"> 513</span></a>
</span><span id="L-514"><a href="#L-514"><span class="linenos"> 514</span></a>            <span class="n">collate_fn</span> <span class="o">=</span> <span class="n">default_collate_fn</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos"> 515</span></a>
</span><span id="L-516"><a href="#L-516"><span class="linenos"> 516</span></a>
</span><span id="L-517"><a href="#L-517"><span class="linenos"> 517</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.main_ppo</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_rl_dataset</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos"> 518</span></a>        <span class="c1"># load train dataset from files or environment</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos"> 519</span></a>        <span class="n">env_client</span><span class="o">=</span><span class="n">EnvClient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_url</span><span class="p">)</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos"> 520</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos"> 521</span></a>            <span class="n">train_seed_dataset</span> <span class="o">=</span> <span class="n">create_rl_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_files</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">)</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos"> 522</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_seed_dataset</span><span class="p">,</span><span class="n">RLHFDataset</span><span class="p">),</span> <span class="s2">&quot;train_dataset must be RLHFDataset&quot;</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos"> 523</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_dataset</span><span class="p">(</span><span class="n">train_seed_dataset</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">)</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos"> 524</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos"> 525</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos"> 526</span></a>        <span class="c1"># load val dataset</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos"> 527</span></a>        
</span><span id="L-528"><a href="#L-528"><span class="linenos"> 528</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos"> 529</span></a>            <span class="n">val_seed_dataset</span> <span class="o">=</span> <span class="n">create_rl_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_files</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">)</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos"> 530</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val_seed_dataset</span><span class="p">,</span><span class="n">RLHFDataset</span><span class="p">),</span> <span class="s2">&quot;train_dataset must be RLHFDataset&quot;</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos"> 531</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_dataset</span><span class="p">(</span><span class="n">val_seed_dataset</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">)</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos"> 532</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos"> 533</span></a>            <span class="n">num_loaded_val_tasks</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos"> 534</span></a>            <span class="k">if</span> <span class="s1">&#39;val_on_test&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_type</span> <span class="o">==</span> <span class="s1">&#39;test_normal&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span> <span class="o">==</span> <span class="s2">&quot;appworld&quot;</span><span class="p">):</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos"> 535</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;using test_normal as val dataset&quot;</span><span class="p">)</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos"> 536</span></a>                <span class="n">num_loaded_val_tasks</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;test_normal&quot;</span><span class="p">)</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos"> 537</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos"> 538</span></a>                <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">,</span><span class="s1">&#39;dev&#39;</span><span class="p">]:</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos"> 539</span></a>                    <span class="k">try</span><span class="p">:</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos"> 540</span></a>                        <span class="n">num_loaded_val_tasks</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos"> 541</span></a>                    <span class="k">except</span><span class="p">:</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos"> 542</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;failed to load val dataset from environment, split=</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">. this may be *normal* if your dataset is split into train/dev&quot;</span><span class="p">)</span>    
</span><span id="L-543"><a href="#L-543"><span class="linenos"> 543</span></a>            
</span><span id="L-544"><a href="#L-544"><span class="linenos"> 544</span></a>            <span class="k">assert</span> <span class="n">num_loaded_val_tasks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;failed to load val/dev dataset from environment&quot;</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos"> 545</span></a>        
</span><span id="L-546"><a href="#L-546"><span class="linenos"> 546</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">FullDataset</span><span class="p">(</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos"> 547</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="p">,</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos"> 548</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos"> 549</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">_reward_config</span><span class="p">,</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos"> 550</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">task_manager</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos"> 551</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos"> 552</span></a>            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos"> 553</span></a>            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos"> 554</span></a>        <span class="p">)</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos"> 555</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">FullDataset</span><span class="p">(</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos"> 556</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="p">,</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos"> 557</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos"> 558</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">_reward_config</span><span class="p">,</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos"> 559</span></a>            <span class="n">cache_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos"> 560</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos"> 561</span></a>            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos"> 562</span></a>            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos"> 563</span></a>        <span class="p">)</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos"> 564</span></a>
</span><span id="L-565"><a href="#L-565"><span class="linenos"> 565</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span><span class="n">AutoReloadDataset</span><span class="p">),</span> <span class="s2">&quot;please disable multiple workers for AutoReloadDataset&quot;</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos"> 566</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span><span class="n">AutoReloadDataset</span><span class="p">),</span> <span class="s2">&quot;please disable multiple workers for AutoReloadDataset&quot;</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos"> 567</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos"> 568</span></a>            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos"> 569</span></a>            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gen_batch_size&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">),</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos"> 570</span></a>            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos"> 571</span></a>            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos"> 572</span></a>            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos"> 573</span></a>            <span class="n">sampler</span><span class="o">=</span><span class="n">create_rl_sampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">),</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos"> 574</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Create the train dataloader with specified parameters</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos"> 575</span></a>
</span><span id="L-576"><a href="#L-576"><span class="linenos"> 576</span></a>        <span class="n">val_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_batch_size</span>  <span class="c1"># Prefer config value if set</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos"> 577</span></a>        <span class="k">if</span> <span class="n">val_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos"> 578</span></a>            <span class="n">val_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">)</span> <span class="c1"># type: ignore</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos"> 579</span></a>
</span><span id="L-580"><a href="#L-580"><span class="linenos"> 580</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos"> 581</span></a>            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos"> 582</span></a>            <span class="n">batch_size</span><span class="o">=</span><span class="n">val_batch_size</span><span class="p">,</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos"> 583</span></a>            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos"> 584</span></a>            <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation_shuffle&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos"> 585</span></a>            <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-586"><a href="#L-586"><span class="linenos"> 586</span></a>            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos"> 587</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Create the validation dataloader with specified parameters</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos"> 588</span></a>
</span><span id="L-589"><a href="#L-589"><span class="linenos"> 589</span></a>        <span class="c1"># train dataloader is on-the-fly, so we don&#39;t need to check the size</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos"> 590</span></a>        <span class="c1"># assert len(self.train_dataloader) &gt;= 1, &quot;Train dataloader is empty!&quot;</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos"> 591</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Validation dataloader is empty!&quot;</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos"> 592</span></a>
</span><span id="L-593"><a href="#L-593"><span class="linenos"> 593</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span><span class="n">IterableDataset</span><span class="p">):</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos"> 594</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos"> 595</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of train dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">, Size of val dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos"> 596</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-597"><a href="#L-597"><span class="linenos"> 597</span></a>            <span class="c1"># FIXME: need a elegant way to set total_training_steps</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos"> 598</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">seed_tasks</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos"> 599</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of train dataloader: unknown, Size of val dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-600"><a href="#L-600"><span class="linenos"> 600</span></a>
</span><span id="L-601"><a href="#L-601"><span class="linenos"> 601</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos"> 602</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span>
</span><span id="L-603"><a href="#L-603"><span class="linenos"> 603</span></a>
</span><span id="L-604"><a href="#L-604"><span class="linenos"> 604</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos"> 605</span></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total training steps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos"> 606</span></a>
</span><span id="L-607"><a href="#L-607"><span class="linenos"> 607</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos"> 608</span></a>            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos"> 609</span></a>            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">):</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos"> 610</span></a>                <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;actor_rollout_ref.actor.optim&quot;</span><span class="p">):</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos"> 611</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos"> 612</span></a>                <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;critic.optim&quot;</span><span class="p">):</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos"> 613</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos"> 614</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos"> 615</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Could not set total_training_steps in config. Structure missing? Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos"> 616</span></a>
</span><span id="L-617"><a href="#L-617"><span class="linenos"> 617</span></a>
</span><span id="L-618"><a href="#L-618"><span class="linenos"> 618</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_get_attribution_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos"> 619</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos"> 620</span></a><span class="sd">        Retrieves and validates the configuration for attribution-driven credit assignment, including the setup for API retry attempts.</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos"> 621</span></a>
</span><span id="L-622"><a href="#L-622"><span class="linenos"> 622</span></a><span class="sd">        Returns:</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos"> 623</span></a><span class="sd">            dict: The validated and possibly updated configuration dictionary.</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos"> 624</span></a>
</span><span id="L-625"><a href="#L-625"><span class="linenos"> 625</span></a><span class="sd">        Raises:</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos"> 626</span></a><span class="sd">            ValueError: If the required &#39;attribution_driven_credit_assignment&#39; block is missing from the configuration.</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos"> 627</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos"> 628</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;attribution_driven_credit_assignment&#39;</span><span class="p">):</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos"> 629</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;attribution_driven_credit_assignment configuration block is required&quot;</span><span class="p">)</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos"> 630</span></a>
</span><span id="L-631"><a href="#L-631"><span class="linenos"> 631</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">attribution_driven_credit_assignment</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos"> 632</span></a>
</span><span id="L-633"><a href="#L-633"><span class="linenos"> 633</span></a>        <span class="c1"># set the default api_max_retries</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos"> 634</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;api_max_retries&#39;</span><span class="p">):</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos"> 635</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">api_max_retries</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># ‚≠ê Set the default number of API retries to 200</span>
</span><span id="L-636"><a href="#L-636"><span class="linenos"> 636</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[attribution_config] Using default api_max_retries: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">api_max_retries</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos"> 637</span></a>
</span><span id="L-638"><a href="#L-638"><span class="linenos"> 638</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos"> 639</span></a>
</span><span id="L-640"><a href="#L-640"><span class="linenos"> 640</span></a>
</span><span id="L-641"><a href="#L-641"><span class="linenos"> 641</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos"> 642</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos"> 643</span></a><span class="sd">        Validates the configuration settings to ensure they are consistent and meet the necessary requirements for the training process.</span>
</span><span id="L-644"><a href="#L-644"><span class="linenos"> 644</span></a>
</span><span id="L-645"><a href="#L-645"><span class="linenos"> 645</span></a><span class="sd">        This function checks:</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos"> 646</span></a><span class="sd">        - The total number of GPUs and their allocation.</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos"> 647</span></a><span class="sd">        - The total batch size and its divisibility by the minimal possible batch size.</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos"> 648</span></a><span class="sd">        - Mutual exclusivity of certain micro-batch size parameters.</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos"> 649</span></a><span class="sd">        - Consistency in actor, critic, and reward model configurations.</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos"> 650</span></a><span class="sd">        - Other critical settings such as loss aggregation mode and sequence parallelism.</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos"> 651</span></a>
</span><span id="L-652"><a href="#L-652"><span class="linenos"> 652</span></a><span class="sd">        Raises:</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos"> 653</span></a><span class="sd">            AssertionError: If any of the configuration settings do not meet the required conditions.</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos"> 654</span></a><span class="sd">            ValueError: If mutually exclusive parameters are both set or neither is set.</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos"> 655</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos"> 656</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos"> 657</span></a>        <span class="c1"># number of GPUs total</span>
</span><span id="L-658"><a href="#L-658"><span class="linenos"> 658</span></a>        <span class="n">n_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">n_gpus_per_node</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">nnodes</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos"> 659</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;megatron&quot;</span><span class="p">:</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos"> 660</span></a>            <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos"> 661</span></a>            <span class="k">assert</span> <span class="n">n_gpus</span> <span class="o">%</span> <span class="p">(</span><span class="n">model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;n_gpus (</span><span class="si">{</span><span class="n">n_gpus</span><span class="si">}</span><span class="s2">) must be divisible by model_parallel_size (</span><span class="si">{</span><span class="n">model_parallel_size</span><span class="si">}</span><span class="s2">) times context_parallel_size (</span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos"> 662</span></a>            <span class="n">megatron_dp</span> <span class="o">=</span> <span class="n">n_gpus</span> <span class="o">//</span> <span class="p">(</span><span class="n">model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="p">)</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos"> 663</span></a>            <span class="n">minimal_bsz</span> <span class="o">=</span> <span class="n">megatron_dp</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos"> 664</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos"> 665</span></a>            <span class="n">minimal_bsz</span> <span class="o">=</span> <span class="n">n_gpus</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos"> 666</span></a>
</span><span id="L-667"><a href="#L-667"><span class="linenos"> 667</span></a>        <span class="c1"># 1. Check total batch size for data correctness</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos"> 668</span></a>        <span class="n">real_train_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos"> 669</span></a>        <span class="k">assert</span> <span class="n">real_train_batch_size</span> <span class="o">%</span> <span class="n">minimal_bsz</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;real_train_batch_size (</span><span class="si">{</span><span class="n">real_train_batch_size</span><span class="si">}</span><span class="s2">) must be divisible by minimal possible batch size (</span><span class="si">{</span><span class="n">minimal_bsz</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos"> 670</span></a>
</span><span id="L-671"><a href="#L-671"><span class="linenos"> 671</span></a>        <span class="c1"># A helper function to check &quot;micro_batch_size&quot; vs &quot;micro_batch_size_per_gpu&quot;</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos"> 672</span></a>        <span class="c1"># We throw an error if the user sets both. The new convention is &quot;..._micro_batch_size_per_gpu&quot;.</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos"> 673</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">check_mutually_exclusive</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="n">mbs_per_gpu</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos"> 674</span></a>            <span class="n">settings</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos"> 675</span></a>                <span class="s2">&quot;actor_rollout_ref.actor&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos"> 676</span></a>                <span class="s2">&quot;critic&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos"> 677</span></a>                <span class="s2">&quot;reward_model&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos"> 678</span></a>                <span class="s2">&quot;actor_rollout_ref.ref&quot;</span><span class="p">:</span> <span class="s2">&quot;log_prob_micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos"> 679</span></a>                <span class="s2">&quot;actor_rollout_ref.rollout&quot;</span><span class="p">:</span> <span class="s2">&quot;log_prob_micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos"> 680</span></a>            <span class="p">}</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos"> 681</span></a>
</span><span id="L-682"><a href="#L-682"><span class="linenos"> 682</span></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">settings</span><span class="p">:</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos"> 683</span></a>                <span class="n">param</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos"> 684</span></a>                <span class="n">param_per_gpu</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">_per_gpu&quot;</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos"> 685</span></a>
</span><span id="L-686"><a href="#L-686"><span class="linenos"> 686</span></a>                <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos"> 687</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] Please set at least one of &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; or &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos"> 688</span></a>
</span><span id="L-689"><a href="#L-689"><span class="linenos"> 689</span></a>                <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos"> 690</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] You have set both &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; AND &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;. Please remove &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; because only &#39;*_</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;&quot;</span> <span class="o">+</span> <span class="s2">&quot;is supported (the former is deprecated).&quot;</span><span class="p">)</span>
</span><span id="L-691"><a href="#L-691"><span class="linenos"> 691</span></a>
</span><span id="L-692"><a href="#L-692"><span class="linenos"> 692</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos"> 693</span></a>            <span class="c1"># actor: ppo_micro_batch_size vs. ppo_micro_batch_size_per_gpu</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos"> 694</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos"> 695</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos"> 696</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos"> 697</span></a>                <span class="s2">&quot;actor_rollout_ref.actor&quot;</span><span class="p">,</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos"> 698</span></a>            <span class="p">)</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos"> 699</span></a>
</span><span id="L-700"><a href="#L-700"><span class="linenos"> 700</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos"> 701</span></a>                <span class="c1"># reference: log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos"> 702</span></a>                <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos"> 703</span></a>                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos"> 704</span></a>                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos"> 705</span></a>                    <span class="s2">&quot;actor_rollout_ref.ref&quot;</span><span class="p">,</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos"> 706</span></a>                <span class="p">)</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos"> 707</span></a>
</span><span id="L-708"><a href="#L-708"><span class="linenos"> 708</span></a>            <span class="c1">#  The rollout section also has log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos"> 709</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="L-710"><a href="#L-710"><span class="linenos"> 710</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos"> 711</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="L-712"><a href="#L-712"><span class="linenos"> 712</span></a>                <span class="s2">&quot;actor_rollout_ref.rollout&quot;</span><span class="p">,</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos"> 713</span></a>            <span class="p">)</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos"> 714</span></a>
</span><span id="L-715"><a href="#L-715"><span class="linenos"> 715</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos"> 716</span></a>            <span class="c1"># Check for critic micro-batch size conflicts</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos"> 717</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span> <span class="s2">&quot;critic&quot;</span><span class="p">)</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos"> 718</span></a>
</span><span id="L-719"><a href="#L-719"><span class="linenos"> 719</span></a>        <span class="c1"># Check for reward model micro-batch size conflicts</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos"> 720</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos"> 721</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size_per_gpu</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">)</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos"> 722</span></a>
</span><span id="L-723"><a href="#L-723"><span class="linenos"> 723</span></a>        <span class="c1"># Actor</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos"> 724</span></a>        <span class="c1"># check if train_batch_size is larger than ppo_mini_batch_size</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos"> 725</span></a>        <span class="c1"># if NOT dynamic_bsz, we must ensure:</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos"> 726</span></a>        <span class="c1">#    ppo_mini_batch_size is divisible by ppo_micro_batch_size</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos"> 727</span></a>        <span class="c1">#    ppo_micro_batch_size * sequence_parallel_size &gt;= n_gpus</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos"> 728</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="L-729"><a href="#L-729"><span class="linenos"> 729</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>  <span class="c1"># ‚≠ê Ensure train_batch_size is at least as large as ppo_mini_batch_size</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos"> 730</span></a>            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-731"><a href="#L-731"><span class="linenos"> 731</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos"> 732</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># ‚≠ê Ensure ppo_mini_batch_size is divisible by ppo_micro_batch_size</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos"> 733</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>  <span class="c1"># ‚≠ê Ensure sufficient GPU allocation for micro-batch size and sequence parallelism</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos"> 734</span></a>
</span><span id="L-735"><a href="#L-735"><span class="linenos"> 735</span></a>        <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span> <span class="ow">in</span> <span class="p">[</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos"> 736</span></a>            <span class="s2">&quot;token-mean&quot;</span><span class="p">,</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos"> 737</span></a>            <span class="s2">&quot;seq-mean-token-sum&quot;</span><span class="p">,</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos"> 738</span></a>            <span class="s2">&quot;seq-mean-token-mean&quot;</span><span class="p">,</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos"> 739</span></a>            <span class="s2">&quot;seq-mean-token-sum-norm&quot;</span><span class="p">,</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos"> 740</span></a>        <span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;Invalid loss_agg_mode: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-741"><a href="#L-741"><span class="linenos"> 741</span></a>
</span><span id="L-742"><a href="#L-742"><span class="linenos"> 742</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_kl_loss</span><span class="p">:</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos"> 743</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NOTICE: You have both enabled in-reward kl and kl loss.&quot;</span><span class="p">)</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos"> 744</span></a>
</span><span id="L-745"><a href="#L-745"><span class="linenos"> 745</span></a>        <span class="c1"># critic</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos"> 746</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos"> 747</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>  <span class="c1"># ‚≠ê Ensure train_batch_size is at least as large as ppo_mini_batch_size for critic</span>
</span><span id="L-748"><a href="#L-748"><span class="linenos"> 748</span></a>            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos"> 749</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos"> 750</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># ‚≠ê Ensure ppo_mini_batch_size is divisible by ppo_micro_batch_size for critic</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos"> 751</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>  <span class="c1"># ‚≠ê Ensure sufficient GPU allocation for micro-batch size and sequence parallelism for critic</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos"> 752</span></a>
</span><span id="L-753"><a href="#L-753"><span class="linenos"> 753</span></a>        <span class="c1"># Check if use_remove_padding is enabled when using sequence parallelism for fsdp</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos"> 754</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-755"><a href="#L-755"><span class="linenos"> 755</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span><span class="p">,</span> <span class="s2">&quot;When using sequence parallelism for actor/ref policy, you must enable `use_remove_padding`.&quot;</span>
</span><span id="L-756"><a href="#L-756"><span class="linenos"> 756</span></a>
</span><span id="L-757"><a href="#L-757"><span class="linenos"> 757</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">:</span>
</span><span id="L-758"><a href="#L-758"><span class="linenos"> 758</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos"> 759</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span><span class="p">,</span> <span class="s2">&quot;When using sequence parallelism for critic, you must enable `use_remove_padding`.&quot;</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos"> 760</span></a>
</span><span id="L-761"><a href="#L-761"><span class="linenos"> 761</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_batch_size&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-762"><a href="#L-762"><span class="linenos"> 762</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: val_batch_size is deprecated.&quot;</span> <span class="o">+</span> <span class="s2">&quot; Validation datasets are sent to inference engines as a whole batch,&quot;</span> <span class="o">+</span> <span class="s2">&quot; which will schedule the memory themselves.&quot;</span><span class="p">)</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos"> 763</span></a>
</span><span id="L-764"><a href="#L-764"><span class="linenos"> 764</span></a>        <span class="c1"># check eval config</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos"> 765</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">:</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos"> 766</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">temperature</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;validation gen temperature should be greater than 0 when enabling do_sample&quot;</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos"> 767</span></a>
</span><span id="L-768"><a href="#L-768"><span class="linenos"> 768</span></a>        <span class="c1"># check multi_turn with tool config</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos"> 769</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span><span class="p">:</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos"> 770</span></a>            <span class="c1"># 0623 yunpeng comment: no need this tool_config_path</span>
</span><span id="L-771"><a href="#L-771"><span class="linenos"> 771</span></a>            <span class="c1"># assert config.actor_rollout_ref.rollout.multi_turn.tool_config_path is not None or config.actor_rollout_ref.rollout.multi_turn.interaction_config_path is not None, &quot;tool_config_path or interaction_config_path must be set when enabling multi_turn with tool, due to no role-playing support&quot;</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos"> 772</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span><span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">],</span> <span class="s2">&quot;only GRPO is tested for multi-turn with tool&quot;</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos"> 773</span></a>
</span><span id="L-774"><a href="#L-774"><span class="linenos"> 774</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[validate_config] All configuration checks passed successfully!&quot;</span><span class="p">)</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos"> 775</span></a>
</span><span id="L-776"><a href="#L-776"><span class="linenos"> 776</span></a>    <span class="c1">##################</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos"> 777</span></a>    <span class="c1"># ANNI</span>
</span><span id="L-778"><a href="#L-778"><span class="linenos"> 778</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_dump_generations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span><span class="p">,</span> <span class="n">dump_path</span><span class="p">):</span>
</span><span id="L-779"><a href="#L-779"><span class="linenos"> 779</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos"> 780</span></a><span class="sd">        Dumps rollout/validation samples as JSONL.</span>
</span><span id="L-781"><a href="#L-781"><span class="linenos"> 781</span></a>
</span><span id="L-782"><a href="#L-782"><span class="linenos"> 782</span></a><span class="sd">        Args:</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos"> 783</span></a><span class="sd">            inputs (list): List of input data.</span>
</span><span id="L-784"><a href="#L-784"><span class="linenos"> 784</span></a><span class="sd">            outputs (list): List of output data.</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos"> 785</span></a><span class="sd">            scores (list): List of score data.</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos"> 786</span></a><span class="sd">            reward_extra_infos_dict (dict): Dictionary containing additional reward information.</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos"> 787</span></a><span class="sd">            dump_path (str): Path to the directory where the JSONL file will be saved.</span>
</span><span id="L-788"><a href="#L-788"><span class="linenos"> 788</span></a>
</span><span id="L-789"><a href="#L-789"><span class="linenos"> 789</span></a><span class="sd">        Returns:</span>
</span><span id="L-790"><a href="#L-790"><span class="linenos"> 790</span></a><span class="sd">            None</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos"> 791</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-792"><a href="#L-792"><span class="linenos"> 792</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dump_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-793"><a href="#L-793"><span class="linenos"> 793</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dump_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create the filename for the JSONL file</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos"> 794</span></a>
</span><span id="L-795"><a href="#L-795"><span class="linenos"> 795</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-796"><a href="#L-796"><span class="linenos"> 796</span></a>        <span class="n">base_data</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos"> 797</span></a>            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">,</span>
</span><span id="L-798"><a href="#L-798"><span class="linenos"> 798</span></a>            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos"> 799</span></a>            <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">scores</span><span class="p">,</span>
</span><span id="L-800"><a href="#L-800"><span class="linenos"> 800</span></a>            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span>
</span><span id="L-801"><a href="#L-801"><span class="linenos"> 801</span></a>        <span class="p">}</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos"> 802</span></a>
</span><span id="L-803"><a href="#L-803"><span class="linenos"> 803</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos"> 804</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos"> 805</span></a>                <span class="n">base_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos"> 806</span></a>
</span><span id="L-807"><a href="#L-807"><span class="linenos"> 807</span></a>        <span class="n">lines</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos"> 808</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos"> 809</span></a>            <span class="n">entry</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">base_data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="L-810"><a href="#L-810"><span class="linenos"> 810</span></a>            <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos"> 811</span></a>
</span><span id="L-812"><a href="#L-812"><span class="linenos"> 812</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos"> 813</span></a>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Write the data to the JSONL file</span>
</span><span id="L-814"><a href="#L-814"><span class="linenos"> 814</span></a>
</span><span id="L-815"><a href="#L-815"><span class="linenos"> 815</span></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dumped generations to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos"> 816</span></a>
</span><span id="L-817"><a href="#L-817"><span class="linenos"> 817</span></a>
</span><span id="L-818"><a href="#L-818"><span class="linenos"> 818</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos"> 819</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos"> 820</span></a><span class="sd">        Validates the model by generating sequences, collecting samples, and storing the results.</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos"> 821</span></a>
</span><span id="L-822"><a href="#L-822"><span class="linenos"> 822</span></a><span class="sd">        This function processes each batch of validation data, generates outputs, and collects</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos"> 823</span></a><span class="sd">        input, output, and experience information for further analysis.</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos"> 824</span></a>
</span><span id="L-825"><a href="#L-825"><span class="linenos"> 825</span></a><span class="sd">        Args:</span>
</span><span id="L-826"><a href="#L-826"><span class="linenos"> 826</span></a><span class="sd">            None</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos"> 827</span></a>
</span><span id="L-828"><a href="#L-828"><span class="linenos"> 828</span></a><span class="sd">        Returns:</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos"> 829</span></a><span class="sd">            None</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos"> 830</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-831"><a href="#L-831"><span class="linenos"> 831</span></a>        <span class="n">data_source_lst</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos"> 832</span></a>        <span class="n">reward_extra_infos_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos"> 833</span></a>
</span><span id="L-834"><a href="#L-834"><span class="linenos"> 834</span></a>        <span class="c1"># Lists to collect samples for the table</span>
</span><span id="L-835"><a href="#L-835"><span class="linenos"> 835</span></a>        <span class="n">sample_inputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos"> 836</span></a>        <span class="n">sample_outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-837"><a href="#L-837"><span class="linenos"> 837</span></a>        <span class="n">sample_scores</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-838"><a href="#L-838"><span class="linenos"> 838</span></a>
</span><span id="L-839"><a href="#L-839"><span class="linenos"> 839</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">):</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos"> 840</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</span><span id="L-841"><a href="#L-841"><span class="linenos"> 841</span></a>
</span><span id="L-842"><a href="#L-842"><span class="linenos"> 842</span></a>            <span class="c1"># repeat test batch</span>
</span><span id="L-843"><a href="#L-843"><span class="linenos"> 843</span></a>            <span class="c1"># test_batch = test_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.val_kwargs.n, interleave=True)</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos"> 844</span></a>
</span><span id="L-845"><a href="#L-845"><span class="linenos"> 845</span></a>            <span class="c1"># we only do validation on rule-based rm</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos"> 846</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
</span><span id="L-847"><a href="#L-847"><span class="linenos"> 847</span></a>                <span class="k">return</span> <span class="p">{}</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos"> 848</span></a>
</span><span id="L-849"><a href="#L-849"><span class="linenos"> 849</span></a>            <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos"> 850</span></a>            <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="L-851"><a href="#L-851"><span class="linenos"> 851</span></a>            <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-852"><a href="#L-852"><span class="linenos"> 852</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="L-853"><a href="#L-853"><span class="linenos"> 853</span></a>            <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos"> 854</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="L-855"><a href="#L-855"><span class="linenos"> 855</span></a>            <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos"> 856</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="L-857"><a href="#L-857"><span class="linenos"> 857</span></a>            <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-858"><a href="#L-858"><span class="linenos"> 858</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="L-859"><a href="#L-859"><span class="linenos"> 859</span></a>            <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos"> 860</span></a>                <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-861"><a href="#L-861"><span class="linenos"> 861</span></a>                <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-862"><a href="#L-862"><span class="linenos"> 862</span></a>            <span class="p">)</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos"> 863</span></a>
</span><span id="L-864"><a href="#L-864"><span class="linenos"> 864</span></a>            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-865"><a href="#L-865"><span class="linenos"> 865</span></a>                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span id="L-866"><a href="#L-866"><span class="linenos"> 866</span></a>                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="L-867"><a href="#L-867"><span class="linenos"> 867</span></a>                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-868"><a href="#L-868"><span class="linenos"> 868</span></a>                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">,</span>
</span><span id="L-869"><a href="#L-869"><span class="linenos"> 869</span></a>                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-870"><a href="#L-870"><span class="linenos"> 870</span></a>            <span class="p">}</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos"> 871</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_gen_batch meta info: </span><span class="si">{</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-872"><a href="#L-872"><span class="linenos"> 872</span></a>
</span><span id="L-873"><a href="#L-873"><span class="linenos"> 873</span></a>            <span class="c1"># pad to be divisible by dp_size</span>
</span><span id="L-874"><a href="#L-874"><span class="linenos"> 874</span></a>            <span class="c1"># test_gen_batch_padded, pad_size = pad_dataproto_to_divisor(test_gen_batch, self.actor_rollout_wg.world_size)</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos"> 875</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="L-876"><a href="#L-876"><span class="linenos"> 876</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-877"><a href="#L-877"><span class="linenos"> 877</span></a>
</span><span id="L-878"><a href="#L-878"><span class="linenos"> 878</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-879"><a href="#L-879"><span class="linenos"> 879</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos"> 880</span></a>                <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="L-881"><a href="#L-881"><span class="linenos"> 881</span></a>                            <span class="n">task_id</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos"> 882</span></a>                            <span class="n">query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="L-883"><a href="#L-883"><span class="linenos"> 883</span></a>                            <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="L-884"><a href="#L-884"><span class="linenos"> 884</span></a>                            <span class="n">open_query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="L-885"><a href="#L-885"><span class="linenos"> 885</span></a>                            <span class="c1"># evaluator=gen_batch.non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;], # avoid potential bugs</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos"> 886</span></a>                         <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_gen_batch</span><span class="p">))]</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos"> 887</span></a>                <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
</span><span id="L-888"><a href="#L-888"><span class="linenos"> 888</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-889"><a href="#L-889"><span class="linenos"> 889</span></a>                <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test.1.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Execute the rollout to generate trajectories</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos"> 890</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-891"><a href="#L-891"><span class="linenos"> 891</span></a>                <span class="n">test_output_gen_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">to_dataproto</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="L-892"><a href="#L-892"><span class="linenos"> 892</span></a>                <span class="c1"># test_output_gen_batch_padded = self.explorer_manager.rollout(test_gen_batch_padded)</span>
</span><span id="L-893"><a href="#L-893"><span class="linenos"> 893</span></a>                <span class="c1"># test_output_gen_batch_padded = self.async_rollout_manager.generate_sequences(test_gen_batch_padded)</span>
</span><span id="L-894"><a href="#L-894"><span class="linenos"> 894</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="L-895"><a href="#L-895"><span class="linenos"> 895</span></a>
</span><span id="L-896"><a href="#L-896"><span class="linenos"> 896</span></a>            <span class="c1"># unpad</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos"> 897</span></a>            <span class="c1"># test_output_gen_batch = unpad_dataproto(test_output_gen_batch_padded, pad_size=pad_size)</span>
</span><span id="L-898"><a href="#L-898"><span class="linenos"> 898</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;validation generation end&quot;</span><span class="p">)</span>
</span><span id="L-899"><a href="#L-899"><span class="linenos"> 899</span></a>
</span><span id="L-900"><a href="#L-900"><span class="linenos"> 900</span></a>            <span class="c1"># Store original inputs</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos"> 901</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">test_output_gen_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span>
</span><span id="L-902"><a href="#L-902"><span class="linenos"> 902</span></a>            <span class="c1"># TODO: Can we keep special tokens except for padding tokens?</span>
</span><span id="L-903"><a href="#L-903"><span class="linenos"> 903</span></a>            <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="L-904"><a href="#L-904"><span class="linenos"> 904</span></a>            <span class="n">sample_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>
</span><span id="L-905"><a href="#L-905"><span class="linenos"> 905</span></a>
</span><span id="L-906"><a href="#L-906"><span class="linenos"> 906</span></a>            <span class="c1"># Store generated outputs</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos"> 907</span></a>            <span class="n">output_ids</span> <span class="o">=</span> <span class="n">test_output_gen_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
</span><span id="L-908"><a href="#L-908"><span class="linenos"> 908</span></a>            <span class="n">output_texts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">output_ids</span><span class="p">]</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos"> 909</span></a>            <span class="n">sample_outputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_texts</span><span class="p">)</span>
</span><span id="L-910"><a href="#L-910"><span class="linenos"> 910</span></a>
</span><span id="L-911"><a href="#L-911"><span class="linenos"> 911</span></a>            <span class="c1"># repeat test batch</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos"> 912</span></a>            <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos"> 913</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">test_batch</span><span class="p">,</span> <span class="n">test_output_gen_batch</span><span class="p">)</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos"> 914</span></a>            <span class="n">test_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;validate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-915"><a href="#L-915"><span class="linenos"> 915</span></a>
</span><span id="L-916"><a href="#L-916"><span class="linenos"> 916</span></a>            <span class="c1"># test_batch = test_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.val_kwargs.n, interleave=True)</span>
</span><span id="L-917"><a href="#L-917"><span class="linenos"> 917</span></a>            <span class="c1"># test_batch = test_batch.union(test_output_gen_batch)</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos"> 918</span></a>
</span><span id="L-919"><a href="#L-919"><span class="linenos"> 919</span></a>            <span class="c1"># evaluate using reward_function</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos"> 920</span></a>            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># ‚≠ê Evaluate the test batch using the reward function</span>
</span><span id="L-921"><a href="#L-921"><span class="linenos"> 921</span></a>            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reward_tensor&quot;</span><span class="p">]</span>
</span><span id="L-922"><a href="#L-922"><span class="linenos"> 922</span></a>            <span class="n">scores</span> <span class="o">=</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="L-923"><a href="#L-923"><span class="linenos"> 923</span></a>            <span class="n">sample_scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos"> 924</span></a>
</span><span id="L-925"><a href="#L-925"><span class="linenos"> 925</span></a>            <span class="n">reward_extra_infos_dict</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span><span id="L-926"><a href="#L-926"><span class="linenos"> 926</span></a>            <span class="k">if</span> <span class="s2">&quot;reward_extra_info&quot;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
</span><span id="L-927"><a href="#L-927"><span class="linenos"> 927</span></a>                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reward_extra_info&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos"> 928</span></a>                    <span class="n">reward_extra_infos_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos"> 929</span></a>
</span><span id="L-930"><a href="#L-930"><span class="linenos"> 930</span></a>            <span class="n">data_source_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data_source&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;unknown&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="L-931"><a href="#L-931"><span class="linenos"> 931</span></a>
</span><span id="L-932"><a href="#L-932"><span class="linenos"> 932</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_log_val_generations</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">sample_outputs</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">sample_scores</span><span class="p">)</span>
</span><span id="L-933"><a href="#L-933"><span class="linenos"> 933</span></a>
</span><span id="L-934"><a href="#L-934"><span class="linenos"> 934</span></a>        <span class="c1"># dump generations</span>
</span><span id="L-935"><a href="#L-935"><span class="linenos"> 935</span></a>        <span class="n">val_data_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation_data_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-936"><a href="#L-936"><span class="linenos"> 936</span></a>        <span class="c1"># val_data_dir = &quot;experiments/validation_log&quot;</span>
</span><span id="L-937"><a href="#L-937"><span class="linenos"> 937</span></a>        <span class="k">if</span> <span class="n">val_data_dir</span><span class="p">:</span>
</span><span id="L-938"><a href="#L-938"><span class="linenos"> 938</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dump_generations</span><span class="p">(</span>
</span><span id="L-939"><a href="#L-939"><span class="linenos"> 939</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span>
</span><span id="L-940"><a href="#L-940"><span class="linenos"> 940</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="n">sample_outputs</span><span class="p">,</span>
</span><span id="L-941"><a href="#L-941"><span class="linenos"> 941</span></a>                <span class="n">scores</span><span class="o">=</span><span class="n">sample_scores</span><span class="p">,</span>
</span><span id="L-942"><a href="#L-942"><span class="linenos"> 942</span></a>                <span class="n">reward_extra_infos_dict</span><span class="o">=</span><span class="n">reward_extra_infos_dict</span><span class="p">,</span>
</span><span id="L-943"><a href="#L-943"><span class="linenos"> 943</span></a>                <span class="n">dump_path</span><span class="o">=</span><span class="n">val_data_dir</span><span class="p">,</span>
</span><span id="L-944"><a href="#L-944"><span class="linenos"> 944</span></a>            <span class="p">)</span>
</span><span id="L-945"><a href="#L-945"><span class="linenos"> 945</span></a>
</span><span id="L-946"><a href="#L-946"><span class="linenos"> 946</span></a>        <span class="k">for</span> <span class="n">key_info</span><span class="p">,</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-947"><a href="#L-947"><span class="linenos"> 947</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_scores</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_info</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_scores</span><span class="p">)</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="L-948"><a href="#L-948"><span class="linenos"> 948</span></a>
</span><span id="L-949"><a href="#L-949"><span class="linenos"> 949</span></a>        <span class="n">data_sources</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data_source_lst</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="L-950"><a href="#L-950"><span class="linenos"> 950</span></a>
</span><span id="L-951"><a href="#L-951"><span class="linenos"> 951</span></a>        <span class="n">data_src2var2metric2val</span> <span class="o">=</span> <span class="n">process_validation_metrics</span><span class="p">(</span><span class="n">data_sources</span><span class="p">,</span> <span class="n">sample_inputs</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span><span class="p">)</span>  <span class="c1"># ‚≠ê Process the validation metrics for different data sources</span>
</span><span id="L-952"><a href="#L-952"><span class="linenos"> 952</span></a>        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-953"><a href="#L-953"><span class="linenos"> 953</span></a>        <span class="k">for</span> <span class="n">data_source</span><span class="p">,</span> <span class="n">var2metric2val</span> <span class="ow">in</span> <span class="n">data_src2var2metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-954"><a href="#L-954"><span class="linenos"> 954</span></a>            <span class="n">core_var</span> <span class="o">=</span> <span class="s2">&quot;acc&quot;</span> <span class="k">if</span> <span class="s2">&quot;acc&quot;</span> <span class="ow">in</span> <span class="n">var2metric2val</span> <span class="k">else</span> <span class="s2">&quot;reward&quot;</span>
</span><span id="L-955"><a href="#L-955"><span class="linenos"> 955</span></a>            <span class="k">for</span> <span class="n">var_name</span><span class="p">,</span> <span class="n">metric2val</span> <span class="ow">in</span> <span class="n">var2metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-956"><a href="#L-956"><span class="linenos"> 956</span></a>                <span class="n">n_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;@&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">metric2val</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span>
</span><span id="L-957"><a href="#L-957"><span class="linenos"> 957</span></a>                <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_val</span> <span class="ow">in</span> <span class="n">metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-958"><a href="#L-958"><span class="linenos"> 958</span></a>                    <span class="k">if</span> <span class="p">(</span><span class="n">var_name</span> <span class="o">==</span> <span class="n">core_var</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">metric_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">pfx</span><span class="p">)</span> <span class="k">for</span> <span class="n">pfx</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;maj&quot;</span><span class="p">,</span> <span class="s2">&quot;best&quot;</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;@</span><span class="si">{</span><span class="n">n_max</span><span class="si">}</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">metric_name</span><span class="p">):</span>
</span><span id="L-959"><a href="#L-959"><span class="linenos"> 959</span></a>                        <span class="n">metric_sec</span> <span class="o">=</span> <span class="s2">&quot;val-core&quot;</span>
</span><span id="L-960"><a href="#L-960"><span class="linenos"> 960</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="L-961"><a href="#L-961"><span class="linenos"> 961</span></a>                        <span class="n">metric_sec</span> <span class="o">=</span> <span class="s2">&quot;val-aux&quot;</span>
</span><span id="L-962"><a href="#L-962"><span class="linenos"> 962</span></a>                    <span class="n">pfx</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_sec</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">data_source</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">var_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-963"><a href="#L-963"><span class="linenos"> 963</span></a>                    <span class="n">metric_dict</span><span class="p">[</span><span class="n">pfx</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric_val</span>
</span><span id="L-964"><a href="#L-964"><span class="linenos"> 964</span></a>
</span><span id="L-965"><a href="#L-965"><span class="linenos"> 965</span></a>        <span class="k">return</span> <span class="n">metric_dict</span>
</span><span id="L-966"><a href="#L-966"><span class="linenos"> 966</span></a>    
</span><span id="L-967"><a href="#L-967"><span class="linenos"> 967</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_exp_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-968"><a href="#L-968"><span class="linenos"> 968</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-969"><a href="#L-969"><span class="linenos"> 969</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-970"><a href="#L-970"><span class="linenos"> 970</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">):</span>
</span><span id="L-971"><a href="#L-971"><span class="linenos"> 971</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</span><span id="L-972"><a href="#L-972"><span class="linenos"> 972</span></a>
</span><span id="L-973"><a href="#L-973"><span class="linenos"> 973</span></a>            <span class="c1"># we only do validation on rule-based rm</span>
</span><span id="L-974"><a href="#L-974"><span class="linenos"> 974</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
</span><span id="L-975"><a href="#L-975"><span class="linenos"> 975</span></a>                <span class="k">return</span> <span class="p">{}</span>
</span><span id="L-976"><a href="#L-976"><span class="linenos"> 976</span></a>
</span><span id="L-977"><a href="#L-977"><span class="linenos"> 977</span></a>            <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="L-978"><a href="#L-978"><span class="linenos"> 978</span></a>            <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="L-979"><a href="#L-979"><span class="linenos"> 979</span></a>            <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-980"><a href="#L-980"><span class="linenos"> 980</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="L-981"><a href="#L-981"><span class="linenos"> 981</span></a>            <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-982"><a href="#L-982"><span class="linenos"> 982</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="L-983"><a href="#L-983"><span class="linenos"> 983</span></a>            <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-984"><a href="#L-984"><span class="linenos"> 984</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="L-985"><a href="#L-985"><span class="linenos"> 985</span></a>            <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-986"><a href="#L-986"><span class="linenos"> 986</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="L-987"><a href="#L-987"><span class="linenos"> 987</span></a>            <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="L-988"><a href="#L-988"><span class="linenos"> 988</span></a>                <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-989"><a href="#L-989"><span class="linenos"> 989</span></a>                <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-990"><a href="#L-990"><span class="linenos"> 990</span></a>            <span class="p">)</span>
</span><span id="L-991"><a href="#L-991"><span class="linenos"> 991</span></a>
</span><span id="L-992"><a href="#L-992"><span class="linenos"> 992</span></a>            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-993"><a href="#L-993"><span class="linenos"> 993</span></a>                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span id="L-994"><a href="#L-994"><span class="linenos"> 994</span></a>                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="L-995"><a href="#L-995"><span class="linenos"> 995</span></a>                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-996"><a href="#L-996"><span class="linenos"> 996</span></a>                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">,</span>
</span><span id="L-997"><a href="#L-997"><span class="linenos"> 997</span></a>                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-998"><a href="#L-998"><span class="linenos"> 998</span></a>            <span class="p">}</span>
</span><span id="L-999"><a href="#L-999"><span class="linenos"> 999</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_gen_batch meta info: </span><span class="si">{</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1000"><a href="#L-1000"><span class="linenos">1000</span></a>
</span><span id="L-1001"><a href="#L-1001"><span class="linenos">1001</span></a>            <span class="c1"># pad to be divisible by dp_size</span>
</span><span id="L-1002"><a href="#L-1002"><span class="linenos">1002</span></a>            <span class="c1"># test_gen_batch_padded, pad_size = pad_dataproto_to_divisor(test_gen_batch, self.actor_rollout_wg.world_size)</span>
</span><span id="L-1003"><a href="#L-1003"><span class="linenos">1003</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="L-1004"><a href="#L-1004"><span class="linenos">1004</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-1005"><a href="#L-1005"><span class="linenos">1005</span></a>
</span><span id="L-1006"><a href="#L-1006"><span class="linenos">1006</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1007"><a href="#L-1007"><span class="linenos">1007</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="L-1008"><a href="#L-1008"><span class="linenos">1008</span></a>                <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="L-1009"><a href="#L-1009"><span class="linenos">1009</span></a>                            <span class="n">task_id</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="L-1010"><a href="#L-1010"><span class="linenos">1010</span></a>                            <span class="n">query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="L-1011"><a href="#L-1011"><span class="linenos">1011</span></a>                            <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="L-1012"><a href="#L-1012"><span class="linenos">1012</span></a>                            <span class="n">open_query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="L-1013"><a href="#L-1013"><span class="linenos">1013</span></a>                            <span class="c1"># evaluator=gen_batch.non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;], # avoid potential bugs</span>
</span><span id="L-1014"><a href="#L-1014"><span class="linenos">1014</span></a>                         <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_gen_batch</span><span class="p">))]</span>
</span><span id="L-1015"><a href="#L-1015"><span class="linenos">1015</span></a>                <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
</span><span id="L-1016"><a href="#L-1016"><span class="linenos">1016</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-1017"><a href="#L-1017"><span class="linenos">1017</span></a>                <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test.1.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Execute the rollout to generate trajectories</span>
</span><span id="L-1018"><a href="#L-1018"><span class="linenos">1018</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-1019"><a href="#L-1019"><span class="linenos">1019</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="L-1020"><a href="#L-1020"><span class="linenos">1020</span></a>
</span><span id="L-1021"><a href="#L-1021"><span class="linenos">1021</span></a>            <span class="c1"># summarize in batch: updating experience pool</span>
</span><span id="L-1022"><a href="#L-1022"><span class="linenos">1022</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">summarize_in_batch</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="L-1023"><a href="#L-1023"><span class="linenos">1023</span></a>        
</span><span id="L-1024"><a href="#L-1024"><span class="linenos">1024</span></a>        <span class="k">return</span>
</span><span id="L-1025"><a href="#L-1025"><span class="linenos">1025</span></a>
</span><span id="L-1026"><a href="#L-1026"><span class="linenos">1026</span></a>
</span><span id="L-1027"><a href="#L-1027"><span class="linenos">1027</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-1028"><a href="#L-1028"><span class="linenos">1028</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1029"><a href="#L-1029"><span class="linenos">1029</span></a><span class="sd">        The training loop of PPO.</span>
</span><span id="L-1030"><a href="#L-1030"><span class="linenos">1030</span></a><span class="sd">        The driver process only need to call the compute functions of the worker group through RPC</span>
</span><span id="L-1031"><a href="#L-1031"><span class="linenos">1031</span></a><span class="sd">        to construct the PPO dataflow.</span>
</span><span id="L-1032"><a href="#L-1032"><span class="linenos">1032</span></a><span class="sd">        The light-weight advantage computation is done on the driver process.</span>
</span><span id="L-1033"><a href="#L-1033"><span class="linenos">1033</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1034"><a href="#L-1034"><span class="linenos">1034</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span>
</span><span id="L-1035"><a href="#L-1035"><span class="linenos">1035</span></a>
</span><span id="L-1036"><a href="#L-1036"><span class="linenos">1036</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tracking</span>
</span><span id="L-1037"><a href="#L-1037"><span class="linenos">1037</span></a>
</span><span id="L-1038"><a href="#L-1038"><span class="linenos">1038</span></a>        <span class="n">logger</span> <span class="o">=</span> <span class="n">Tracking</span><span class="p">(</span>
</span><span id="L-1039"><a href="#L-1039"><span class="linenos">1039</span></a>            <span class="n">project_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">project_name</span><span class="p">,</span>
</span><span id="L-1040"><a href="#L-1040"><span class="linenos">1040</span></a>            <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
</span><span id="L-1041"><a href="#L-1041"><span class="linenos">1041</span></a>            <span class="n">default_backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span>
</span><span id="L-1042"><a href="#L-1042"><span class="linenos">1042</span></a>            <span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="L-1043"><a href="#L-1043"><span class="linenos">1043</span></a>        <span class="p">)</span>
</span><span id="L-1044"><a href="#L-1044"><span class="linenos">1044</span></a>
</span><span id="L-1045"><a href="#L-1045"><span class="linenos">1045</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-1046"><a href="#L-1046"><span class="linenos">1046</span></a>
</span><span id="L-1047"><a href="#L-1047"><span class="linenos">1047</span></a>        <span class="c1"># load checkpoint before doing anything</span>
</span><span id="L-1048"><a href="#L-1048"><span class="linenos">1048</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_checkpoint</span><span class="p">()</span>
</span><span id="L-1049"><a href="#L-1049"><span class="linenos">1049</span></a>        <span class="c1"># spread parameters to vllm</span>
</span><span id="L-1050"><a href="#L-1050"><span class="linenos">1050</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="L-1051"><a href="#L-1051"><span class="linenos">1051</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="L-1052"><a href="#L-1052"><span class="linenos">1052</span></a>
</span><span id="L-1053"><a href="#L-1053"><span class="linenos">1053</span></a>        <span class="c1"># initialize experience pool</span>
</span><span id="L-1054"><a href="#L-1054"><span class="linenos">1054</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_before_training&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1055"><a href="#L-1055"><span class="linenos">1055</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_exp_pool</span><span class="p">()</span>
</span><span id="L-1056"><a href="#L-1056"><span class="linenos">1056</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1057"><a href="#L-1057"><span class="linenos">1057</span></a>                <span class="k">return</span>
</span><span id="L-1058"><a href="#L-1058"><span class="linenos">1058</span></a>
</span><span id="L-1059"><a href="#L-1059"><span class="linenos">1059</span></a>        <span class="c1"># perform validation before training</span>
</span><span id="L-1060"><a href="#L-1060"><span class="linenos">1060</span></a>        <span class="c1"># currently, we only support validation using the reward_function.</span>
</span><span id="L-1061"><a href="#L-1061"><span class="linenos">1061</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_before_train&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-1062"><a href="#L-1062"><span class="linenos">1062</span></a>            <span class="n">val_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Perform initial validation and get the validation metrics</span>
</span><span id="L-1063"><a href="#L-1063"><span class="linenos">1063</span></a>            <span class="k">assert</span> <span class="n">val_metrics</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val_metrics</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="L-1064"><a href="#L-1064"><span class="linenos">1064</span></a>            <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial validation metrics: </span><span class="si">{</span><span class="n">val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1065"><a href="#L-1065"><span class="linenos">1065</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">val_metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="L-1066"><a href="#L-1066"><span class="linenos">1066</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1067"><a href="#L-1067"><span class="linenos">1067</span></a>                <span class="k">return</span>
</span><span id="L-1068"><a href="#L-1068"><span class="linenos">1068</span></a>
</span><span id="L-1069"><a href="#L-1069"><span class="linenos">1069</span></a>        <span class="c1"># [0616] qingxu: add `RAY_DEBUG_POST_MORTEM` env var to activate breakpoint debugging</span>
</span><span id="L-1070"><a href="#L-1070"><span class="linenos">1070</span></a>        <span class="c1"># vscode_conditional_breakpoint()</span>
</span><span id="L-1071"><a href="#L-1071"><span class="linenos">1071</span></a>        <span class="c1"># breakpoint()</span>
</span><span id="L-1072"><a href="#L-1072"><span class="linenos">1072</span></a>
</span><span id="L-1073"><a href="#L-1073"><span class="linenos">1073</span></a>        <span class="c1"># add tqdm</span>
</span><span id="L-1074"><a href="#L-1074"><span class="linenos">1074</span></a>        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Progress&quot;</span><span class="p">)</span>
</span><span id="L-1075"><a href="#L-1075"><span class="linenos">1075</span></a>
</span><span id="L-1076"><a href="#L-1076"><span class="linenos">1076</span></a>        <span class="c1"># we start from step 1</span>
</span><span id="L-1077"><a href="#L-1077"><span class="linenos">1077</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-1078"><a href="#L-1078"><span class="linenos">1078</span></a>        <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1079"><a href="#L-1079"><span class="linenos">1079</span></a>        
</span><span id="L-1080"><a href="#L-1080"><span class="linenos">1080</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">):</span>
</span><span id="L-1081"><a href="#L-1081"><span class="linenos">1081</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">):</span>
</span><span id="L-1082"><a href="#L-1082"><span class="linenos">1082</span></a>                <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-1083"><a href="#L-1083"><span class="linenos">1083</span></a>                <span class="n">timing_raw</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-1084"><a href="#L-1084"><span class="linenos">1084</span></a>                <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>
</span><span id="L-1085"><a href="#L-1085"><span class="linenos">1085</span></a>
</span><span id="L-1086"><a href="#L-1086"><span class="linenos">1086</span></a>                <span class="c1"># pop those keys for generation</span>
</span><span id="L-1087"><a href="#L-1087"><span class="linenos">1087</span></a>                <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="L-1088"><a href="#L-1088"><span class="linenos">1088</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="L-1089"><a href="#L-1089"><span class="linenos">1089</span></a>                <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-1090"><a href="#L-1090"><span class="linenos">1090</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="L-1091"><a href="#L-1091"><span class="linenos">1091</span></a>                <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-1092"><a href="#L-1092"><span class="linenos">1092</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="L-1093"><a href="#L-1093"><span class="linenos">1093</span></a>                <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-1094"><a href="#L-1094"><span class="linenos">1094</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="L-1095"><a href="#L-1095"><span class="linenos">1095</span></a>                <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-1096"><a href="#L-1096"><span class="linenos">1096</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="L-1097"><a href="#L-1097"><span class="linenos">1097</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">])</span>
</span><span id="L-1098"><a href="#L-1098"><span class="linenos">1098</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1099"><a href="#L-1099"><span class="linenos">1099</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1100"><a href="#L-1100"><span class="linenos">1100</span></a>                <span class="n">gen_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="L-1101"><a href="#L-1101"><span class="linenos">1101</span></a>                    <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-1102"><a href="#L-1102"><span class="linenos">1102</span></a>                    <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="L-1103"><a href="#L-1103"><span class="linenos">1103</span></a>                <span class="p">)</span>
</span><span id="L-1104"><a href="#L-1104"><span class="linenos">1104</span></a>
</span><span id="L-1105"><a href="#L-1105"><span class="linenos">1105</span></a>                <span class="n">is_last_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span>
</span><span id="L-1106"><a href="#L-1106"><span class="linenos">1106</span></a>
</span><span id="L-1107"><a href="#L-1107"><span class="linenos">1107</span></a>                <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1108"><a href="#L-1108"><span class="linenos">1108</span></a>                    <span class="c1"># generate a batch</span>
</span><span id="L-1109"><a href="#L-1109"><span class="linenos">1109</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1110"><a href="#L-1110"><span class="linenos">1110</span></a>                        <span class="n">trajectories</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Trajectory</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1111"><a href="#L-1111"><span class="linenos">1111</span></a>                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="L-1112"><a href="#L-1112"><span class="linenos">1112</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="L-1113"><a href="#L-1113"><span class="linenos">1113</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1114"><a href="#L-1114"><span class="linenos">1114</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="L-1115"><a href="#L-1115"><span class="linenos">1115</span></a>                            <span class="c1"># gen_batch_output = self.explorer_manager.rollout(gen_batch)</span>
</span><span id="L-1116"><a href="#L-1116"><span class="linenos">1116</span></a>
</span><span id="L-1117"><a href="#L-1117"><span class="linenos">1117</span></a>                            <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="L-1118"><a href="#L-1118"><span class="linenos">1118</span></a>                                        <span class="n">task_id</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="L-1119"><a href="#L-1119"><span class="linenos">1119</span></a>                                        <span class="n">query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="L-1120"><a href="#L-1120"><span class="linenos">1120</span></a>                                        <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="L-1121"><a href="#L-1121"><span class="linenos">1121</span></a>                                        <span class="n">open_query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="L-1122"><a href="#L-1122"><span class="linenos">1122</span></a>                                        <span class="n">evaluator</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">],</span>
</span><span id="L-1123"><a href="#L-1123"><span class="linenos">1123</span></a>                                        <span class="n">ground_truth</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;ground_truth&#39;</span><span class="p">]</span>
</span><span id="L-1124"><a href="#L-1124"><span class="linenos">1124</span></a>                                    <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">))</span>
</span><span id="L-1125"><a href="#L-1125"><span class="linenos">1125</span></a>                            <span class="p">]</span>
</span><span id="L-1126"><a href="#L-1126"><span class="linenos">1126</span></a>                            <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
</span><span id="L-1127"><a href="#L-1127"><span class="linenos">1127</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_exp_configs</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">),</span> <span class="s2">&quot;{len(task_exp_configs)=}, {len(gen_batch)=}&quot;</span>
</span><span id="L-1128"><a href="#L-1128"><span class="linenos">1128</span></a>
</span><span id="L-1129"><a href="#L-1129"><span class="linenos">1129</span></a>                            <span class="c1"># TODO enable tracing by jinli 0619</span>
</span><span id="L-1130"><a href="#L-1130"><span class="linenos">1130</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-1131"><a href="#L-1131"><span class="linenos">1131</span></a>                            <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train.</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate trajectories using the environment manager</span>
</span><span id="L-1132"><a href="#L-1132"><span class="linenos">1132</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;{len(trajectories)=}?&quot;</span>
</span><span id="L-1133"><a href="#L-1133"><span class="linenos">1133</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="L-1134"><a href="#L-1134"><span class="linenos">1134</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">to_dataproto</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="L-1135"><a href="#L-1135"><span class="linenos">1135</span></a>                            
</span><span id="L-1136"><a href="#L-1136"><span class="linenos">1136</span></a>                            <span class="c1"># update metrics about experience manager</span>
</span><span id="L-1137"><a href="#L-1137"><span class="linenos">1137</span></a>                            <span class="n">exp_mask_ratio</span> <span class="o">=</span> <span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;exp_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="L-1138"><a href="#L-1138"><span class="linenos">1138</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_mask_ratio&quot;</span><span class="p">:</span> <span class="n">exp_mask_ratio</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
</span><span id="L-1139"><a href="#L-1139"><span class="linenos">1139</span></a>                            <span class="n">context_time_cost</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;context_time_cost&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trajectories</span> <span class="k">if</span> <span class="s2">&quot;context_time_cost&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">]</span>
</span><span id="L-1140"><a href="#L-1140"><span class="linenos">1140</span></a>                            <span class="k">if</span> <span class="n">context_time_cost</span><span class="p">:</span>
</span><span id="L-1141"><a href="#L-1141"><span class="linenos">1141</span></a>                                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
</span><span id="L-1142"><a href="#L-1142"><span class="linenos">1142</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_avg&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="L-1143"><a href="#L-1143"><span class="linenos">1143</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_max&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="L-1144"><a href="#L-1144"><span class="linenos">1144</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_min&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="L-1145"><a href="#L-1145"><span class="linenos">1145</span></a>                                <span class="p">})</span>
</span><span id="L-1146"><a href="#L-1146"><span class="linenos">1146</span></a>
</span><span id="L-1147"><a href="#L-1147"><span class="linenos">1147</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gen_batch_output.info batch.keys=</span><span class="si">{</span><span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1148"><a href="#L-1148"><span class="linenos">1148</span></a>                            <span class="n">num_term_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">traj</span><span class="o">.</span><span class="n">is_terminated</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="L-1149"><a href="#L-1149"><span class="linenos">1149</span></a>                            <span class="n">num_not_none_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="L-1150"><a href="#L-1150"><span class="linenos">1150</span></a>
</span><span id="L-1151"><a href="#L-1151"><span class="linenos">1151</span></a>                            <span class="c1"># gen_batch_output = self.async_rollout_manager.generate_sequences(gen_batch)</span>
</span><span id="L-1152"><a href="#L-1152"><span class="linenos">1152</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="L-1153"><a href="#L-1153"><span class="linenos">1153</span></a>
</span><span id="L-1154"><a href="#L-1154"><span class="linenos">1154</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">:</span>
</span><span id="L-1155"><a href="#L-1155"><span class="linenos">1155</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen_max&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1156"><a href="#L-1156"><span class="linenos">1156</span></a>                            <span class="n">gen_baseline_batch</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="L-1157"><a href="#L-1157"><span class="linenos">1157</span></a>                            <span class="n">gen_baseline_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;do_sample&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1158"><a href="#L-1158"><span class="linenos">1158</span></a>                            <span class="n">gen_baseline_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_baseline_batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate baseline sequences for advantage estimation</span>
</span><span id="L-1159"><a href="#L-1159"><span class="linenos">1159</span></a>
</span><span id="L-1160"><a href="#L-1160"><span class="linenos">1160</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="p">)</span>
</span><span id="L-1161"><a href="#L-1161"><span class="linenos">1161</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="L-1162"><a href="#L-1162"><span class="linenos">1162</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-1163"><a href="#L-1163"><span class="linenos">1163</span></a>
</span><span id="L-1164"><a href="#L-1164"><span class="linenos">1164</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">batch_keys</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</span><span id="L-1165"><a href="#L-1165"><span class="linenos">1165</span></a>
</span><span id="L-1166"><a href="#L-1166"><span class="linenos">1166</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span>  <span class="c1"># ‚≠ê Add reward baselines to the batch</span>
</span><span id="L-1167"><a href="#L-1167"><span class="linenos">1167</span></a>
</span><span id="L-1168"><a href="#L-1168"><span class="linenos">1168</span></a>                            <span class="k">del</span> <span class="n">gen_baseline_batch</span><span class="p">,</span> <span class="n">gen_baseline_output</span>
</span><span id="L-1169"><a href="#L-1169"><span class="linenos">1169</span></a>
</span><span id="L-1170"><a href="#L-1170"><span class="linenos">1170</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate unique UIDs for each item in the batch</span>
</span><span id="L-1171"><a href="#L-1171"><span class="linenos">1171</span></a>
</span><span id="L-1172"><a href="#L-1172"><span class="linenos">1172</span></a>                    <span class="c1"># in the new code, the rollout process generates new extras, which should be merged with the original extra.</span>
</span><span id="L-1173"><a href="#L-1173"><span class="linenos">1173</span></a>                    <span class="c1"># by now, they are stored seperately.</span>
</span><span id="L-1174"><a href="#L-1174"><span class="linenos">1174</span></a>                    <span class="c1"># assert len(gen_batch_output.non_tensor_batch[&quot;extras&quot;].keys()&amp;batch_extras.keys())==0, &quot;extra of extra should not overlap with existing extra...how funny...&quot;</span>
</span><span id="L-1175"><a href="#L-1175"><span class="linenos">1175</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;original_extras&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">batch_extras</span>  <span class="c1"># ‚≠ê Store original extras before scaling</span>
</span><span id="L-1176"><a href="#L-1176"><span class="linenos">1176</span></a>                    <span class="n">batch</span> <span class="o">=</span> <span class="n">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">gen_batch_output</span><span class="p">)</span>  <span class="c1"># ‚≠ê Merge generated batch with the current batch</span>
</span><span id="L-1177"><a href="#L-1177"><span class="linenos">1177</span></a>
</span><span id="L-1178"><a href="#L-1178"><span class="linenos">1178</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute and add response mask to the batch</span>
</span><span id="L-1179"><a href="#L-1179"><span class="linenos">1179</span></a>
</span><span id="L-1180"><a href="#L-1180"><span class="linenos">1180</span></a>                    <span class="c1"># update experience pool</span>
</span><span id="L-1181"><a href="#L-1181"><span class="linenos">1181</span></a>                    <span class="n">summary_task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">submit_summary_task</span><span class="p">(</span><span class="n">trajectories</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="L-1182"><a href="#L-1182"><span class="linenos">1182</span></a>
</span><span id="L-1183"><a href="#L-1183"><span class="linenos">1183</span></a>
</span><span id="L-1184"><a href="#L-1184"><span class="linenos">1184</span></a>                    <span class="c1"># balance the number of valid tokens on each dp rank.</span>
</span><span id="L-1185"><a href="#L-1185"><span class="linenos">1185</span></a>                    <span class="c1"># Note that this breaks the order of data inside the batch.</span>
</span><span id="L-1186"><a href="#L-1186"><span class="linenos">1186</span></a>                    <span class="c1"># Please take care when you implement group based adv computation such as GRPO and rloo</span>
</span><span id="L-1187"><a href="#L-1187"><span class="linenos">1187</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">balance_batch</span><span class="p">:</span>
</span><span id="L-1188"><a href="#L-1188"><span class="linenos">1188</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_balance_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>  <span class="c1"># ‚≠ê Balance the batch to distribute valid tokens evenly</span>
</span><span id="L-1189"><a href="#L-1189"><span class="linenos">1189</span></a>
</span><span id="L-1190"><a href="#L-1190"><span class="linenos">1190</span></a>                    <span class="c1"># compute global_valid tokens</span>
</span><span id="L-1191"><a href="#L-1191"><span class="linenos">1191</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;global_token_num&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ‚≠ê Compute and store the global token numbers</span>
</span><span id="L-1192"><a href="#L-1192"><span class="linenos">1192</span></a>
</span><span id="L-1193"><a href="#L-1193"><span class="linenos">1193</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;reward&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1194"><a href="#L-1194"><span class="linenos">1194</span></a>                        <span class="c1"># compute reward model score</span>
</span><span id="L-1195"><a href="#L-1195"><span class="linenos">1195</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="L-1196"><a href="#L-1196"><span class="linenos">1196</span></a>                            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">compute_rm_score</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reward scores using the reward model</span>
</span><span id="L-1197"><a href="#L-1197"><span class="linenos">1197</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">)</span>
</span><span id="L-1198"><a href="#L-1198"><span class="linenos">1198</span></a>
</span><span id="L-1199"><a href="#L-1199"><span class="linenos">1199</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="L-1200"><a href="#L-1200"><span class="linenos">1200</span></a>                            <span class="n">future_reward</span> <span class="o">=</span> <span class="n">compute_reward_async</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</span><span id="L-1201"><a href="#L-1201"><span class="linenos">1201</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1202"><a href="#L-1202"><span class="linenos">1202</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">compute_reward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute rewards and extra information</span>
</span><span id="L-1203"><a href="#L-1203"><span class="linenos">1203</span></a>
</span><span id="L-1204"><a href="#L-1204"><span class="linenos">1204</span></a>                    <span class="c1"># recompute old_log_probs</span>
</span><span id="L-1205"><a href="#L-1205"><span class="linenos">1205</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;old_log_prob&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1206"><a href="#L-1206"><span class="linenos">1206</span></a>                        <span class="n">old_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute old log probabilities</span>
</span><span id="L-1207"><a href="#L-1207"><span class="linenos">1207</span></a>                        <span class="n">entropys</span> <span class="o">=</span> <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;entropys&quot;</span><span class="p">]</span>
</span><span id="L-1208"><a href="#L-1208"><span class="linenos">1208</span></a>                        <span class="n">response_masks</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
</span><span id="L-1209"><a href="#L-1209"><span class="linenos">1209</span></a>                        <span class="n">loss_agg_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span>
</span><span id="L-1210"><a href="#L-1210"><span class="linenos">1210</span></a>                        <span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">agg_loss</span><span class="p">(</span><span class="n">loss_mat</span><span class="o">=</span><span class="n">entropys</span><span class="p">,</span> <span class="n">loss_mask</span><span class="o">=</span><span class="n">response_masks</span><span class="p">,</span> <span class="n">loss_agg_mode</span><span class="o">=</span><span class="n">loss_agg_mode</span><span class="p">)</span>
</span><span id="L-1211"><a href="#L-1211"><span class="linenos">1211</span></a>                        <span class="n">old_log_prob_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;actor/entropy_loss&quot;</span><span class="p">:</span> <span class="n">entropy_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
</span><span id="L-1212"><a href="#L-1212"><span class="linenos">1212</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">old_log_prob_metrics</span><span class="p">)</span>
</span><span id="L-1213"><a href="#L-1213"><span class="linenos">1213</span></a>                        <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;entropys&quot;</span><span class="p">)</span>
</span><span id="L-1214"><a href="#L-1214"><span class="linenos">1214</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">old_log_prob</span><span class="p">)</span>
</span><span id="L-1215"><a href="#L-1215"><span class="linenos">1215</span></a>
</span><span id="L-1216"><a href="#L-1216"><span class="linenos">1216</span></a>                        <span class="k">if</span> <span class="s2">&quot;rollout_log_probs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-1217"><a href="#L-1217"><span class="linenos">1217</span></a>                            <span class="c1"># TODO: we may want to add diff of probs too.</span>
</span><span id="L-1218"><a href="#L-1218"><span class="linenos">1218</span></a>                            <span class="n">rollout_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rollout_log_probs&quot;</span><span class="p">]</span>
</span><span id="L-1219"><a href="#L-1219"><span class="linenos">1219</span></a>                            <span class="n">actor_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;old_log_probs&quot;</span><span class="p">]</span>
</span><span id="L-1220"><a href="#L-1220"><span class="linenos">1220</span></a>                            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="L-1221"><a href="#L-1221"><span class="linenos">1221</span></a>                            <span class="n">responses</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
</span><span id="L-1222"><a href="#L-1222"><span class="linenos">1222</span></a>                            <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-1223"><a href="#L-1223"><span class="linenos">1223</span></a>                            <span class="n">response_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
</span><span id="L-1224"><a href="#L-1224"><span class="linenos">1224</span></a>
</span><span id="L-1225"><a href="#L-1225"><span class="linenos">1225</span></a>                            <span class="n">rollout_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">rollout_old_log_probs</span><span class="p">)</span>
</span><span id="L-1226"><a href="#L-1226"><span class="linenos">1226</span></a>                            <span class="n">actor_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">actor_old_log_probs</span><span class="p">)</span>
</span><span id="L-1227"><a href="#L-1227"><span class="linenos">1227</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">rollout_probs</span> <span class="o">-</span> <span class="n">actor_probs</span><span class="p">)</span>
</span><span id="L-1228"><a href="#L-1228"><span class="linenos">1228</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">,</span> <span class="n">response_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
</span><span id="L-1229"><a href="#L-1229"><span class="linenos">1229</span></a>                            <span class="n">rollout_probs_diff_max</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="L-1230"><a href="#L-1230"><span class="linenos">1230</span></a>                            <span class="n">rollout_probs_diff_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="L-1231"><a href="#L-1231"><span class="linenos">1231</span></a>                            <span class="n">rollout_probs_diff_std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="L-1232"><a href="#L-1232"><span class="linenos">1232</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="L-1233"><a href="#L-1233"><span class="linenos">1233</span></a>                                <span class="p">{</span>
</span><span id="L-1234"><a href="#L-1234"><span class="linenos">1234</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_max&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_max</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="L-1235"><a href="#L-1235"><span class="linenos">1235</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_mean&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="L-1236"><a href="#L-1236"><span class="linenos">1236</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_std&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_std</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="L-1237"><a href="#L-1237"><span class="linenos">1237</span></a>                                <span class="p">}</span>
</span><span id="L-1238"><a href="#L-1238"><span class="linenos">1238</span></a>                            <span class="p">)</span>
</span><span id="L-1239"><a href="#L-1239"><span class="linenos">1239</span></a>
</span><span id="L-1240"><a href="#L-1240"><span class="linenos">1240</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="L-1241"><a href="#L-1241"><span class="linenos">1241</span></a>                        <span class="c1"># compute reference log_prob</span>
</span><span id="L-1242"><a href="#L-1242"><span class="linenos">1242</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;ref&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1243"><a href="#L-1243"><span class="linenos">1243</span></a>                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="L-1244"><a href="#L-1244"><span class="linenos">1244</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reference log probabilities</span>
</span><span id="L-1245"><a href="#L-1245"><span class="linenos">1245</span></a>                            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1246"><a href="#L-1246"><span class="linenos">1246</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="L-1247"><a href="#L-1247"><span class="linenos">1247</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">ref_log_prob</span><span class="p">)</span>
</span><span id="L-1248"><a href="#L-1248"><span class="linenos">1248</span></a>
</span><span id="L-1249"><a href="#L-1249"><span class="linenos">1249</span></a>                    <span class="c1"># compute values</span>
</span><span id="L-1250"><a href="#L-1250"><span class="linenos">1250</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="L-1251"><a href="#L-1251"><span class="linenos">1251</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1252"><a href="#L-1252"><span class="linenos">1252</span></a>                            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">compute_values</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute values using the critic model</span>
</span><span id="L-1253"><a href="#L-1253"><span class="linenos">1253</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</span><span id="L-1254"><a href="#L-1254"><span class="linenos">1254</span></a>
</span><span id="L-1255"><a href="#L-1255"><span class="linenos">1255</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;adv&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1256"><a href="#L-1256"><span class="linenos">1256</span></a>                        <span class="c1"># we combine with rule-based rm</span>
</span><span id="L-1257"><a href="#L-1257"><span class="linenos">1257</span></a>                        <span class="n">reward_extra_infos_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>
</span><span id="L-1258"><a href="#L-1258"><span class="linenos">1258</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="L-1259"><a href="#L-1259"><span class="linenos">1259</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">future_reward</span><span class="p">)</span>  <span class="c1"># ‚≠ê Get the reward tensor and extra info from the async call</span>
</span><span id="L-1260"><a href="#L-1260"><span class="linenos">1260</span></a>                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_tensor</span>
</span><span id="L-1261"><a href="#L-1261"><span class="linenos">1261</span></a>
</span><span id="L-1262"><a href="#L-1262"><span class="linenos">1262</span></a>                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1263"><a href="#L-1263"><span class="linenos">1263</span></a>                        <span class="k">if</span> <span class="n">reward_extra_infos_dict</span><span class="p">:</span>
</span><span id="L-1264"><a href="#L-1264"><span class="linenos">1264</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
</span><span id="L-1265"><a href="#L-1265"><span class="linenos">1265</span></a>
</span><span id="L-1266"><a href="#L-1266"><span class="linenos">1266</span></a>                        <span class="c1"># compute rewards. apply_kl_penalty if available</span>
</span><span id="L-1267"><a href="#L-1267"><span class="linenos">1267</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="L-1268"><a href="#L-1268"><span class="linenos">1268</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">kl_metrics</span> <span class="o">=</span> <span class="n">apply_kl_penalty</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">kl_ctrl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span><span class="p">,</span> <span class="n">kl_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_penalty</span><span class="p">)</span>  <span class="c1"># ‚≠ê Apply KL divergence penalty</span>
</span><span id="L-1269"><a href="#L-1269"><span class="linenos">1269</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kl_metrics</span><span class="p">)</span>
</span><span id="L-1270"><a href="#L-1270"><span class="linenos">1270</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1271"><a href="#L-1271"><span class="linenos">1271</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span>
</span><span id="L-1272"><a href="#L-1272"><span class="linenos">1272</span></a>
</span><span id="L-1273"><a href="#L-1273"><span class="linenos">1273</span></a>                        <span class="c1"># compute advantages, executed on the driver process</span>
</span><span id="L-1274"><a href="#L-1274"><span class="linenos">1274</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># GRPO adv normalization factor</span>
</span><span id="L-1275"><a href="#L-1275"><span class="linenos">1275</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;disable_adv_std&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="L-1276"><a href="#L-1276"><span class="linenos">1276</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="L-1277"><a href="#L-1277"><span class="linenos">1277</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change norm_adv_by_std_in_grpo from True to False, using batch std!&quot;</span><span class="p">)</span>
</span><span id="L-1278"><a href="#L-1278"><span class="linenos">1278</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1279"><a href="#L-1279"><span class="linenos">1279</span></a>
</span><span id="L-1280"><a href="#L-1280"><span class="linenos">1280</span></a>                        <span class="c1"># call the original compute_advantage for compatibility</span>
</span><span id="L-1281"><a href="#L-1281"><span class="linenos">1281</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-1282"><a href="#L-1282"><span class="linenos">1282</span></a>
</span><span id="L-1283"><a href="#L-1283"><span class="linenos">1283</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">compute_advantage</span><span class="p">(</span>
</span><span id="L-1284"><a href="#L-1284"><span class="linenos">1284</span></a>                            <span class="n">batch</span><span class="p">,</span>
</span><span id="L-1285"><a href="#L-1285"><span class="linenos">1285</span></a>                            <span class="n">adv_estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span><span class="p">,</span>
</span><span id="L-1286"><a href="#L-1286"><span class="linenos">1286</span></a>                            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="L-1287"><a href="#L-1287"><span class="linenos">1287</span></a>                            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span>
</span><span id="L-1288"><a href="#L-1288"><span class="linenos">1288</span></a>                            <span class="n">num_repeat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
</span><span id="L-1289"><a href="#L-1289"><span class="linenos">1289</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="n">norm_adv_by_std_in_grpo</span><span class="p">,</span>
</span><span id="L-1290"><a href="#L-1290"><span class="linenos">1290</span></a>                            <span class="n">multi_turn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span>
</span><span id="L-1291"><a href="#L-1291"><span class="linenos">1291</span></a>                            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="p">,</span>
</span><span id="L-1292"><a href="#L-1292"><span class="linenos">1292</span></a>                        <span class="p">)</span>
</span><span id="L-1293"><a href="#L-1293"><span class="linenos">1293</span></a>                        <span class="c1"># shuchang</span>
</span><span id="L-1294"><a href="#L-1294"><span class="linenos">1294</span></a>                        <span class="c1"># ==================== Begin ADCA GRPO  ====================</span>
</span><span id="L-1295"><a href="#L-1295"><span class="linenos">1295</span></a>                        <span class="n">attribution_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_attribution_config</span><span class="p">()</span>
</span><span id="L-1296"><a href="#L-1296"><span class="linenos">1296</span></a>                        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">attribution_cfg</span><span class="p">,</span> <span class="s1">&#39;enable&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-1297"><a href="#L-1297"><span class="linenos">1297</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">adca_metrics</span> <span class="o">=</span> <span class="n">apply_adca_grpo</span><span class="p">(</span>
</span><span id="L-1298"><a href="#L-1298"><span class="linenos">1298</span></a>                                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
</span><span id="L-1299"><a href="#L-1299"><span class="linenos">1299</span></a>                                <span class="n">attribution_cfg</span><span class="o">=</span><span class="n">attribution_cfg</span><span class="p">,</span>
</span><span id="L-1300"><a href="#L-1300"><span class="linenos">1300</span></a>                                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="L-1301"><a href="#L-1301"><span class="linenos">1301</span></a>                                <span class="n">global_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="L-1302"><a href="#L-1302"><span class="linenos">1302</span></a>                                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
</span><span id="L-1303"><a href="#L-1303"><span class="linenos">1303</span></a>                                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
</span><span id="L-1304"><a href="#L-1304"><span class="linenos">1304</span></a>                            <span class="p">)</span>
</span><span id="L-1305"><a href="#L-1305"><span class="linenos">1305</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">adca_metrics</span><span class="p">)</span>
</span><span id="L-1306"><a href="#L-1306"><span class="linenos">1306</span></a>                        <span class="c1"># ==================== End ADCA GRPO ====================</span>
</span><span id="L-1307"><a href="#L-1307"><span class="linenos">1307</span></a>                        <span class="c1"># Apply decay factor of 0.5 to non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;] != &#39;env&#39;</span>
</span><span id="L-1308"><a href="#L-1308"><span class="linenos">1308</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;synth_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="L-1309"><a href="#L-1309"><span class="linenos">1309</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="L-1310"><a href="#L-1310"><span class="linenos">1310</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="L-1311"><a href="#L-1311"><span class="linenos">1311</span></a>                            <span class="k">assert</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span>
</span><span id="L-1312"><a href="#L-1312"><span class="linenos">1312</span></a>                            <span class="k">if</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="L-1313"><a href="#L-1313"><span class="linenos">1313</span></a>                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">])):</span>
</span><span id="L-1314"><a href="#L-1314"><span class="linenos">1314</span></a>                                    <span class="k">assert</span> <span class="s1">&#39;evaluator&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="L-1315"><a href="#L-1315"><span class="linenos">1315</span></a>                                    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">]</span>
</span><span id="L-1316"><a href="#L-1316"><span class="linenos">1316</span></a>                                    <span class="k">if</span> <span class="n">evaluator</span> <span class="o">!=</span> <span class="s1">&#39;env&#39;</span><span class="p">:</span>
</span><span id="L-1317"><a href="#L-1317"><span class="linenos">1317</span></a>                                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span>  <span class="c1"># ‚≠ê Apply decay factor to synthetic data</span>
</span><span id="L-1318"><a href="#L-1318"><span class="linenos">1318</span></a>
</span><span id="L-1319"><a href="#L-1319"><span class="linenos">1319</span></a>                    <span class="c1"># update critic</span>
</span><span id="L-1320"><a href="#L-1320"><span class="linenos">1320</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="L-1321"><a href="#L-1321"><span class="linenos">1321</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_critic&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1322"><a href="#L-1322"><span class="linenos">1322</span></a>                            <span class="n">critic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">update_critic</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the critic model</span>
</span><span id="L-1323"><a href="#L-1323"><span class="linenos">1323</span></a>                        <span class="n">critic_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">critic_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="L-1324"><a href="#L-1324"><span class="linenos">1324</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">critic_output_metrics</span><span class="p">)</span>
</span><span id="L-1325"><a href="#L-1325"><span class="linenos">1325</span></a>
</span><span id="L-1326"><a href="#L-1326"><span class="linenos">1326</span></a>                    <span class="c1"># implement critic warmup</span>
</span><span id="L-1327"><a href="#L-1327"><span class="linenos">1327</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">critic_warmup</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">:</span>
</span><span id="L-1328"><a href="#L-1328"><span class="linenos">1328</span></a>                        <span class="c1"># update actor</span>
</span><span id="L-1329"><a href="#L-1329"><span class="linenos">1329</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_actor&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1330"><a href="#L-1330"><span class="linenos">1330</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;multi_turn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span>
</span><span id="L-1331"><a href="#L-1331"><span class="linenos">1331</span></a>                            <span class="n">actor_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">update_actor</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the actor with the new batch</span>
</span><span id="L-1332"><a href="#L-1332"><span class="linenos">1332</span></a>                        <span class="n">actor_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">actor_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="L-1333"><a href="#L-1333"><span class="linenos">1333</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">actor_output_metrics</span><span class="p">)</span>
</span><span id="L-1334"><a href="#L-1334"><span class="linenos">1334</span></a>                    
</span><span id="L-1335"><a href="#L-1335"><span class="linenos">1335</span></a>                    <span class="c1"># collect summary tasks</span>
</span><span id="L-1336"><a href="#L-1336"><span class="linenos">1336</span></a>                    <span class="k">if</span> <span class="n">summary_task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1337"><a href="#L-1337"><span class="linenos">1337</span></a>                        <span class="n">time_cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">collect_summary_result</span><span class="p">(</span><span class="n">summary_task</span><span class="p">)</span>
</span><span id="L-1338"><a href="#L-1338"><span class="linenos">1338</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_manager/summary&quot;</span><span class="p">:</span> <span class="n">time_cost</span><span class="p">})</span>
</span><span id="L-1339"><a href="#L-1339"><span class="linenos">1339</span></a>
</span><span id="L-1340"><a href="#L-1340"><span class="linenos">1340</span></a>
</span><span id="L-1341"><a href="#L-1341"><span class="linenos">1341</span></a>                    <span class="c1"># Log rollout generations if enabled</span>
</span><span id="L-1342"><a href="#L-1342"><span class="linenos">1342</span></a>                    <span class="n">rollout_data_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rollout_data_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-1343"><a href="#L-1343"><span class="linenos">1343</span></a>                    <span class="k">if</span> <span class="n">rollout_data_dir</span><span class="p">:</span>
</span><span id="L-1344"><a href="#L-1344"><span class="linenos">1344</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;dump_rollout_generations&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1345"><a href="#L-1345"><span class="linenos">1345</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="L-1346"><a href="#L-1346"><span class="linenos">1346</span></a>                            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-1347"><a href="#L-1347"><span class="linenos">1347</span></a>                            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-1348"><a href="#L-1348"><span class="linenos">1348</span></a>                            <span class="n">scores</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="L-1349"><a href="#L-1349"><span class="linenos">1349</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_dump_generations</span><span class="p">(</span>
</span><span id="L-1350"><a href="#L-1350"><span class="linenos">1350</span></a>                                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
</span><span id="L-1351"><a href="#L-1351"><span class="linenos">1351</span></a>                                <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
</span><span id="L-1352"><a href="#L-1352"><span class="linenos">1352</span></a>                                <span class="n">scores</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span id="L-1353"><a href="#L-1353"><span class="linenos">1353</span></a>                                <span class="n">reward_extra_infos_dict</span><span class="o">=</span><span class="n">reward_extra_infos_dict</span><span class="p">,</span>
</span><span id="L-1354"><a href="#L-1354"><span class="linenos">1354</span></a>                                <span class="n">dump_path</span><span class="o">=</span><span class="n">rollout_data_dir</span><span class="p">,</span>
</span><span id="L-1355"><a href="#L-1355"><span class="linenos">1355</span></a>                            <span class="p">)</span>  <span class="c1"># ‚≠ê Dump the generated experiences and trajectories</span>
</span><span id="L-1356"><a href="#L-1356"><span class="linenos">1356</span></a>
</span><span id="L-1357"><a href="#L-1357"><span class="linenos">1357</span></a>                            <span class="c1"># save original trajectory</span>
</span><span id="L-1358"><a href="#L-1358"><span class="linenos">1358</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;traj_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="L-1359"><a href="#L-1359"><span class="linenos">1359</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-1360"><a href="#L-1360"><span class="linenos">1360</span></a>                                <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">:</span>
</span><span id="L-1361"><a href="#L-1361"><span class="linenos">1361</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1362"><a href="#L-1362"><span class="linenos">1362</span></a>                            <span class="c1"># save tasks</span>
</span><span id="L-1363"><a href="#L-1363"><span class="linenos">1363</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;task_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="L-1364"><a href="#L-1364"><span class="linenos">1364</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-1365"><a href="#L-1365"><span class="linenos">1365</span></a>                                <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span> <span class="c1"># this must be bounded # type: ignore</span>
</span><span id="L-1366"><a href="#L-1366"><span class="linenos">1366</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1367"><a href="#L-1367"><span class="linenos">1367</span></a>
</span><span id="L-1368"><a href="#L-1368"><span class="linenos">1368</span></a>                    <span class="c1"># validate</span>
</span><span id="L-1369"><a href="#L-1369"><span class="linenos">1369</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="L-1370"><a href="#L-1370"><span class="linenos">1370</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1371"><a href="#L-1371"><span class="linenos">1371</span></a>                            <span class="n">val_metrics</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Validate the model and collect validation metrics</span>
</span><span id="L-1372"><a href="#L-1372"><span class="linenos">1372</span></a>                            <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="L-1373"><a href="#L-1373"><span class="linenos">1373</span></a>                                <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="n">val_metrics</span>
</span><span id="L-1374"><a href="#L-1374"><span class="linenos">1374</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_metrics</span><span class="p">)</span>
</span><span id="L-1375"><a href="#L-1375"><span class="linenos">1375</span></a>
</span><span id="L-1376"><a href="#L-1376"><span class="linenos">1376</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="L-1377"><a href="#L-1377"><span class="linenos">1377</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="L-1378"><a href="#L-1378"><span class="linenos">1378</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">()</span>  <span class="c1"># ‚≠ê Save the current state of the model as a checkpoint</span>
</span><span id="L-1379"><a href="#L-1379"><span class="linenos">1379</span></a>
</span><span id="L-1380"><a href="#L-1380"><span class="linenos">1380</span></a>                <span class="c1"># training metrics</span>
</span><span id="L-1381"><a href="#L-1381"><span class="linenos">1381</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="L-1382"><a href="#L-1382"><span class="linenos">1382</span></a>                    <span class="p">{</span>
</span><span id="L-1383"><a href="#L-1383"><span class="linenos">1383</span></a>                        <span class="s2">&quot;training/global_step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="L-1384"><a href="#L-1384"><span class="linenos">1384</span></a>                        <span class="s2">&quot;training/epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
</span><span id="L-1385"><a href="#L-1385"><span class="linenos">1385</span></a>                        <span class="s2">&quot;training/num_not_none_traj&quot;</span><span class="p">:</span> <span class="n">num_not_none_traj</span><span class="p">,</span>
</span><span id="L-1386"><a href="#L-1386"><span class="linenos">1386</span></a>                        <span class="s2">&quot;training/num_term_traj&quot;</span><span class="p">:</span> <span class="n">num_term_traj</span>
</span><span id="L-1387"><a href="#L-1387"><span class="linenos">1387</span></a>                    <span class="p">}</span>
</span><span id="L-1388"><a href="#L-1388"><span class="linenos">1388</span></a>                <span class="p">)</span>
</span><span id="L-1389"><a href="#L-1389"><span class="linenos">1389</span></a>                <span class="c1"># collect metrics</span>
</span><span id="L-1390"><a href="#L-1390"><span class="linenos">1390</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_data_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">use_critic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">))</span>
</span><span id="L-1391"><a href="#L-1391"><span class="linenos">1391</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_timing_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">))</span>
</span><span id="L-1392"><a href="#L-1392"><span class="linenos">1392</span></a>                <span class="c1"># TODO: implement actual tflpo and theoretical tflpo</span>
</span><span id="L-1393"><a href="#L-1393"><span class="linenos">1393</span></a>                <span class="n">n_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_n_gpus</span><span class="p">()</span>
</span><span id="L-1394"><a href="#L-1394"><span class="linenos">1394</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_throughout_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">,</span> <span class="n">n_gpus</span><span class="o">=</span><span class="n">n_gpus</span><span class="p">))</span>
</span><span id="L-1395"><a href="#L-1395"><span class="linenos">1395</span></a>
</span><span id="L-1396"><a href="#L-1396"><span class="linenos">1396</span></a>                <span class="c1"># TODO: make a canonical logger that supports various backend</span>
</span><span id="L-1397"><a href="#L-1397"><span class="linenos">1397</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>  <span class="c1"># ‚≠ê Log the collected metrics</span>
</span><span id="L-1398"><a href="#L-1398"><span class="linenos">1398</span></a>
</span><span id="L-1399"><a href="#L-1399"><span class="linenos">1399</span></a>                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-1400"><a href="#L-1400"><span class="linenos">1400</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-1401"><a href="#L-1401"><span class="linenos">1401</span></a>                <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="L-1402"><a href="#L-1402"><span class="linenos">1402</span></a>                    <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final validation metrics: </span><span class="si">{</span><span class="n">last_val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-1403"><a href="#L-1403"><span class="linenos">1403</span></a>                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="L-1404"><a href="#L-1404"><span class="linenos">1404</span></a>                    <span class="k">return</span>
</span><span id="L-1405"><a href="#L-1405"><span class="linenos">1405</span></a>
</span><span id="L-1406"><a href="#L-1406"><span class="linenos">1406</span></a>            <span class="c1"># we expect the train dataset is fully explored at the beginning, no reload needed.</span>
</span><span id="L-1407"><a href="#L-1407"><span class="linenos">1407</span></a>            <span class="c1"># if isinstance(self.train_dataset, FullDataset):</span>
</span><span id="L-1408"><a href="#L-1408"><span class="linenos">1408</span></a>            <span class="c1">#     self.train_dataset.reload()</span>
</span><span id="L-1409"><a href="#L-1409"><span class="linenos">1409</span></a>            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ratio_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="L-1410"><a href="#L-1410"><span class="linenos">1410</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager.data_mixture</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedMixtureStrategy</span>
</span><span id="L-1411"><a href="#L-1411"><span class="linenos">1411</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="L-1412"><a href="#L-1412"><span class="linenos">1412</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span><span class="n">UnifiedMixtureStrategy</span><span class="p">)</span>
</span><span id="L-1413"><a href="#L-1413"><span class="linenos">1413</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="o">.</span><span class="n">_synthetic_ratio</span><span class="o">-=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span> <span class="c1"># initial 1, 0 at about epoch 5 (about step 30)</span>
</span><span id="L-1414"><a href="#L-1414"><span class="linenos">1414</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>  <span class="c1"># ‚≠ê Update the training dataset for the next iteration</span>
</span></pre></div>


            </section>
                <section id="parse_reward_from_dataproto">
                            <input id="parse_reward_from_dataproto-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">parse_reward_from_dataproto</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">data</span><span class="p">:</span> <span class="n">verl</span><span class="o">.</span><span class="n">protocol</span><span class="o">.</span><span class="n">DataProto</span>, </span><span class="param"><span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span></span><span class="return-annotation">) -> <span class="nb">dict</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="parse_reward_from_dataproto-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#parse_reward_from_dataproto"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="parse_reward_from_dataproto-73"><a href="#parse_reward_from_dataproto-73"><span class="linenos"> 73</span></a><span class="k">def</span><span class="w"> </span><span class="nf">parse_reward_from_dataproto</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="parse_reward_from_dataproto-74"><a href="#parse_reward_from_dataproto-74"><span class="linenos"> 74</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="parse_reward_from_dataproto-75"><a href="#parse_reward_from_dataproto-75"><span class="linenos"> 75</span></a><span class="sd">    Compute reward for a batch of data.</span>
</span><span id="parse_reward_from_dataproto-76"><a href="#parse_reward_from_dataproto-76"><span class="linenos"> 76</span></a>
</span><span id="parse_reward_from_dataproto-77"><a href="#parse_reward_from_dataproto-77"><span class="linenos"> 77</span></a><span class="sd">    Args:</span>
</span><span id="parse_reward_from_dataproto-78"><a href="#parse_reward_from_dataproto-78"><span class="linenos"> 78</span></a><span class="sd">        data: DataProto object containing the input data.</span>
</span><span id="parse_reward_from_dataproto-79"><a href="#parse_reward_from_dataproto-79"><span class="linenos"> 79</span></a><span class="sd">        return_dict: Whether to return a dictionary or just the reward tensor.</span>
</span><span id="parse_reward_from_dataproto-80"><a href="#parse_reward_from_dataproto-80"><span class="linenos"> 80</span></a>
</span><span id="parse_reward_from_dataproto-81"><a href="#parse_reward_from_dataproto-81"><span class="linenos"> 81</span></a><span class="sd">    Returns:</span>
</span><span id="parse_reward_from_dataproto-82"><a href="#parse_reward_from_dataproto-82"><span class="linenos"> 82</span></a><span class="sd">        Tensor of shape (bs, response_len) if return_dict is False,</span>
</span><span id="parse_reward_from_dataproto-83"><a href="#parse_reward_from_dataproto-83"><span class="linenos"> 83</span></a><span class="sd">        or a dict with &#39;reward_tensor&#39; and &#39;reward_extra_info&#39;.</span>
</span><span id="parse_reward_from_dataproto-84"><a href="#parse_reward_from_dataproto-84"><span class="linenos"> 84</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="parse_reward_from_dataproto-85"><a href="#parse_reward_from_dataproto-85"><span class="linenos"> 85</span></a>    <span class="c1"># Within DataFlow, world.execute() will pass a float score, which will be contained in the DataProto.non_tensor_batch(&#39;reward_scores&#39;)</span>
</span><span id="parse_reward_from_dataproto-86"><a href="#parse_reward_from_dataproto-86"><span class="linenos"> 86</span></a>
</span><span id="parse_reward_from_dataproto-87"><a href="#parse_reward_from_dataproto-87"><span class="linenos"> 87</span></a>    <span class="c1"># Initialize reward tensor</span>
</span><span id="parse_reward_from_dataproto-88"><a href="#parse_reward_from_dataproto-88"><span class="linenos"> 88</span></a>    <span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (bs, reslen)  # ‚≠ê Initialize the reward tensor</span>
</span><span id="parse_reward_from_dataproto-89"><a href="#parse_reward_from_dataproto-89"><span class="linenos"> 89</span></a>    <span class="n">reward_extra_info</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="parse_reward_from_dataproto-90"><a href="#parse_reward_from_dataproto-90"><span class="linenos"> 90</span></a>
</span><span id="parse_reward_from_dataproto-91"><a href="#parse_reward_from_dataproto-91"><span class="linenos"> 91</span></a>    <span class="c1"># Batch-level processing</span>
</span><span id="parse_reward_from_dataproto-92"><a href="#parse_reward_from_dataproto-92"><span class="linenos"> 92</span></a>    <span class="n">prompt_ids_batch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span>  <span class="c1"># (bs, prompt_len)</span>
</span><span id="parse_reward_from_dataproto-93"><a href="#parse_reward_from_dataproto-93"><span class="linenos"> 93</span></a>    <span class="n">prompt_lengths</span> <span class="o">=</span> <span class="n">prompt_ids_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="parse_reward_from_dataproto-94"><a href="#parse_reward_from_dataproto-94"><span class="linenos"> 94</span></a>
</span><span id="parse_reward_from_dataproto-95"><a href="#parse_reward_from_dataproto-95"><span class="linenos"> 95</span></a>    <span class="c1"># Get attention masks for all items</span>
</span><span id="parse_reward_from_dataproto-96"><a href="#parse_reward_from_dataproto-96"><span class="linenos"> 96</span></a>    <span class="n">attention_masks</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>  <span class="c1"># (bs, total_len)</span>
</span><span id="parse_reward_from_dataproto-97"><a href="#parse_reward_from_dataproto-97"><span class="linenos"> 97</span></a>    <span class="n">response_lengths</span> <span class="o">=</span> <span class="n">attention_masks</span><span class="p">[:,</span> <span class="n">prompt_lengths</span><span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (bs, )</span>
</span><span id="parse_reward_from_dataproto-98"><a href="#parse_reward_from_dataproto-98"><span class="linenos"> 98</span></a>
</span><span id="parse_reward_from_dataproto-99"><a href="#parse_reward_from_dataproto-99"><span class="linenos"> 99</span></a>    <span class="c1"># Get reward scores</span>
</span><span id="parse_reward_from_dataproto-100"><a href="#parse_reward_from_dataproto-100"><span class="linenos">100</span></a>    <span class="n">reward_scores_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;outcome&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_scores&quot;</span><span class="p">]]</span>
</span><span id="parse_reward_from_dataproto-101"><a href="#parse_reward_from_dataproto-101"><span class="linenos">101</span></a>    <span class="n">reward_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">reward_scores_list</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">reward_tensor</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (bs, )  # ‚≠ê Convert reward scores to a tensor</span>
</span><span id="parse_reward_from_dataproto-102"><a href="#parse_reward_from_dataproto-102"><span class="linenos">102</span></a>
</span><span id="parse_reward_from_dataproto-103"><a href="#parse_reward_from_dataproto-103"><span class="linenos">103</span></a>    <span class="c1"># Use advanced indexing to assign rewards</span>
</span><span id="parse_reward_from_dataproto-104"><a href="#parse_reward_from_dataproto-104"><span class="linenos">104</span></a>    <span class="n">reward_tensor</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)),</span> <span class="n">response_lengths</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_scores</span>
</span><span id="parse_reward_from_dataproto-105"><a href="#parse_reward_from_dataproto-105"><span class="linenos">105</span></a>
</span><span id="parse_reward_from_dataproto-106"><a href="#parse_reward_from_dataproto-106"><span class="linenos">106</span></a>    <span class="k">if</span> <span class="n">return_dict</span><span class="p">:</span>
</span><span id="parse_reward_from_dataproto-107"><a href="#parse_reward_from_dataproto-107"><span class="linenos">107</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="parse_reward_from_dataproto-108"><a href="#parse_reward_from_dataproto-108"><span class="linenos">108</span></a>            <span class="s2">&quot;reward_tensor&quot;</span><span class="p">:</span> <span class="n">reward_tensor</span><span class="p">,</span>
</span><span id="parse_reward_from_dataproto-109"><a href="#parse_reward_from_dataproto-109"><span class="linenos">109</span></a>            <span class="s2">&quot;reward_extra_info&quot;</span><span class="p">:</span> <span class="n">reward_extra_info</span><span class="p">,</span>
</span><span id="parse_reward_from_dataproto-110"><a href="#parse_reward_from_dataproto-110"><span class="linenos">110</span></a>        <span class="p">}</span>
</span><span id="parse_reward_from_dataproto-111"><a href="#parse_reward_from_dataproto-111"><span class="linenos">111</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="parse_reward_from_dataproto-112"><a href="#parse_reward_from_dataproto-112"><span class="linenos">112</span></a>        <span class="k">return</span> <span class="n">reward_tensor</span>
</span></pre></div>


            <div class="docstring"><p>Compute reward for a batch of data.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>data:</strong>  DataProto object containing the input data.</li>
<li><strong>return_dict:</strong>  Whether to return a dictionary or just the reward tensor.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Tensor of shape (bs, response_len) if return_dict is False,
  or a dict with 'reward_tensor' and 'reward_extra_info'.</p>
</blockquote>
</div>


                </section>
                <section id="create_rl_sampler">
                            <input id="create_rl_sampler-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">create_rl_sampler</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">data_config</span>, </span><span class="param"><span class="n">dataset</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="create_rl_sampler-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#create_rl_sampler"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="create_rl_sampler-115"><a href="#create_rl_sampler-115"><span class="linenos">115</span></a><span class="k">def</span><span class="w"> </span><span class="nf">create_rl_sampler</span><span class="p">(</span><span class="n">data_config</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
</span><span id="create_rl_sampler-116"><a href="#create_rl_sampler-116"><span class="linenos">116</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a sampler for the dataset.</span>
</span><span id="create_rl_sampler-117"><a href="#create_rl_sampler-117"><span class="linenos">117</span></a>
</span><span id="create_rl_sampler-118"><a href="#create_rl_sampler-118"><span class="linenos">118</span></a><span class="sd">    Arguments:</span>
</span><span id="create_rl_sampler-119"><a href="#create_rl_sampler-119"><span class="linenos">119</span></a><span class="sd">        data_config: The data config.</span>
</span><span id="create_rl_sampler-120"><a href="#create_rl_sampler-120"><span class="linenos">120</span></a><span class="sd">        dataset (Dataset): The dataset.</span>
</span><span id="create_rl_sampler-121"><a href="#create_rl_sampler-121"><span class="linenos">121</span></a>
</span><span id="create_rl_sampler-122"><a href="#create_rl_sampler-122"><span class="linenos">122</span></a><span class="sd">    Returns:</span>
</span><span id="create_rl_sampler-123"><a href="#create_rl_sampler-123"><span class="linenos">123</span></a><span class="sd">        sampler (Sampler): The sampler.</span>
</span><span id="create_rl_sampler-124"><a href="#create_rl_sampler-124"><span class="linenos">124</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="create_rl_sampler-125"><a href="#create_rl_sampler-125"><span class="linenos">125</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="create_rl_sampler-126"><a href="#create_rl_sampler-126"><span class="linenos">126</span></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>
</span><span id="create_rl_sampler-127"><a href="#create_rl_sampler-127"><span class="linenos">127</span></a>
</span><span id="create_rl_sampler-128"><a href="#create_rl_sampler-128"><span class="linenos">128</span></a>    <span class="c1"># use sampler for better ckpt resume</span>
</span><span id="create_rl_sampler-129"><a href="#create_rl_sampler-129"><span class="linenos">129</span></a>    <span class="k">if</span> <span class="n">data_config</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
</span><span id="create_rl_sampler-130"><a href="#create_rl_sampler-130"><span class="linenos">130</span></a>        <span class="n">train_dataloader_generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
</span><span id="create_rl_sampler-131"><a href="#create_rl_sampler-131"><span class="linenos">131</span></a>        <span class="n">train_dataloader_generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">data_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="create_rl_sampler-132"><a href="#create_rl_sampler-132"><span class="linenos">132</span></a>        <span class="n">sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">train_dataloader_generator</span><span class="p">)</span>
</span><span id="create_rl_sampler-133"><a href="#create_rl_sampler-133"><span class="linenos">133</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="create_rl_sampler-134"><a href="#create_rl_sampler-134"><span class="linenos">134</span></a>        <span class="n">sampler</span> <span class="o">=</span> <span class="n">SequentialSampler</span><span class="p">(</span><span class="n">data_source</span><span class="o">=</span><span class="n">dataset</span><span class="p">)</span>
</span><span id="create_rl_sampler-135"><a href="#create_rl_sampler-135"><span class="linenos">135</span></a>
</span><span id="create_rl_sampler-136"><a href="#create_rl_sampler-136"><span class="linenos">136</span></a>    <span class="k">return</span> <span class="n">sampler</span>
</span></pre></div>


            <div class="docstring"><p>Create a sampler for the dataset.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>data_config:</strong>  The data config.</li>
<li><strong>dataset (Dataset):</strong>  The dataset.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>sampler (Sampler): The sampler.</p>
</blockquote>
</div>


                </section>
                <section id="union_gen_batch_via_task_id">
                            <input id="union_gen_batch_via_task_id-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">union_gen_batch_via_task_id</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">tasks</span>,</span><span class="param">	<span class="n">batch</span><span class="p">:</span> <span class="n">verl</span><span class="o">.</span><span class="n">protocol</span><span class="o">.</span><span class="n">DataProto</span>,</span><span class="param">	<span class="n">gen_batch_output</span><span class="p">:</span> <span class="n">verl</span><span class="o">.</span><span class="n">protocol</span><span class="o">.</span><span class="n">DataProto</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="union_gen_batch_via_task_id-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#union_gen_batch_via_task_id"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="union_gen_batch_via_task_id-138"><a href="#union_gen_batch_via_task_id-138"><span class="linenos">138</span></a><span class="k">def</span><span class="w"> </span><span class="nf">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">gen_batch_output</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">):</span>
</span><span id="union_gen_batch_via_task_id-139"><a href="#union_gen_batch_via_task_id-139"><span class="linenos">139</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="union_gen_batch_via_task_id-140"><a href="#union_gen_batch_via_task_id-140"><span class="linenos">140</span></a><span class="sd">    Merges the `gen_batch_output` with the `batch` based on the `task_id`.</span>
</span><span id="union_gen_batch_via_task_id-141"><a href="#union_gen_batch_via_task_id-141"><span class="linenos">141</span></a>
</span><span id="union_gen_batch_via_task_id-142"><a href="#union_gen_batch_via_task_id-142"><span class="linenos">142</span></a><span class="sd">    Args:</span>
</span><span id="union_gen_batch_via_task_id-143"><a href="#union_gen_batch_via_task_id-143"><span class="linenos">143</span></a><span class="sd">        tasks (list): A list of task objects, each containing a `task_id`.</span>
</span><span id="union_gen_batch_via_task_id-144"><a href="#union_gen_batch_via_task_id-144"><span class="linenos">144</span></a><span class="sd">        batch (DataProto): The original batch of data.</span>
</span><span id="union_gen_batch_via_task_id-145"><a href="#union_gen_batch_via_task_id-145"><span class="linenos">145</span></a><span class="sd">        gen_batch_output (DataProto): The generated batch output that needs to be merged.</span>
</span><span id="union_gen_batch_via_task_id-146"><a href="#union_gen_batch_via_task_id-146"><span class="linenos">146</span></a>
</span><span id="union_gen_batch_via_task_id-147"><a href="#union_gen_batch_via_task_id-147"><span class="linenos">147</span></a><span class="sd">    Returns:</span>
</span><span id="union_gen_batch_via_task_id-148"><a href="#union_gen_batch_via_task_id-148"><span class="linenos">148</span></a><span class="sd">        DataProto: The final merged batch.</span>
</span><span id="union_gen_batch_via_task_id-149"><a href="#union_gen_batch_via_task_id-149"><span class="linenos">149</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="union_gen_batch_via_task_id-150"><a href="#union_gen_batch_via_task_id-150"><span class="linenos">150</span></a>    <span class="n">map_task_id_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="o">.</span><span class="n">task_id</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="p">)}</span>  <span class="c1"># ‚≠ê Create a mapping from task_id to its index in tasks</span>
</span><span id="union_gen_batch_via_task_id-151"><a href="#union_gen_batch_via_task_id-151"><span class="linenos">151</span></a>    <span class="n">gen_task_task_ids</span> <span class="o">=</span> <span class="n">gen_batch_output</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;task_ids&#39;</span><span class="p">]</span>
</span><span id="union_gen_batch_via_task_id-152"><a href="#union_gen_batch_via_task_id-152"><span class="linenos">152</span></a>    <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">map_task_id_to_index</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="k">for</span> <span class="n">tid</span> <span class="ow">in</span> <span class="n">gen_task_task_ids</span><span class="p">]</span>
</span><span id="union_gen_batch_via_task_id-153"><a href="#union_gen_batch_via_task_id-153"><span class="linenos">153</span></a>    <span class="n">batch_extend</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">select_idxs</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
</span><span id="union_gen_batch_via_task_id-154"><a href="#union_gen_batch_via_task_id-154"><span class="linenos">154</span></a>    <span class="n">batch_final</span> <span class="o">=</span> <span class="n">batch_extend</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_batch_output</span><span class="p">)</span>  <span class="c1"># ‚≠ê Merge the selected part of the batch with the gen_batch_output</span>
</span><span id="union_gen_batch_via_task_id-155"><a href="#union_gen_batch_via_task_id-155"><span class="linenos">155</span></a>    <span class="k">return</span> <span class="n">batch_final</span>
</span></pre></div>


            <div class="docstring"><p>Merges the <code>gen_batch_output</code> with the <code>batch</code> based on the <code>task_id</code>.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>tasks (list):</strong>  A list of task objects, each containing a <code>task_id</code>.</li>
<li><strong>batch (DataProto):</strong>  The original batch of data.</li>
<li><strong>gen_batch_output (DataProto):</strong>  The generated batch output that needs to be merged.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>DataProto: The final merged batch.</p>
</blockquote>
</div>


                </section>
                <section id="compute_grpo_outcome_advantage">
                            <input id="compute_grpo_outcome_advantage-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_grpo_outcome_advantage</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">token_level_rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">response_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">index</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-06</span>,</span><span class="param">	<span class="n">norm_adv_by_std_in_grpo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="compute_grpo_outcome_advantage-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#compute_grpo_outcome_advantage"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="compute_grpo_outcome_advantage-158"><a href="#compute_grpo_outcome_advantage-158"><span class="linenos">158</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_grpo_outcome_advantage</span><span class="p">(</span>
</span><span id="compute_grpo_outcome_advantage-159"><a href="#compute_grpo_outcome_advantage-159"><span class="linenos">159</span></a>    <span class="n">token_level_rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="compute_grpo_outcome_advantage-160"><a href="#compute_grpo_outcome_advantage-160"><span class="linenos">160</span></a>    <span class="n">response_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="compute_grpo_outcome_advantage-161"><a href="#compute_grpo_outcome_advantage-161"><span class="linenos">161</span></a>    <span class="n">index</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
</span><span id="compute_grpo_outcome_advantage-162"><a href="#compute_grpo_outcome_advantage-162"><span class="linenos">162</span></a>    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span id="compute_grpo_outcome_advantage-163"><a href="#compute_grpo_outcome_advantage-163"><span class="linenos">163</span></a>    <span class="n">norm_adv_by_std_in_grpo</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="compute_grpo_outcome_advantage-164"><a href="#compute_grpo_outcome_advantage-164"><span class="linenos">164</span></a><span class="p">):</span>
</span><span id="compute_grpo_outcome_advantage-165"><a href="#compute_grpo_outcome_advantage-165"><span class="linenos">165</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="compute_grpo_outcome_advantage-166"><a href="#compute_grpo_outcome_advantage-166"><span class="linenos">166</span></a><span class="sd">    Compute advantage for GRPO, operating only on Outcome reward</span>
</span><span id="compute_grpo_outcome_advantage-167"><a href="#compute_grpo_outcome_advantage-167"><span class="linenos">167</span></a><span class="sd">    (with only one scalar reward for each response).</span>
</span><span id="compute_grpo_outcome_advantage-168"><a href="#compute_grpo_outcome_advantage-168"><span class="linenos">168</span></a>
</span><span id="compute_grpo_outcome_advantage-169"><a href="#compute_grpo_outcome_advantage-169"><span class="linenos">169</span></a><span class="sd">    Args:</span>
</span><span id="compute_grpo_outcome_advantage-170"><a href="#compute_grpo_outcome_advantage-170"><span class="linenos">170</span></a><span class="sd">        token_level_rewards: `(torch.Tensor)`</span>
</span><span id="compute_grpo_outcome_advantage-171"><a href="#compute_grpo_outcome_advantage-171"><span class="linenos">171</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="compute_grpo_outcome_advantage-172"><a href="#compute_grpo_outcome_advantage-172"><span class="linenos">172</span></a><span class="sd">        response_mask: `(torch.Tensor)`</span>
</span><span id="compute_grpo_outcome_advantage-173"><a href="#compute_grpo_outcome_advantage-173"><span class="linenos">173</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="compute_grpo_outcome_advantage-174"><a href="#compute_grpo_outcome_advantage-174"><span class="linenos">174</span></a><span class="sd">        norm_adv_by_std_in_grpo: (bool)</span>
</span><span id="compute_grpo_outcome_advantage-175"><a href="#compute_grpo_outcome_advantage-175"><span class="linenos">175</span></a><span class="sd">            whether to scale the GRPO advantage.</span>
</span><span id="compute_grpo_outcome_advantage-176"><a href="#compute_grpo_outcome_advantage-176"><span class="linenos">176</span></a><span class="sd">            If True, the advantage is scaled by the std, as in the original GRPO.</span>
</span><span id="compute_grpo_outcome_advantage-177"><a href="#compute_grpo_outcome_advantage-177"><span class="linenos">177</span></a><span class="sd">            If False, the advantage is not scaled, as in Dr.GRPO (https://arxiv.org/abs/2503.20783).</span>
</span><span id="compute_grpo_outcome_advantage-178"><a href="#compute_grpo_outcome_advantage-178"><span class="linenos">178</span></a>
</span><span id="compute_grpo_outcome_advantage-179"><a href="#compute_grpo_outcome_advantage-179"><span class="linenos">179</span></a><span class="sd">    Returns:</span>
</span><span id="compute_grpo_outcome_advantage-180"><a href="#compute_grpo_outcome_advantage-180"><span class="linenos">180</span></a><span class="sd">        advantages: `(torch.Tensor)`</span>
</span><span id="compute_grpo_outcome_advantage-181"><a href="#compute_grpo_outcome_advantage-181"><span class="linenos">181</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="compute_grpo_outcome_advantage-182"><a href="#compute_grpo_outcome_advantage-182"><span class="linenos">182</span></a><span class="sd">        Returns: `(torch.Tensor)`</span>
</span><span id="compute_grpo_outcome_advantage-183"><a href="#compute_grpo_outcome_advantage-183"><span class="linenos">183</span></a><span class="sd">            shape is (bs, response_length)</span>
</span><span id="compute_grpo_outcome_advantage-184"><a href="#compute_grpo_outcome_advantage-184"><span class="linenos">184</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="compute_grpo_outcome_advantage-185"><a href="#compute_grpo_outcome_advantage-185"><span class="linenos">185</span></a>    <span class="n">scores</span> <span class="o">=</span> <span class="n">token_level_rewards</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-186"><a href="#compute_grpo_outcome_advantage-186"><span class="linenos">186</span></a>
</span><span id="compute_grpo_outcome_advantage-187"><a href="#compute_grpo_outcome_advantage-187"><span class="linenos">187</span></a>    <span class="n">id2score</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-188"><a href="#compute_grpo_outcome_advantage-188"><span class="linenos">188</span></a>    <span class="n">id2mean</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="compute_grpo_outcome_advantage-189"><a href="#compute_grpo_outcome_advantage-189"><span class="linenos">189</span></a>    <span class="n">id2std</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="compute_grpo_outcome_advantage-190"><a href="#compute_grpo_outcome_advantage-190"><span class="linenos">190</span></a>
</span><span id="compute_grpo_outcome_advantage-191"><a href="#compute_grpo_outcome_advantage-191"><span class="linenos">191</span></a>    <span class="k">if</span> <span class="n">scores</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">!=</span><span class="mi">1</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-192"><a href="#compute_grpo_outcome_advantage-192"><span class="linenos">192</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;scores.dim()!=1&quot;</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-193"><a href="#compute_grpo_outcome_advantage-193"><span class="linenos">193</span></a>
</span><span id="compute_grpo_outcome_advantage-194"><a href="#compute_grpo_outcome_advantage-194"><span class="linenos">194</span></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="compute_grpo_outcome_advantage-195"><a href="#compute_grpo_outcome_advantage-195"><span class="linenos">195</span></a>        <span class="n">bsz</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="compute_grpo_outcome_advantage-196"><a href="#compute_grpo_outcome_advantage-196"><span class="linenos">196</span></a>        
</span><span id="compute_grpo_outcome_advantage-197"><a href="#compute_grpo_outcome_advantage-197"><span class="linenos">197</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bsz</span><span class="p">):</span>
</span><span id="compute_grpo_outcome_advantage-198"><a href="#compute_grpo_outcome_advantage-198"><span class="linenos">198</span></a>            <span class="n">id2score</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="compute_grpo_outcome_advantage-199"><a href="#compute_grpo_outcome_advantage-199"><span class="linenos">199</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">id2score</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-200"><a href="#compute_grpo_outcome_advantage-200"><span class="linenos">200</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-201"><a href="#compute_grpo_outcome_advantage-201"><span class="linenos">201</span></a>                <span class="n">id2mean</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-202"><a href="#compute_grpo_outcome_advantage-202"><span class="linenos">202</span></a>                <span class="n">id2std</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-203"><a href="#compute_grpo_outcome_advantage-203"><span class="linenos">203</span></a>            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-204"><a href="#compute_grpo_outcome_advantage-204"><span class="linenos">204</span></a>                <span class="n">id2mean</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
</span><span id="compute_grpo_outcome_advantage-205"><a href="#compute_grpo_outcome_advantage-205"><span class="linenos">205</span></a>                <span class="n">id2std</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">id2score</span><span class="p">[</span><span class="n">idx</span><span class="p">]]))</span>
</span><span id="compute_grpo_outcome_advantage-206"><a href="#compute_grpo_outcome_advantage-206"><span class="linenos">206</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-207"><a href="#compute_grpo_outcome_advantage-207"><span class="linenos">207</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;no score in prompt index: </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-208"><a href="#compute_grpo_outcome_advantage-208"><span class="linenos">208</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bsz</span><span class="p">):</span>
</span><span id="compute_grpo_outcome_advantage-209"><a href="#compute_grpo_outcome_advantage-209"><span class="linenos">209</span></a>            <span class="k">if</span> <span class="n">norm_adv_by_std_in_grpo</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-210"><a href="#compute_grpo_outcome_advantage-210"><span class="linenos">210</span></a>                <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">id2mean</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span> <span class="o">/</span> <span class="p">(</span><span class="n">id2std</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
</span><span id="compute_grpo_outcome_advantage-211"><a href="#compute_grpo_outcome_advantage-211"><span class="linenos">211</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="compute_grpo_outcome_advantage-212"><a href="#compute_grpo_outcome_advantage-212"><span class="linenos">212</span></a>                <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">id2mean</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
</span><span id="compute_grpo_outcome_advantage-213"><a href="#compute_grpo_outcome_advantage-213"><span class="linenos">213</span></a>                <span class="c1"># no std</span>
</span><span id="compute_grpo_outcome_advantage-214"><a href="#compute_grpo_outcome_advantage-214"><span class="linenos">214</span></a>                <span class="c1"># if llm judge output similar rewards for undistinguishable samples, we may want to reduce its weight according to the batch std</span>
</span><span id="compute_grpo_outcome_advantage-215"><a href="#compute_grpo_outcome_advantage-215"><span class="linenos">215</span></a>                <span class="c1"># scores[i] = scores[i] / (batch_std + epsilon)</span>
</span><span id="compute_grpo_outcome_advantage-216"><a href="#compute_grpo_outcome_advantage-216"><span class="linenos">216</span></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">response_mask</span>
</span><span id="compute_grpo_outcome_advantage-217"><a href="#compute_grpo_outcome_advantage-217"><span class="linenos">217</span></a>
</span><span id="compute_grpo_outcome_advantage-218"><a href="#compute_grpo_outcome_advantage-218"><span class="linenos">218</span></a>    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">scores</span>
</span></pre></div>


            <div class="docstring"><p>Compute advantage for GRPO, operating only on Outcome reward
(with only one scalar reward for each response).</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>token_level_rewards:</strong>  <code>(torch.Tensor)</code>
shape is (bs, response_length)</li>
<li><strong>response_mask:</strong>  <code>(torch.Tensor)</code>
shape is (bs, response_length)</li>
<li><strong>norm_adv_by_std_in_grpo:</strong>  (bool)
whether to scale the GRPO advantage.
If True, the advantage is scaled by the std, as in the original GRPO.
If False, the advantage is not scaled, as in Dr.GRPO (https://arxiv.org/abs/2503.20783).</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>advantages: <code>(torch.Tensor)</code>
      shape is (bs, response_length)
  Returns: <code>(torch.Tensor)</code>
      shape is (bs, response_length)</p>
</blockquote>
</div>


                </section>
                <section id="compute_advantage">
                            <input id="compute_advantage-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_advantage</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">data</span><span class="p">:</span> <span class="n">verl</span><span class="o">.</span><span class="n">protocol</span><span class="o">.</span><span class="n">DataProto</span>,</span><span class="param">	<span class="n">adv_estimator</span>,</span><span class="param">	<span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span>,</span><span class="param">	<span class="n">lam</span><span class="o">=</span><span class="mf">1.0</span>,</span><span class="param">	<span class="n">num_repeat</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="n">multi_turn</span><span class="o">=</span><span class="kc">False</span>,</span><span class="param">	<span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="kc">True</span>,</span><span class="param">	<span class="n">config</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="compute_advantage-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#compute_advantage"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="compute_advantage-222"><a href="#compute_advantage-222"><span class="linenos">222</span></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_advantage</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">DataProto</span><span class="p">,</span> <span class="n">adv_estimator</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">multi_turn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="compute_advantage-223"><a href="#compute_advantage-223"><span class="linenos">223</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="compute_advantage-224"><a href="#compute_advantage-224"><span class="linenos">224</span></a><span class="sd">    Compute advantage estimates for policy optimization.</span>
</span><span id="compute_advantage-225"><a href="#compute_advantage-225"><span class="linenos">225</span></a>
</span><span id="compute_advantage-226"><a href="#compute_advantage-226"><span class="linenos">226</span></a><span class="sd">    This function computes advantage estimates using various estimators like GAE, GRPO, REINFORCE++, etc.</span>
</span><span id="compute_advantage-227"><a href="#compute_advantage-227"><span class="linenos">227</span></a><span class="sd">    The advantage estimates are used to guide policy optimization in RL algorithms.</span>
</span><span id="compute_advantage-228"><a href="#compute_advantage-228"><span class="linenos">228</span></a>
</span><span id="compute_advantage-229"><a href="#compute_advantage-229"><span class="linenos">229</span></a><span class="sd">    Args:</span>
</span><span id="compute_advantage-230"><a href="#compute_advantage-230"><span class="linenos">230</span></a><span class="sd">        data (DataProto): The data containing batched model outputs and inputs.</span>
</span><span id="compute_advantage-231"><a href="#compute_advantage-231"><span class="linenos">231</span></a><span class="sd">        adv_estimator: The advantage estimator to use (e.g., GAE, GRPO, REINFORCE++).</span>
</span><span id="compute_advantage-232"><a href="#compute_advantage-232"><span class="linenos">232</span></a><span class="sd">        gamma (float, optional): Discount factor for future rewards. Defaults to 1.0.</span>
</span><span id="compute_advantage-233"><a href="#compute_advantage-233"><span class="linenos">233</span></a><span class="sd">        lam (float, optional): Lambda parameter for GAE. Defaults to 1.0.</span>
</span><span id="compute_advantage-234"><a href="#compute_advantage-234"><span class="linenos">234</span></a><span class="sd">        num_repeat (int, optional): Number of times to repeat the computation. Defaults to 1.</span>
</span><span id="compute_advantage-235"><a href="#compute_advantage-235"><span class="linenos">235</span></a><span class="sd">        multi_turn (bool, optional): Whether the data is from a multi-turn conversation. Defaults to False.</span>
</span><span id="compute_advantage-236"><a href="#compute_advantage-236"><span class="linenos">236</span></a><span class="sd">        norm_adv_by_std_in_grpo (bool, optional): Whether to normalize advantages by standard deviation in GRPO. Defaults to True.</span>
</span><span id="compute_advantage-237"><a href="#compute_advantage-237"><span class="linenos">237</span></a><span class="sd">        config (dict, optional): Configuration dictionary for algorithm settings. Defaults to None.</span>
</span><span id="compute_advantage-238"><a href="#compute_advantage-238"><span class="linenos">238</span></a>
</span><span id="compute_advantage-239"><a href="#compute_advantage-239"><span class="linenos">239</span></a><span class="sd">    Returns:</span>
</span><span id="compute_advantage-240"><a href="#compute_advantage-240"><span class="linenos">240</span></a><span class="sd">        DataProto: The updated data with computed advantages and returns.</span>
</span><span id="compute_advantage-241"><a href="#compute_advantage-241"><span class="linenos">241</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="compute_advantage-242"><a href="#compute_advantage-242"><span class="linenos">242</span></a>    <span class="c1"># Back-compatible with trainers that do not compute response mask in fit</span>
</span><span id="compute_advantage-243"><a href="#compute_advantage-243"><span class="linenos">243</span></a>    <span class="k">if</span> <span class="s2">&quot;response_mask&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="compute_advantage-244"><a href="#compute_advantage-244"><span class="linenos">244</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span id="compute_advantage-245"><a href="#compute_advantage-245"><span class="linenos">245</span></a>    <span class="c1"># prepare response group</span>
</span><span id="compute_advantage-246"><a href="#compute_advantage-246"><span class="linenos">246</span></a>    <span class="k">if</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
</span><span id="compute_advantage-247"><a href="#compute_advantage-247"><span class="linenos">247</span></a>        <span class="c1"># Compute advantages and returns using Generalized Advantage Estimation (GAE)</span>
</span><span id="compute_advantage-248"><a href="#compute_advantage-248"><span class="linenos">248</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_gae_advantage_return</span><span class="p">(</span>
</span><span id="compute_advantage-249"><a href="#compute_advantage-249"><span class="linenos">249</span></a>            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-250"><a href="#compute_advantage-250"><span class="linenos">250</span></a>            <span class="n">values</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-251"><a href="#compute_advantage-251"><span class="linenos">251</span></a>            <span class="n">response_mask</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-252"><a href="#compute_advantage-252"><span class="linenos">252</span></a>            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="compute_advantage-253"><a href="#compute_advantage-253"><span class="linenos">253</span></a>            <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
</span><span id="compute_advantage-254"><a href="#compute_advantage-254"><span class="linenos">254</span></a>        <span class="p">)</span>
</span><span id="compute_advantage-255"><a href="#compute_advantage-255"><span class="linenos">255</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="compute_advantage-256"><a href="#compute_advantage-256"><span class="linenos">256</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="compute_advantage-257"><a href="#compute_advantage-257"><span class="linenos">257</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_pf_ppo&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="compute_advantage-258"><a href="#compute_advantage-258"><span class="linenos">258</span></a>            <span class="n">data</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">compute_pf_ppo_reweight_data</span><span class="p">(</span>
</span><span id="compute_advantage-259"><a href="#compute_advantage-259"><span class="linenos">259</span></a>                <span class="n">data</span><span class="p">,</span>
</span><span id="compute_advantage-260"><a href="#compute_advantage-260"><span class="linenos">260</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pf_ppo_reweight_method&quot;</span><span class="p">,</span> <span class="s2">&quot;pow&quot;</span><span class="p">),</span>
</span><span id="compute_advantage-261"><a href="#compute_advantage-261"><span class="linenos">261</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pf_ppo_weight_pow&quot;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
</span><span id="compute_advantage-262"><a href="#compute_advantage-262"><span class="linenos">262</span></a>            <span class="p">)</span>
</span><span id="compute_advantage-263"><a href="#compute_advantage-263"><span class="linenos">263</span></a>    <span class="k">elif</span> <span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">:</span>
</span><span id="compute_advantage-264"><a href="#compute_advantage-264"><span class="linenos">264</span></a>        <span class="c1"># Initialize the mask for GRPO calculation</span>
</span><span id="compute_advantage-265"><a href="#compute_advantage-265"><span class="linenos">265</span></a>        <span class="n">grpo_calculation_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
</span><span id="compute_advantage-266"><a href="#compute_advantage-266"><span class="linenos">266</span></a>        <span class="k">if</span> <span class="n">multi_turn</span><span class="p">:</span>
</span><span id="compute_advantage-267"><a href="#compute_advantage-267"><span class="linenos">267</span></a>            <span class="c1"># If multi-turn, replace the mask with the relevant part of loss_mask</span>
</span><span id="compute_advantage-268"><a href="#compute_advantage-268"><span class="linenos">268</span></a>            <span class="c1"># Get length from the initial response mask</span>
</span><span id="compute_advantage-269"><a href="#compute_advantage-269"><span class="linenos">269</span></a>            <span class="n">response_length</span> <span class="o">=</span> <span class="n">grpo_calculation_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="compute_advantage-270"><a href="#compute_advantage-270"><span class="linenos">270</span></a>            <span class="c1"># This mask is the one intended for GRPO</span>
</span><span id="compute_advantage-271"><a href="#compute_advantage-271"><span class="linenos">271</span></a>            <span class="n">grpo_calculation_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;loss_mask&quot;</span><span class="p">][:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
</span><span id="compute_advantage-272"><a href="#compute_advantage-272"><span class="linenos">272</span></a>        <span class="c1"># Call compute_grpo_outcome_advantage with parameters matching its definition</span>
</span><span id="compute_advantage-273"><a href="#compute_advantage-273"><span class="linenos">273</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">compute_grpo_outcome_advantage</span><span class="p">(</span>
</span><span id="compute_advantage-274"><a href="#compute_advantage-274"><span class="linenos">274</span></a>            <span class="n">token_level_rewards</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-275"><a href="#compute_advantage-275"><span class="linenos">275</span></a>            <span class="n">response_mask</span><span class="o">=</span><span class="n">grpo_calculation_mask</span><span class="p">,</span>
</span><span id="compute_advantage-276"><a href="#compute_advantage-276"><span class="linenos">276</span></a>            <span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-277"><a href="#compute_advantage-277"><span class="linenos">277</span></a>            <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="n">norm_adv_by_std_in_grpo</span><span class="p">,</span>
</span><span id="compute_advantage-278"><a href="#compute_advantage-278"><span class="linenos">278</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Compute advantages and returns for GRPO</span>
</span><span id="compute_advantage-279"><a href="#compute_advantage-279"><span class="linenos">279</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="compute_advantage-280"><a href="#compute_advantage-280"><span class="linenos">280</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="compute_advantage-281"><a href="#compute_advantage-281"><span class="linenos">281</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="compute_advantage-282"><a href="#compute_advantage-282"><span class="linenos">282</span></a>        <span class="c1"># handle all other adv estimator type other than GAE and GRPO</span>
</span><span id="compute_advantage-283"><a href="#compute_advantage-283"><span class="linenos">283</span></a>        <span class="n">adv_estimator_fn</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_adv_estimator_fn</span><span class="p">(</span><span class="n">adv_estimator</span><span class="p">)</span>
</span><span id="compute_advantage-284"><a href="#compute_advantage-284"><span class="linenos">284</span></a>        <span class="n">adv_kwargs</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="compute_advantage-285"><a href="#compute_advantage-285"><span class="linenos">285</span></a>            <span class="s2">&quot;token_level_rewards&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-286"><a href="#compute_advantage-286"><span class="linenos">286</span></a>            <span class="s2">&quot;response_mask&quot;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">],</span>
</span><span id="compute_advantage-287"><a href="#compute_advantage-287"><span class="linenos">287</span></a>            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
</span><span id="compute_advantage-288"><a href="#compute_advantage-288"><span class="linenos">288</span></a>        <span class="p">}</span>
</span><span id="compute_advantage-289"><a href="#compute_advantage-289"><span class="linenos">289</span></a>        <span class="k">if</span> <span class="s2">&quot;uid&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>  <span class="c1"># optional</span>
</span><span id="compute_advantage-290"><a href="#compute_advantage-290"><span class="linenos">290</span></a>            <span class="n">adv_kwargs</span><span class="p">[</span><span class="s2">&quot;index&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span>
</span><span id="compute_advantage-291"><a href="#compute_advantage-291"><span class="linenos">291</span></a>        <span class="k">if</span> <span class="s2">&quot;reward_baselines&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">:</span>  <span class="c1"># optional</span>
</span><span id="compute_advantage-292"><a href="#compute_advantage-292"><span class="linenos">292</span></a>            <span class="n">adv_kwargs</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span>
</span><span id="compute_advantage-293"><a href="#compute_advantage-293"><span class="linenos">293</span></a>
</span><span id="compute_advantage-294"><a href="#compute_advantage-294"><span class="linenos">294</span></a>        <span class="c1"># calculate advantage estimator</span>
</span><span id="compute_advantage-295"><a href="#compute_advantage-295"><span class="linenos">295</span></a>        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="n">adv_estimator_fn</span><span class="p">(</span><span class="o">**</span><span class="n">adv_kwargs</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute advantages and returns for other estimators</span>
</span><span id="compute_advantage-296"><a href="#compute_advantage-296"><span class="linenos">296</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">advantages</span>
</span><span id="compute_advantage-297"><a href="#compute_advantage-297"><span class="linenos">297</span></a>        <span class="n">data</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">returns</span>
</span><span id="compute_advantage-298"><a href="#compute_advantage-298"><span class="linenos">298</span></a>    <span class="k">return</span> <span class="n">data</span>
</span></pre></div>


            <div class="docstring"><p>Compute advantage estimates for policy optimization.</p>

<p>This function computes advantage estimates using various estimators like GAE, GRPO, REINFORCE++, etc.
The advantage estimates are used to guide policy optimization in RL algorithms.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>data (DataProto):</strong>  The data containing batched model outputs and inputs.</li>
<li><strong>adv_estimator:</strong>  The advantage estimator to use (e.g., GAE, GRPO, REINFORCE++).</li>
<li><strong>gamma (float, optional):</strong>  Discount factor for future rewards. Defaults to 1.0.</li>
<li><strong>lam (float, optional):</strong>  Lambda parameter for GAE. Defaults to 1.0.</li>
<li><strong>num_repeat (int, optional):</strong>  Number of times to repeat the computation. Defaults to 1.</li>
<li><strong>multi_turn (bool, optional):</strong>  Whether the data is from a multi-turn conversation. Defaults to False.</li>
<li><strong>norm_adv_by_std_in_grpo (bool, optional):</strong>  Whether to normalize advantages by standard deviation in GRPO. Defaults to True.</li>
<li><strong>config (dict, optional):</strong>  Configuration dictionary for algorithm settings. Defaults to None.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>DataProto: The updated data with computed advantages and returns.</p>
</blockquote>
</div>


                </section>
                <section id="AgentEvolverRayPPOTrainer">
                            <input id="AgentEvolverRayPPOTrainer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AgentEvolverRayPPOTrainer</span><wbr>(<span class="base">verl.trainer.ppo.ray_trainer.RayPPOTrainer</span>):

                <label class="view-source-button" for="AgentEvolverRayPPOTrainer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AgentEvolverRayPPOTrainer-301"><a href="#AgentEvolverRayPPOTrainer-301"><span class="linenos"> 301</span></a><span class="k">class</span><span class="w"> </span><span class="nc">AgentEvolverRayPPOTrainer</span><span class="p">(</span><span class="n">RayPPOTrainer</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-302"><a href="#AgentEvolverRayPPOTrainer-302"><span class="linenos"> 302</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-303"><a href="#AgentEvolverRayPPOTrainer-303"><span class="linenos"> 303</span></a><span class="sd">    Note that this trainer runs on the driver process on a single CPU/GPU node.</span>
</span><span id="AgentEvolverRayPPOTrainer-304"><a href="#AgentEvolverRayPPOTrainer-304"><span class="linenos"> 304</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-305"><a href="#AgentEvolverRayPPOTrainer-305"><span class="linenos"> 305</span></a>
</span><span id="AgentEvolverRayPPOTrainer-306"><a href="#AgentEvolverRayPPOTrainer-306"><span class="linenos"> 306</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-307"><a href="#AgentEvolverRayPPOTrainer-307"><span class="linenos"> 307</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-308"><a href="#AgentEvolverRayPPOTrainer-308"><span class="linenos"> 308</span></a>        <span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-309"><a href="#AgentEvolverRayPPOTrainer-309"><span class="linenos"> 309</span></a>        <span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-310"><a href="#AgentEvolverRayPPOTrainer-310"><span class="linenos"> 310</span></a>        <span class="n">role_worker_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Role</span><span class="p">,</span> <span class="n">WorkerType</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-311"><a href="#AgentEvolverRayPPOTrainer-311"><span class="linenos"> 311</span></a>        <span class="n">resource_pool_manager</span><span class="p">:</span> <span class="n">ResourcePoolManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-312"><a href="#AgentEvolverRayPPOTrainer-312"><span class="linenos"> 312</span></a>        <span class="n">train_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-313"><a href="#AgentEvolverRayPPOTrainer-313"><span class="linenos"> 313</span></a>        <span class="n">val_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-314"><a href="#AgentEvolverRayPPOTrainer-314"><span class="linenos"> 314</span></a>        <span class="n">ray_worker_group_cls</span><span class="p">:</span> <span class="n">RayWorkerGroup</span> <span class="o">=</span> <span class="n">RayWorkerGroup</span><span class="p">,</span> <span class="c1"># type: ignore</span>
</span><span id="AgentEvolverRayPPOTrainer-315"><a href="#AgentEvolverRayPPOTrainer-315"><span class="linenos"> 315</span></a>        <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-316"><a href="#AgentEvolverRayPPOTrainer-316"><span class="linenos"> 316</span></a>        <span class="n">reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-317"><a href="#AgentEvolverRayPPOTrainer-317"><span class="linenos"> 317</span></a>        <span class="n">val_reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-318"><a href="#AgentEvolverRayPPOTrainer-318"><span class="linenos"> 318</span></a>        <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-319"><a href="#AgentEvolverRayPPOTrainer-319"><span class="linenos"> 319</span></a>        <span class="n">shuffle_trainset</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-320"><a href="#AgentEvolverRayPPOTrainer-320"><span class="linenos"> 320</span></a>        <span class="n">device_name</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-321"><a href="#AgentEvolverRayPPOTrainer-321"><span class="linenos"> 321</span></a>    <span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-322"><a href="#AgentEvolverRayPPOTrainer-322"><span class="linenos"> 322</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-323"><a href="#AgentEvolverRayPPOTrainer-323"><span class="linenos"> 323</span></a><span class="sd">        Initialize distributed PPO trainer with Ray backend.</span>
</span><span id="AgentEvolverRayPPOTrainer-324"><a href="#AgentEvolverRayPPOTrainer-324"><span class="linenos"> 324</span></a>
</span><span id="AgentEvolverRayPPOTrainer-325"><a href="#AgentEvolverRayPPOTrainer-325"><span class="linenos"> 325</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer-326"><a href="#AgentEvolverRayPPOTrainer-326"><span class="linenos"> 326</span></a><span class="sd">            config: Configuration object containing various settings.</span>
</span><span id="AgentEvolverRayPPOTrainer-327"><a href="#AgentEvolverRayPPOTrainer-327"><span class="linenos"> 327</span></a><span class="sd">            tokenizer: Tokenizer used for processing text.</span>
</span><span id="AgentEvolverRayPPOTrainer-328"><a href="#AgentEvolverRayPPOTrainer-328"><span class="linenos"> 328</span></a><span class="sd">            role_worker_mapping (dict[Role, WorkerType]): Mapping of roles to worker types.</span>
</span><span id="AgentEvolverRayPPOTrainer-329"><a href="#AgentEvolverRayPPOTrainer-329"><span class="linenos"> 329</span></a><span class="sd">            resource_pool_manager (ResourcePoolManager): Manager for resource pools.</span>
</span><span id="AgentEvolverRayPPOTrainer-330"><a href="#AgentEvolverRayPPOTrainer-330"><span class="linenos"> 330</span></a><span class="sd">            train_task_manager (TaskManager): Task manager for training tasks.</span>
</span><span id="AgentEvolverRayPPOTrainer-331"><a href="#AgentEvolverRayPPOTrainer-331"><span class="linenos"> 331</span></a><span class="sd">            val_task_manager (TaskManager): Task manager for validation tasks.</span>
</span><span id="AgentEvolverRayPPOTrainer-332"><a href="#AgentEvolverRayPPOTrainer-332"><span class="linenos"> 332</span></a><span class="sd">            ray_worker_group_cls (RayWorkerGroup, optional): Class for Ray worker groups. Defaults to RayWorkerGroup.</span>
</span><span id="AgentEvolverRayPPOTrainer-333"><a href="#AgentEvolverRayPPOTrainer-333"><span class="linenos"> 333</span></a><span class="sd">            processor (optional): Processor for additional data processing.</span>
</span><span id="AgentEvolverRayPPOTrainer-334"><a href="#AgentEvolverRayPPOTrainer-334"><span class="linenos"> 334</span></a><span class="sd">            reward_fn (optional): Function to compute rewards.</span>
</span><span id="AgentEvolverRayPPOTrainer-335"><a href="#AgentEvolverRayPPOTrainer-335"><span class="linenos"> 335</span></a><span class="sd">            val_reward_fn (optional): Function to compute validation rewards.</span>
</span><span id="AgentEvolverRayPPOTrainer-336"><a href="#AgentEvolverRayPPOTrainer-336"><span class="linenos"> 336</span></a><span class="sd">            collate_fn (optional): Function to collate data.</span>
</span><span id="AgentEvolverRayPPOTrainer-337"><a href="#AgentEvolverRayPPOTrainer-337"><span class="linenos"> 337</span></a><span class="sd">            shuffle_trainset (bool, optional): Whether to shuffle the training dataset. Defaults to False.</span>
</span><span id="AgentEvolverRayPPOTrainer-338"><a href="#AgentEvolverRayPPOTrainer-338"><span class="linenos"> 338</span></a><span class="sd">            device_name (str, optional): Name of the device to use. Defaults to &quot;cuda&quot;.</span>
</span><span id="AgentEvolverRayPPOTrainer-339"><a href="#AgentEvolverRayPPOTrainer-339"><span class="linenos"> 339</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-340"><a href="#AgentEvolverRayPPOTrainer-340"><span class="linenos"> 340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="AgentEvolverRayPPOTrainer-341"><a href="#AgentEvolverRayPPOTrainer-341"><span class="linenos"> 341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>
</span><span id="AgentEvolverRayPPOTrainer-342"><a href="#AgentEvolverRayPPOTrainer-342"><span class="linenos"> 342</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="AgentEvolverRayPPOTrainer-343"><a href="#AgentEvolverRayPPOTrainer-343"><span class="linenos"> 343</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">reward_fn</span>
</span><span id="AgentEvolverRayPPOTrainer-344"><a href="#AgentEvolverRayPPOTrainer-344"><span class="linenos"> 344</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">val_reward_fn</span>
</span><span id="AgentEvolverRayPPOTrainer-345"><a href="#AgentEvolverRayPPOTrainer-345"><span class="linenos"> 345</span></a>
</span><span id="AgentEvolverRayPPOTrainer-346"><a href="#AgentEvolverRayPPOTrainer-346"><span class="linenos"> 346</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">hybrid_engine</span>
</span><span id="AgentEvolverRayPPOTrainer-347"><a href="#AgentEvolverRayPPOTrainer-347"><span class="linenos"> 347</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">,</span> <span class="s2">&quot;Currently, only support hybrid engine&quot;</span>  <span class="c1"># ‚≠ê Ensure the hybrid engine is supported</span>
</span><span id="AgentEvolverRayPPOTrainer-348"><a href="#AgentEvolverRayPPOTrainer-348"><span class="linenos"> 348</span></a>
</span><span id="AgentEvolverRayPPOTrainer-349"><a href="#AgentEvolverRayPPOTrainer-349"><span class="linenos"> 349</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-350"><a href="#AgentEvolverRayPPOTrainer-350"><span class="linenos"> 350</span></a>            <span class="k">assert</span> <span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">role_worker_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">=}</span><span class="s2">&quot;</span>  <span class="c1"># ‚≠ê Ensure ActorRollout role is present in the mapping</span>
</span><span id="AgentEvolverRayPPOTrainer-351"><a href="#AgentEvolverRayPPOTrainer-351"><span class="linenos"> 351</span></a>
</span><span id="AgentEvolverRayPPOTrainer-352"><a href="#AgentEvolverRayPPOTrainer-352"><span class="linenos"> 352</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span> <span class="o">=</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer-353"><a href="#AgentEvolverRayPPOTrainer-353"><span class="linenos"> 353</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span> <span class="o">=</span> <span class="n">resource_pool_manager</span>
</span><span id="AgentEvolverRayPPOTrainer-354"><a href="#AgentEvolverRayPPOTrainer-354"><span class="linenos"> 354</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer-355"><a href="#AgentEvolverRayPPOTrainer-355"><span class="linenos"> 355</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer-356"><a href="#AgentEvolverRayPPOTrainer-356"><span class="linenos"> 356</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span> <span class="o">=</span> <span class="n">ray_worker_group_cls</span>
</span><span id="AgentEvolverRayPPOTrainer-357"><a href="#AgentEvolverRayPPOTrainer-357"><span class="linenos"> 357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_name</span> <span class="o">=</span> <span class="n">device_name</span>
</span><span id="AgentEvolverRayPPOTrainer-358"><a href="#AgentEvolverRayPPOTrainer-358"><span class="linenos"> 358</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_generations_logger</span> <span class="o">=</span> <span class="n">ValidationGenerationsLogger</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-359"><a href="#AgentEvolverRayPPOTrainer-359"><span class="linenos"> 359</span></a>
</span><span id="AgentEvolverRayPPOTrainer-360"><a href="#AgentEvolverRayPPOTrainer-360"><span class="linenos"> 360</span></a>        <span class="c1"># if ref_in_actor is True, the reference policy will be actor without lora applied</span>
</span><span id="AgentEvolverRayPPOTrainer-361"><a href="#AgentEvolverRayPPOTrainer-361"><span class="linenos"> 361</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="AgentEvolverRayPPOTrainer-362"><a href="#AgentEvolverRayPPOTrainer-362"><span class="linenos"> 362</span></a>
</span><span id="AgentEvolverRayPPOTrainer-363"><a href="#AgentEvolverRayPPOTrainer-363"><span class="linenos"> 363</span></a>        <span class="c1"># define in-reward KL control</span>
</span><span id="AgentEvolverRayPPOTrainer-364"><a href="#AgentEvolverRayPPOTrainer-364"><span class="linenos"> 364</span></a>        <span class="c1"># kl loss control currently not suppoorted</span>
</span><span id="AgentEvolverRayPPOTrainer-365"><a href="#AgentEvolverRayPPOTrainer-365"><span class="linenos"> 365</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-366"><a href="#AgentEvolverRayPPOTrainer-366"><span class="linenos"> 366</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_kl_controller</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_ctrl</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-367"><a href="#AgentEvolverRayPPOTrainer-367"><span class="linenos"> 367</span></a>
</span><span id="AgentEvolverRayPPOTrainer-368"><a href="#AgentEvolverRayPPOTrainer-368"><span class="linenos"> 368</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-369"><a href="#AgentEvolverRayPPOTrainer-369"><span class="linenos"> 369</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="AgentEvolverRayPPOTrainer-370"><a href="#AgentEvolverRayPPOTrainer-370"><span class="linenos"> 370</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span>
</span><span id="AgentEvolverRayPPOTrainer-371"><a href="#AgentEvolverRayPPOTrainer-371"><span class="linenos"> 371</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-372"><a href="#AgentEvolverRayPPOTrainer-372"><span class="linenos"> 372</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO_PASSK</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-373"><a href="#AgentEvolverRayPPOTrainer-373"><span class="linenos"> 373</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-374"><a href="#AgentEvolverRayPPOTrainer-374"><span class="linenos"> 374</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-375"><a href="#AgentEvolverRayPPOTrainer-375"><span class="linenos"> 375</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">RLOO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-376"><a href="#AgentEvolverRayPPOTrainer-376"><span class="linenos"> 376</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">OPO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-377"><a href="#AgentEvolverRayPPOTrainer-377"><span class="linenos"> 377</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS_BASELINE</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-378"><a href="#AgentEvolverRayPPOTrainer-378"><span class="linenos"> 378</span></a>        <span class="p">]:</span>
</span><span id="AgentEvolverRayPPOTrainer-379"><a href="#AgentEvolverRayPPOTrainer-379"><span class="linenos"> 379</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer-380"><a href="#AgentEvolverRayPPOTrainer-380"><span class="linenos"> 380</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-381"><a href="#AgentEvolverRayPPOTrainer-381"><span class="linenos"> 381</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer-382"><a href="#AgentEvolverRayPPOTrainer-382"><span class="linenos"> 382</span></a>
</span><span id="AgentEvolverRayPPOTrainer-383"><a href="#AgentEvolverRayPPOTrainer-383"><span class="linenos"> 383</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_config</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-384"><a href="#AgentEvolverRayPPOTrainer-384"><span class="linenos"> 384</span></a>
</span><span id="AgentEvolverRayPPOTrainer-385"><a href="#AgentEvolverRayPPOTrainer-385"><span class="linenos"> 385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="p">:</span> <span class="n">ParallelEnvManager</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer-386"><a href="#AgentEvolverRayPPOTrainer-386"><span class="linenos"> 386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span><span class="p">:</span> <span class="n">ThreadPoolExecutor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer-387"><a href="#AgentEvolverRayPPOTrainer-387"><span class="linenos"> 387</span></a>
</span><span id="AgentEvolverRayPPOTrainer-388"><a href="#AgentEvolverRayPPOTrainer-388"><span class="linenos"> 388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">=</span><span class="n">train_task_manager</span>
</span><span id="AgentEvolverRayPPOTrainer-389"><a href="#AgentEvolverRayPPOTrainer-389"><span class="linenos"> 389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">=</span><span class="n">val_task_manager</span>
</span><span id="AgentEvolverRayPPOTrainer-390"><a href="#AgentEvolverRayPPOTrainer-390"><span class="linenos"> 390</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
</span><span id="AgentEvolverRayPPOTrainer-391"><a href="#AgentEvolverRayPPOTrainer-391"><span class="linenos"> 391</span></a>
</span><span id="AgentEvolverRayPPOTrainer-392"><a href="#AgentEvolverRayPPOTrainer-392"><span class="linenos"> 392</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_create_dataloader_from_manager</span><span class="p">(</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">shuffle_trainset</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create dataloader from the provided manager</span>
</span><span id="AgentEvolverRayPPOTrainer-393"><a href="#AgentEvolverRayPPOTrainer-393"><span class="linenos"> 393</span></a>
</span><span id="AgentEvolverRayPPOTrainer-394"><a href="#AgentEvolverRayPPOTrainer-394"><span class="linenos"> 394</span></a>
</span><span id="AgentEvolverRayPPOTrainer-395"><a href="#AgentEvolverRayPPOTrainer-395"><span class="linenos"> 395</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-396"><a href="#AgentEvolverRayPPOTrainer-396"><span class="linenos"> 396</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-397"><a href="#AgentEvolverRayPPOTrainer-397"><span class="linenos"> 397</span></a><span class="sd">        Initializes distributed training workers using the Ray backend.</span>
</span><span id="AgentEvolverRayPPOTrainer-398"><a href="#AgentEvolverRayPPOTrainer-398"><span class="linenos"> 398</span></a>
</span><span id="AgentEvolverRayPPOTrainer-399"><a href="#AgentEvolverRayPPOTrainer-399"><span class="linenos"> 399</span></a><span class="sd">        This function creates:</span>
</span><span id="AgentEvolverRayPPOTrainer-400"><a href="#AgentEvolverRayPPOTrainer-400"><span class="linenos"> 400</span></a><span class="sd">        1. Ray resource pools from configuration</span>
</span><span id="AgentEvolverRayPPOTrainer-401"><a href="#AgentEvolverRayPPOTrainer-401"><span class="linenos"> 401</span></a><span class="sd">        2. Worker groups for each role (actor, critic, etc.)</span>
</span><span id="AgentEvolverRayPPOTrainer-402"><a href="#AgentEvolverRayPPOTrainer-402"><span class="linenos"> 402</span></a>
</span><span id="AgentEvolverRayPPOTrainer-403"><a href="#AgentEvolverRayPPOTrainer-403"><span class="linenos"> 403</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer-404"><a href="#AgentEvolverRayPPOTrainer-404"><span class="linenos"> 404</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-405"><a href="#AgentEvolverRayPPOTrainer-405"><span class="linenos"> 405</span></a>
</span><span id="AgentEvolverRayPPOTrainer-406"><a href="#AgentEvolverRayPPOTrainer-406"><span class="linenos"> 406</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer-407"><a href="#AgentEvolverRayPPOTrainer-407"><span class="linenos"> 407</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-408"><a href="#AgentEvolverRayPPOTrainer-408"><span class="linenos"> 408</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-409"><a href="#AgentEvolverRayPPOTrainer-409"><span class="linenos"> 409</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">create_resource_pool</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the resource pools</span>
</span><span id="AgentEvolverRayPPOTrainer-410"><a href="#AgentEvolverRayPPOTrainer-410"><span class="linenos"> 410</span></a>
</span><span id="AgentEvolverRayPPOTrainer-411"><a href="#AgentEvolverRayPPOTrainer-411"><span class="linenos"> 411</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span> <span class="o">=</span> <span class="p">{</span><span class="n">pool</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">pool</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
</span><span id="AgentEvolverRayPPOTrainer-412"><a href="#AgentEvolverRayPPOTrainer-412"><span class="linenos"> 412</span></a>
</span><span id="AgentEvolverRayPPOTrainer-413"><a href="#AgentEvolverRayPPOTrainer-413"><span class="linenos"> 413</span></a>        <span class="c1"># create actor and rollout</span>
</span><span id="AgentEvolverRayPPOTrainer-414"><a href="#AgentEvolverRayPPOTrainer-414"><span class="linenos"> 414</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-415"><a href="#AgentEvolverRayPPOTrainer-415"><span class="linenos"> 415</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-416"><a href="#AgentEvolverRayPPOTrainer-416"><span class="linenos"> 416</span></a>            <span class="n">actor_rollout_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-417"><a href="#AgentEvolverRayPPOTrainer-417"><span class="linenos"> 417</span></a>                <span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-418"><a href="#AgentEvolverRayPPOTrainer-418"><span class="linenos"> 418</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-419"><a href="#AgentEvolverRayPPOTrainer-419"><span class="linenos"> 419</span></a>                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-420"><a href="#AgentEvolverRayPPOTrainer-420"><span class="linenos"> 420</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-421"><a href="#AgentEvolverRayPPOTrainer-421"><span class="linenos"> 421</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">actor_rollout_cls</span>
</span><span id="AgentEvolverRayPPOTrainer-422"><a href="#AgentEvolverRayPPOTrainer-422"><span class="linenos"> 422</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-423"><a href="#AgentEvolverRayPPOTrainer-423"><span class="linenos"> 423</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer-424"><a href="#AgentEvolverRayPPOTrainer-424"><span class="linenos"> 424</span></a>
</span><span id="AgentEvolverRayPPOTrainer-425"><a href="#AgentEvolverRayPPOTrainer-425"><span class="linenos"> 425</span></a>        <span class="c1"># create critic</span>
</span><span id="AgentEvolverRayPPOTrainer-426"><a href="#AgentEvolverRayPPOTrainer-426"><span class="linenos"> 426</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-427"><a href="#AgentEvolverRayPPOTrainer-427"><span class="linenos"> 427</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-428"><a href="#AgentEvolverRayPPOTrainer-428"><span class="linenos"> 428</span></a>            <span class="n">critic_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-429"><a href="#AgentEvolverRayPPOTrainer-429"><span class="linenos"> 429</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">critic_cls</span>
</span><span id="AgentEvolverRayPPOTrainer-430"><a href="#AgentEvolverRayPPOTrainer-430"><span class="linenos"> 430</span></a>
</span><span id="AgentEvolverRayPPOTrainer-431"><a href="#AgentEvolverRayPPOTrainer-431"><span class="linenos"> 431</span></a>        <span class="c1"># create reference policy if needed</span>
</span><span id="AgentEvolverRayPPOTrainer-432"><a href="#AgentEvolverRayPPOTrainer-432"><span class="linenos"> 432</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-433"><a href="#AgentEvolverRayPPOTrainer-433"><span class="linenos"> 433</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-434"><a href="#AgentEvolverRayPPOTrainer-434"><span class="linenos"> 434</span></a>            <span class="n">ref_policy_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-435"><a href="#AgentEvolverRayPPOTrainer-435"><span class="linenos"> 435</span></a>                                                  <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span> <span class="n">role</span><span class="o">=</span><span class="s2">&quot;ref&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-436"><a href="#AgentEvolverRayPPOTrainer-436"><span class="linenos"> 436</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_policy_cls</span>
</span><span id="AgentEvolverRayPPOTrainer-437"><a href="#AgentEvolverRayPPOTrainer-437"><span class="linenos"> 437</span></a>
</span><span id="AgentEvolverRayPPOTrainer-438"><a href="#AgentEvolverRayPPOTrainer-438"><span class="linenos"> 438</span></a>        <span class="c1"># create a reward model if reward_fn is None</span>
</span><span id="AgentEvolverRayPPOTrainer-439"><a href="#AgentEvolverRayPPOTrainer-439"><span class="linenos"> 439</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-440"><a href="#AgentEvolverRayPPOTrainer-440"><span class="linenos"> 440</span></a>            <span class="c1"># we create a RM here</span>
</span><span id="AgentEvolverRayPPOTrainer-441"><a href="#AgentEvolverRayPPOTrainer-441"><span class="linenos"> 441</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-442"><a href="#AgentEvolverRayPPOTrainer-442"><span class="linenos"> 442</span></a>            <span class="n">rm_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-443"><a href="#AgentEvolverRayPPOTrainer-443"><span class="linenos"> 443</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rm_cls</span>
</span><span id="AgentEvolverRayPPOTrainer-444"><a href="#AgentEvolverRayPPOTrainer-444"><span class="linenos"> 444</span></a>
</span><span id="AgentEvolverRayPPOTrainer-445"><a href="#AgentEvolverRayPPOTrainer-445"><span class="linenos"> 445</span></a>        <span class="c1"># initialize WorkerGroup</span>
</span><span id="AgentEvolverRayPPOTrainer-446"><a href="#AgentEvolverRayPPOTrainer-446"><span class="linenos"> 446</span></a>        <span class="c1"># NOTE: if you want to use a different resource pool for each role, which can support different parallel size,</span>
</span><span id="AgentEvolverRayPPOTrainer-447"><a href="#AgentEvolverRayPPOTrainer-447"><span class="linenos"> 447</span></a>        <span class="c1"># you should not use `create_colocated_worker_cls`.</span>
</span><span id="AgentEvolverRayPPOTrainer-448"><a href="#AgentEvolverRayPPOTrainer-448"><span class="linenos"> 448</span></a>        <span class="c1"># Instead, directly pass different resource pool to different worker groups.</span>
</span><span id="AgentEvolverRayPPOTrainer-449"><a href="#AgentEvolverRayPPOTrainer-449"><span class="linenos"> 449</span></a>        <span class="c1"># See https://github.com/volcengine/verl/blob/master/examples/ray/tutorial.ipynb for more information.</span>
</span><span id="AgentEvolverRayPPOTrainer-450"><a href="#AgentEvolverRayPPOTrainer-450"><span class="linenos"> 450</span></a>        <span class="n">all_wg</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-451"><a href="#AgentEvolverRayPPOTrainer-451"><span class="linenos"> 451</span></a>        <span class="n">wg_kwargs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Setting up kwargs for RayWorkerGroup</span>
</span><span id="AgentEvolverRayPPOTrainer-452"><a href="#AgentEvolverRayPPOTrainer-452"><span class="linenos"> 452</span></a>        <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-453"><a href="#AgentEvolverRayPPOTrainer-453"><span class="linenos"> 453</span></a>            <span class="n">wg_kwargs</span><span class="p">[</span><span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">ray_wait_register_center_timeout</span>
</span><span id="AgentEvolverRayPPOTrainer-454"><a href="#AgentEvolverRayPPOTrainer-454"><span class="linenos"> 454</span></a>
</span><span id="AgentEvolverRayPPOTrainer-455"><a href="#AgentEvolverRayPPOTrainer-455"><span class="linenos"> 455</span></a>        <span class="k">for</span> <span class="n">resource_pool</span><span class="p">,</span> <span class="n">class_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-456"><a href="#AgentEvolverRayPPOTrainer-456"><span class="linenos"> 456</span></a>            <span class="n">worker_dict_cls</span> <span class="o">=</span> <span class="n">create_colocated_worker_cls</span><span class="p">(</span><span class="n">class_dict</span><span class="o">=</span><span class="n">class_dict</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-457"><a href="#AgentEvolverRayPPOTrainer-457"><span class="linenos"> 457</span></a>            <span class="n">wg_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span><span class="p">(</span><span class="n">resource_pool</span><span class="o">=</span><span class="n">resource_pool</span><span class="p">,</span> <span class="n">ray_cls_with_init</span><span class="o">=</span><span class="n">worker_dict_cls</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-458"><a href="#AgentEvolverRayPPOTrainer-458"><span class="linenos"> 458</span></a>                                                <span class="n">device_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="o">**</span><span class="n">wg_kwargs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-459"><a href="#AgentEvolverRayPPOTrainer-459"><span class="linenos"> 459</span></a>            <span class="n">spawn_wg</span> <span class="o">=</span> <span class="n">wg_dict</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">prefix_set</span><span class="o">=</span><span class="n">class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer-460"><a href="#AgentEvolverRayPPOTrainer-460"><span class="linenos"> 460</span></a>            <span class="n">all_wg</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">spawn_wg</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-461"><a href="#AgentEvolverRayPPOTrainer-461"><span class="linenos"> 461</span></a>
</span><span id="AgentEvolverRayPPOTrainer-462"><a href="#AgentEvolverRayPPOTrainer-462"><span class="linenos"> 462</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-463"><a href="#AgentEvolverRayPPOTrainer-463"><span class="linenos"> 463</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-464"><a href="#AgentEvolverRayPPOTrainer-464"><span class="linenos"> 464</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer-465"><a href="#AgentEvolverRayPPOTrainer-465"><span class="linenos"> 465</span></a>
</span><span id="AgentEvolverRayPPOTrainer-466"><a href="#AgentEvolverRayPPOTrainer-466"><span class="linenos"> 466</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-467"><a href="#AgentEvolverRayPPOTrainer-467"><span class="linenos"> 467</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-468"><a href="#AgentEvolverRayPPOTrainer-468"><span class="linenos"> 468</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reference policy model</span>
</span><span id="AgentEvolverRayPPOTrainer-469"><a href="#AgentEvolverRayPPOTrainer-469"><span class="linenos"> 469</span></a>
</span><span id="AgentEvolverRayPPOTrainer-470"><a href="#AgentEvolverRayPPOTrainer-470"><span class="linenos"> 470</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-471"><a href="#AgentEvolverRayPPOTrainer-471"><span class="linenos"> 471</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-472"><a href="#AgentEvolverRayPPOTrainer-472"><span class="linenos"> 472</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reward model</span>
</span><span id="AgentEvolverRayPPOTrainer-473"><a href="#AgentEvolverRayPPOTrainer-473"><span class="linenos"> 473</span></a>
</span><span id="AgentEvolverRayPPOTrainer-474"><a href="#AgentEvolverRayPPOTrainer-474"><span class="linenos"> 474</span></a>        <span class="c1"># we should create rollout at the end so that vllm can have a better estimation of kv cache memory</span>
</span><span id="AgentEvolverRayPPOTrainer-475"><a href="#AgentEvolverRayPPOTrainer-475"><span class="linenos"> 475</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-476"><a href="#AgentEvolverRayPPOTrainer-476"><span class="linenos"> 476</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the actor rollout model</span>
</span><span id="AgentEvolverRayPPOTrainer-477"><a href="#AgentEvolverRayPPOTrainer-477"><span class="linenos"> 477</span></a>
</span><span id="AgentEvolverRayPPOTrainer-478"><a href="#AgentEvolverRayPPOTrainer-478"><span class="linenos"> 478</span></a>        <span class="c1"># create async rollout manager and request scheduler</span>
</span><span id="AgentEvolverRayPPOTrainer-479"><a href="#AgentEvolverRayPPOTrainer-479"><span class="linenos"> 479</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer-480"><a href="#AgentEvolverRayPPOTrainer-480"><span class="linenos"> 480</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;async&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-481"><a href="#AgentEvolverRayPPOTrainer-481"><span class="linenos"> 481</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.trainer.ae_async_llm_server_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaAsyncLLMServerManager</span>
</span><span id="AgentEvolverRayPPOTrainer-482"><a href="#AgentEvolverRayPPOTrainer-482"><span class="linenos"> 482</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="AgentEvolverRayPPOTrainer-483"><a href="#AgentEvolverRayPPOTrainer-483"><span class="linenos"> 483</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span> <span class="o">=</span> <span class="n">BaAsyncLLMServerManager</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-484"><a href="#AgentEvolverRayPPOTrainer-484"><span class="linenos"> 484</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-485"><a href="#AgentEvolverRayPPOTrainer-485"><span class="linenos"> 485</span></a>                <span class="n">worker_group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create the asynchronous rollout manager</span>
</span><span id="AgentEvolverRayPPOTrainer-486"><a href="#AgentEvolverRayPPOTrainer-486"><span class="linenos"> 486</span></a>
</span><span id="AgentEvolverRayPPOTrainer-487"><a href="#AgentEvolverRayPPOTrainer-487"><span class="linenos"> 487</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="AgentEvolverRayPPOTrainer-488"><a href="#AgentEvolverRayPPOTrainer-488"><span class="linenos"> 488</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="AgentEvolverRayPPOTrainer-489"><a href="#AgentEvolverRayPPOTrainer-489"><span class="linenos"> 489</span></a>
</span><span id="AgentEvolverRayPPOTrainer-490"><a href="#AgentEvolverRayPPOTrainer-490"><span class="linenos"> 490</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span> <span class="o">=</span> <span class="n">ParallelEnvManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">async_rollout_manager</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="p">,</span> <span class="n">max_parallel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_worker</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-491"><a href="#AgentEvolverRayPPOTrainer-491"><span class="linenos"> 491</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">thread_pool</span><span class="o">.</span><span class="n">max_workers</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-492"><a href="#AgentEvolverRayPPOTrainer-492"><span class="linenos"> 492</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span> <span class="o">=</span> <span class="n">ExperienceManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-493"><a href="#AgentEvolverRayPPOTrainer-493"><span class="linenos"> 493</span></a>
</span><span id="AgentEvolverRayPPOTrainer-494"><a href="#AgentEvolverRayPPOTrainer-494"><span class="linenos"> 494</span></a>
</span><span id="AgentEvolverRayPPOTrainer-495"><a href="#AgentEvolverRayPPOTrainer-495"><span class="linenos"> 495</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_create_dataloader_from_manager</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">,</span> <span class="n">shuffle_trainset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-496"><a href="#AgentEvolverRayPPOTrainer-496"><span class="linenos"> 496</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-497"><a href="#AgentEvolverRayPPOTrainer-497"><span class="linenos"> 497</span></a><span class="sd">        Creates the train and validation dataloaders.</span>
</span><span id="AgentEvolverRayPPOTrainer-498"><a href="#AgentEvolverRayPPOTrainer-498"><span class="linenos"> 498</span></a>
</span><span id="AgentEvolverRayPPOTrainer-499"><a href="#AgentEvolverRayPPOTrainer-499"><span class="linenos"> 499</span></a><span class="sd">        1. Check the existence of train and val files and load local tasks from them. If no files given, load tasks from environment (train and val/dev splits).</span>
</span><span id="AgentEvolverRayPPOTrainer-500"><a href="#AgentEvolverRayPPOTrainer-500"><span class="linenos"> 500</span></a><span class="sd">        2. Use task manager to generate synthetic tasks for trainset, and load the original val dataset.</span>
</span><span id="AgentEvolverRayPPOTrainer-501"><a href="#AgentEvolverRayPPOTrainer-501"><span class="linenos"> 501</span></a><span class="sd">        3. Use task manager to mix tasks from different sources.</span>
</span><span id="AgentEvolverRayPPOTrainer-502"><a href="#AgentEvolverRayPPOTrainer-502"><span class="linenos"> 502</span></a><span class="sd">        4. Adapt datasets and create dataloaders used in the trainer.</span>
</span><span id="AgentEvolverRayPPOTrainer-503"><a href="#AgentEvolverRayPPOTrainer-503"><span class="linenos"> 503</span></a>
</span><span id="AgentEvolverRayPPOTrainer-504"><a href="#AgentEvolverRayPPOTrainer-504"><span class="linenos"> 504</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer-505"><a href="#AgentEvolverRayPPOTrainer-505"><span class="linenos"> 505</span></a><span class="sd">            collate_fn (callable): The function to use for collating data into batches.</span>
</span><span id="AgentEvolverRayPPOTrainer-506"><a href="#AgentEvolverRayPPOTrainer-506"><span class="linenos"> 506</span></a><span class="sd">            shuffle_trainset (bool, optional): Whether to shuffle the training set. Defaults to True.</span>
</span><span id="AgentEvolverRayPPOTrainer-507"><a href="#AgentEvolverRayPPOTrainer-507"><span class="linenos"> 507</span></a>
</span><span id="AgentEvolverRayPPOTrainer-508"><a href="#AgentEvolverRayPPOTrainer-508"><span class="linenos"> 508</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer-509"><a href="#AgentEvolverRayPPOTrainer-509"><span class="linenos"> 509</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-510"><a href="#AgentEvolverRayPPOTrainer-510"><span class="linenos"> 510</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-511"><a href="#AgentEvolverRayPPOTrainer-511"><span class="linenos"> 511</span></a>        <span class="c1"># TODO: we have to make sure the batch size is divisible by the dp size</span>
</span><span id="AgentEvolverRayPPOTrainer-512"><a href="#AgentEvolverRayPPOTrainer-512"><span class="linenos"> 512</span></a>        <span class="k">if</span> <span class="n">collate_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-513"><a href="#AgentEvolverRayPPOTrainer-513"><span class="linenos"> 513</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">verl.utils.dataset.rl_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">collate_fn</span> <span class="k">as</span> <span class="n">default_collate_fn</span>
</span><span id="AgentEvolverRayPPOTrainer-514"><a href="#AgentEvolverRayPPOTrainer-514"><span class="linenos"> 514</span></a>
</span><span id="AgentEvolverRayPPOTrainer-515"><a href="#AgentEvolverRayPPOTrainer-515"><span class="linenos"> 515</span></a>            <span class="n">collate_fn</span> <span class="o">=</span> <span class="n">default_collate_fn</span>
</span><span id="AgentEvolverRayPPOTrainer-516"><a href="#AgentEvolverRayPPOTrainer-516"><span class="linenos"> 516</span></a>
</span><span id="AgentEvolverRayPPOTrainer-517"><a href="#AgentEvolverRayPPOTrainer-517"><span class="linenos"> 517</span></a>
</span><span id="AgentEvolverRayPPOTrainer-518"><a href="#AgentEvolverRayPPOTrainer-518"><span class="linenos"> 518</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">verl.trainer.main_ppo</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_rl_dataset</span>
</span><span id="AgentEvolverRayPPOTrainer-519"><a href="#AgentEvolverRayPPOTrainer-519"><span class="linenos"> 519</span></a>        <span class="c1"># load train dataset from files or environment</span>
</span><span id="AgentEvolverRayPPOTrainer-520"><a href="#AgentEvolverRayPPOTrainer-520"><span class="linenos"> 520</span></a>        <span class="n">env_client</span><span class="o">=</span><span class="n">EnvClient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_url</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-521"><a href="#AgentEvolverRayPPOTrainer-521"><span class="linenos"> 521</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-522"><a href="#AgentEvolverRayPPOTrainer-522"><span class="linenos"> 522</span></a>            <span class="n">train_seed_dataset</span> <span class="o">=</span> <span class="n">create_rl_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_files</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-523"><a href="#AgentEvolverRayPPOTrainer-523"><span class="linenos"> 523</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_seed_dataset</span><span class="p">,</span><span class="n">RLHFDataset</span><span class="p">),</span> <span class="s2">&quot;train_dataset must be RLHFDataset&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-524"><a href="#AgentEvolverRayPPOTrainer-524"><span class="linenos"> 524</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_dataset</span><span class="p">(</span><span class="n">train_seed_dataset</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-525"><a href="#AgentEvolverRayPPOTrainer-525"><span class="linenos"> 525</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-526"><a href="#AgentEvolverRayPPOTrainer-526"><span class="linenos"> 526</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-527"><a href="#AgentEvolverRayPPOTrainer-527"><span class="linenos"> 527</span></a>        <span class="c1"># load val dataset</span>
</span><span id="AgentEvolverRayPPOTrainer-528"><a href="#AgentEvolverRayPPOTrainer-528"><span class="linenos"> 528</span></a>        
</span><span id="AgentEvolverRayPPOTrainer-529"><a href="#AgentEvolverRayPPOTrainer-529"><span class="linenos"> 529</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_files</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-530"><a href="#AgentEvolverRayPPOTrainer-530"><span class="linenos"> 530</span></a>            <span class="n">val_seed_dataset</span> <span class="o">=</span> <span class="n">create_rl_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_files</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-531"><a href="#AgentEvolverRayPPOTrainer-531"><span class="linenos"> 531</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val_seed_dataset</span><span class="p">,</span><span class="n">RLHFDataset</span><span class="p">),</span> <span class="s2">&quot;train_dataset must be RLHFDataset&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-532"><a href="#AgentEvolverRayPPOTrainer-532"><span class="linenos"> 532</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_dataset</span><span class="p">(</span><span class="n">val_seed_dataset</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-533"><a href="#AgentEvolverRayPPOTrainer-533"><span class="linenos"> 533</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-534"><a href="#AgentEvolverRayPPOTrainer-534"><span class="linenos"> 534</span></a>            <span class="n">num_loaded_val_tasks</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="AgentEvolverRayPPOTrainer-535"><a href="#AgentEvolverRayPPOTrainer-535"><span class="linenos"> 535</span></a>            <span class="k">if</span> <span class="s1">&#39;val_on_test&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_type</span> <span class="o">==</span> <span class="s1">&#39;test_normal&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span> <span class="o">==</span> <span class="s2">&quot;appworld&quot;</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-536"><a href="#AgentEvolverRayPPOTrainer-536"><span class="linenos"> 536</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;using test_normal as val dataset&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-537"><a href="#AgentEvolverRayPPOTrainer-537"><span class="linenos"> 537</span></a>                <span class="n">num_loaded_val_tasks</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="s2">&quot;test_normal&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-538"><a href="#AgentEvolverRayPPOTrainer-538"><span class="linenos"> 538</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-539"><a href="#AgentEvolverRayPPOTrainer-539"><span class="linenos"> 539</span></a>                <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">,</span><span class="s1">&#39;dev&#39;</span><span class="p">]:</span>
</span><span id="AgentEvolverRayPPOTrainer-540"><a href="#AgentEvolverRayPPOTrainer-540"><span class="linenos"> 540</span></a>                    <span class="k">try</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-541"><a href="#AgentEvolverRayPPOTrainer-541"><span class="linenos"> 541</span></a>                        <span class="n">num_loaded_val_tasks</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">load_tasks_from_environment</span><span class="p">(</span><span class="n">env_client</span><span class="p">,</span><span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span><span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-542"><a href="#AgentEvolverRayPPOTrainer-542"><span class="linenos"> 542</span></a>                    <span class="k">except</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-543"><a href="#AgentEvolverRayPPOTrainer-543"><span class="linenos"> 543</span></a>                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;failed to load val dataset from environment, split=</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2">. this may be *normal* if your dataset is split into train/dev&quot;</span><span class="p">)</span>    
</span><span id="AgentEvolverRayPPOTrainer-544"><a href="#AgentEvolverRayPPOTrainer-544"><span class="linenos"> 544</span></a>            
</span><span id="AgentEvolverRayPPOTrainer-545"><a href="#AgentEvolverRayPPOTrainer-545"><span class="linenos"> 545</span></a>            <span class="k">assert</span> <span class="n">num_loaded_val_tasks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;failed to load val/dev dataset from environment&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-546"><a href="#AgentEvolverRayPPOTrainer-546"><span class="linenos"> 546</span></a>        
</span><span id="AgentEvolverRayPPOTrainer-547"><a href="#AgentEvolverRayPPOTrainer-547"><span class="linenos"> 547</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">FullDataset</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-548"><a href="#AgentEvolverRayPPOTrainer-548"><span class="linenos"> 548</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-549"><a href="#AgentEvolverRayPPOTrainer-549"><span class="linenos"> 549</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-550"><a href="#AgentEvolverRayPPOTrainer-550"><span class="linenos"> 550</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">_reward_config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-551"><a href="#AgentEvolverRayPPOTrainer-551"><span class="linenos"> 551</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">task_manager</span><span class="o">.</span><span class="n">train_data_path</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-552"><a href="#AgentEvolverRayPPOTrainer-552"><span class="linenos"> 552</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-553"><a href="#AgentEvolverRayPPOTrainer-553"><span class="linenos"> 553</span></a>            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-554"><a href="#AgentEvolverRayPPOTrainer-554"><span class="linenos"> 554</span></a>            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-555"><a href="#AgentEvolverRayPPOTrainer-555"><span class="linenos"> 555</span></a>        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-556"><a href="#AgentEvolverRayPPOTrainer-556"><span class="linenos"> 556</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">FullDataset</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-557"><a href="#AgentEvolverRayPPOTrainer-557"><span class="linenos"> 557</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-558"><a href="#AgentEvolverRayPPOTrainer-558"><span class="linenos"> 558</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-559"><a href="#AgentEvolverRayPPOTrainer-559"><span class="linenos"> 559</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">.</span><span class="n">_reward_config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-560"><a href="#AgentEvolverRayPPOTrainer-560"><span class="linenos"> 560</span></a>            <span class="n">cache_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-561"><a href="#AgentEvolverRayPPOTrainer-561"><span class="linenos"> 561</span></a>            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-562"><a href="#AgentEvolverRayPPOTrainer-562"><span class="linenos"> 562</span></a>            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-563"><a href="#AgentEvolverRayPPOTrainer-563"><span class="linenos"> 563</span></a>            <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-564"><a href="#AgentEvolverRayPPOTrainer-564"><span class="linenos"> 564</span></a>        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-565"><a href="#AgentEvolverRayPPOTrainer-565"><span class="linenos"> 565</span></a>
</span><span id="AgentEvolverRayPPOTrainer-566"><a href="#AgentEvolverRayPPOTrainer-566"><span class="linenos"> 566</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span><span class="n">AutoReloadDataset</span><span class="p">),</span> <span class="s2">&quot;please disable multiple workers for AutoReloadDataset&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-567"><a href="#AgentEvolverRayPPOTrainer-567"><span class="linenos"> 567</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span><span class="n">AutoReloadDataset</span><span class="p">),</span> <span class="s2">&quot;please disable multiple workers for AutoReloadDataset&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-568"><a href="#AgentEvolverRayPPOTrainer-568"><span class="linenos"> 568</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-569"><a href="#AgentEvolverRayPPOTrainer-569"><span class="linenos"> 569</span></a>            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-570"><a href="#AgentEvolverRayPPOTrainer-570"><span class="linenos"> 570</span></a>            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gen_batch_size&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-571"><a href="#AgentEvolverRayPPOTrainer-571"><span class="linenos"> 571</span></a>            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-572"><a href="#AgentEvolverRayPPOTrainer-572"><span class="linenos"> 572</span></a>            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-573"><a href="#AgentEvolverRayPPOTrainer-573"><span class="linenos"> 573</span></a>            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-574"><a href="#AgentEvolverRayPPOTrainer-574"><span class="linenos"> 574</span></a>            <span class="n">sampler</span><span class="o">=</span><span class="n">create_rl_sampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-575"><a href="#AgentEvolverRayPPOTrainer-575"><span class="linenos"> 575</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Create the train dataloader with specified parameters</span>
</span><span id="AgentEvolverRayPPOTrainer-576"><a href="#AgentEvolverRayPPOTrainer-576"><span class="linenos"> 576</span></a>
</span><span id="AgentEvolverRayPPOTrainer-577"><a href="#AgentEvolverRayPPOTrainer-577"><span class="linenos"> 577</span></a>        <span class="n">val_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_batch_size</span>  <span class="c1"># Prefer config value if set</span>
</span><span id="AgentEvolverRayPPOTrainer-578"><a href="#AgentEvolverRayPPOTrainer-578"><span class="linenos"> 578</span></a>        <span class="k">if</span> <span class="n">val_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-579"><a href="#AgentEvolverRayPPOTrainer-579"><span class="linenos"> 579</span></a>            <span class="n">val_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">)</span> <span class="c1"># type: ignore</span>
</span><span id="AgentEvolverRayPPOTrainer-580"><a href="#AgentEvolverRayPPOTrainer-580"><span class="linenos"> 580</span></a>
</span><span id="AgentEvolverRayPPOTrainer-581"><a href="#AgentEvolverRayPPOTrainer-581"><span class="linenos"> 581</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span> <span class="o">=</span> <span class="n">StatefulDataLoader</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-582"><a href="#AgentEvolverRayPPOTrainer-582"><span class="linenos"> 582</span></a>            <span class="n">dataset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-583"><a href="#AgentEvolverRayPPOTrainer-583"><span class="linenos"> 583</span></a>            <span class="n">batch_size</span><span class="o">=</span><span class="n">val_batch_size</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-584"><a href="#AgentEvolverRayPPOTrainer-584"><span class="linenos"> 584</span></a>            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dataloader_num_workers&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-585"><a href="#AgentEvolverRayPPOTrainer-585"><span class="linenos"> 585</span></a>            <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation_shuffle&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-586"><a href="#AgentEvolverRayPPOTrainer-586"><span class="linenos"> 586</span></a>            <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-587"><a href="#AgentEvolverRayPPOTrainer-587"><span class="linenos"> 587</span></a>            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-588"><a href="#AgentEvolverRayPPOTrainer-588"><span class="linenos"> 588</span></a>        <span class="p">)</span>  <span class="c1"># ‚≠ê Create the validation dataloader with specified parameters</span>
</span><span id="AgentEvolverRayPPOTrainer-589"><a href="#AgentEvolverRayPPOTrainer-589"><span class="linenos"> 589</span></a>
</span><span id="AgentEvolverRayPPOTrainer-590"><a href="#AgentEvolverRayPPOTrainer-590"><span class="linenos"> 590</span></a>        <span class="c1"># train dataloader is on-the-fly, so we don&#39;t need to check the size</span>
</span><span id="AgentEvolverRayPPOTrainer-591"><a href="#AgentEvolverRayPPOTrainer-591"><span class="linenos"> 591</span></a>        <span class="c1"># assert len(self.train_dataloader) &gt;= 1, &quot;Train dataloader is empty!&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-592"><a href="#AgentEvolverRayPPOTrainer-592"><span class="linenos"> 592</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Validation dataloader is empty!&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-593"><a href="#AgentEvolverRayPPOTrainer-593"><span class="linenos"> 593</span></a>
</span><span id="AgentEvolverRayPPOTrainer-594"><a href="#AgentEvolverRayPPOTrainer-594"><span class="linenos"> 594</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span><span class="n">IterableDataset</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-595"><a href="#AgentEvolverRayPPOTrainer-595"><span class="linenos"> 595</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>
</span><span id="AgentEvolverRayPPOTrainer-596"><a href="#AgentEvolverRayPPOTrainer-596"><span class="linenos"> 596</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of train dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">, Size of val dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-597"><a href="#AgentEvolverRayPPOTrainer-597"><span class="linenos"> 597</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-598"><a href="#AgentEvolverRayPPOTrainer-598"><span class="linenos"> 598</span></a>            <span class="c1"># FIXME: need a elegant way to set total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-599"><a href="#AgentEvolverRayPPOTrainer-599"><span class="linenos"> 599</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">.</span><span class="n">seed_tasks</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span>
</span><span id="AgentEvolverRayPPOTrainer-600"><a href="#AgentEvolverRayPPOTrainer-600"><span class="linenos"> 600</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Size of train dataloader: unknown, Size of val dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-601"><a href="#AgentEvolverRayPPOTrainer-601"><span class="linenos"> 601</span></a>
</span><span id="AgentEvolverRayPPOTrainer-602"><a href="#AgentEvolverRayPPOTrainer-602"><span class="linenos"> 602</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-603"><a href="#AgentEvolverRayPPOTrainer-603"><span class="linenos"> 603</span></a>            <span class="n">total_training_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-604"><a href="#AgentEvolverRayPPOTrainer-604"><span class="linenos"> 604</span></a>
</span><span id="AgentEvolverRayPPOTrainer-605"><a href="#AgentEvolverRayPPOTrainer-605"><span class="linenos"> 605</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-606"><a href="#AgentEvolverRayPPOTrainer-606"><span class="linenos"> 606</span></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total training steps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-607"><a href="#AgentEvolverRayPPOTrainer-607"><span class="linenos"> 607</span></a>
</span><span id="AgentEvolverRayPPOTrainer-608"><a href="#AgentEvolverRayPPOTrainer-608"><span class="linenos"> 608</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-609"><a href="#AgentEvolverRayPPOTrainer-609"><span class="linenos"> 609</span></a>            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-610"><a href="#AgentEvolverRayPPOTrainer-610"><span class="linenos"> 610</span></a>            <span class="k">with</span> <span class="n">open_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-611"><a href="#AgentEvolverRayPPOTrainer-611"><span class="linenos"> 611</span></a>                <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;actor_rollout_ref.actor.optim&quot;</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-612"><a href="#AgentEvolverRayPPOTrainer-612"><span class="linenos"> 612</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-613"><a href="#AgentEvolverRayPPOTrainer-613"><span class="linenos"> 613</span></a>                <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;critic.optim&quot;</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-614"><a href="#AgentEvolverRayPPOTrainer-614"><span class="linenos"> 614</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">total_training_steps</span> <span class="o">=</span> <span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-615"><a href="#AgentEvolverRayPPOTrainer-615"><span class="linenos"> 615</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-616"><a href="#AgentEvolverRayPPOTrainer-616"><span class="linenos"> 616</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Could not set total_training_steps in config. Structure missing? Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-617"><a href="#AgentEvolverRayPPOTrainer-617"><span class="linenos"> 617</span></a>
</span><span id="AgentEvolverRayPPOTrainer-618"><a href="#AgentEvolverRayPPOTrainer-618"><span class="linenos"> 618</span></a>
</span><span id="AgentEvolverRayPPOTrainer-619"><a href="#AgentEvolverRayPPOTrainer-619"><span class="linenos"> 619</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_get_attribution_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-620"><a href="#AgentEvolverRayPPOTrainer-620"><span class="linenos"> 620</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-621"><a href="#AgentEvolverRayPPOTrainer-621"><span class="linenos"> 621</span></a><span class="sd">        Retrieves and validates the configuration for attribution-driven credit assignment, including the setup for API retry attempts.</span>
</span><span id="AgentEvolverRayPPOTrainer-622"><a href="#AgentEvolverRayPPOTrainer-622"><span class="linenos"> 622</span></a>
</span><span id="AgentEvolverRayPPOTrainer-623"><a href="#AgentEvolverRayPPOTrainer-623"><span class="linenos"> 623</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer-624"><a href="#AgentEvolverRayPPOTrainer-624"><span class="linenos"> 624</span></a><span class="sd">            dict: The validated and possibly updated configuration dictionary.</span>
</span><span id="AgentEvolverRayPPOTrainer-625"><a href="#AgentEvolverRayPPOTrainer-625"><span class="linenos"> 625</span></a>
</span><span id="AgentEvolverRayPPOTrainer-626"><a href="#AgentEvolverRayPPOTrainer-626"><span class="linenos"> 626</span></a><span class="sd">        Raises:</span>
</span><span id="AgentEvolverRayPPOTrainer-627"><a href="#AgentEvolverRayPPOTrainer-627"><span class="linenos"> 627</span></a><span class="sd">            ValueError: If the required &#39;attribution_driven_credit_assignment&#39; block is missing from the configuration.</span>
</span><span id="AgentEvolverRayPPOTrainer-628"><a href="#AgentEvolverRayPPOTrainer-628"><span class="linenos"> 628</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-629"><a href="#AgentEvolverRayPPOTrainer-629"><span class="linenos"> 629</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;attribution_driven_credit_assignment&#39;</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-630"><a href="#AgentEvolverRayPPOTrainer-630"><span class="linenos"> 630</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;attribution_driven_credit_assignment configuration block is required&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-631"><a href="#AgentEvolverRayPPOTrainer-631"><span class="linenos"> 631</span></a>
</span><span id="AgentEvolverRayPPOTrainer-632"><a href="#AgentEvolverRayPPOTrainer-632"><span class="linenos"> 632</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">attribution_driven_credit_assignment</span>
</span><span id="AgentEvolverRayPPOTrainer-633"><a href="#AgentEvolverRayPPOTrainer-633"><span class="linenos"> 633</span></a>
</span><span id="AgentEvolverRayPPOTrainer-634"><a href="#AgentEvolverRayPPOTrainer-634"><span class="linenos"> 634</span></a>        <span class="c1"># set the default api_max_retries</span>
</span><span id="AgentEvolverRayPPOTrainer-635"><a href="#AgentEvolverRayPPOTrainer-635"><span class="linenos"> 635</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s1">&#39;api_max_retries&#39;</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-636"><a href="#AgentEvolverRayPPOTrainer-636"><span class="linenos"> 636</span></a>            <span class="n">config</span><span class="o">.</span><span class="n">api_max_retries</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># ‚≠ê Set the default number of API retries to 200</span>
</span><span id="AgentEvolverRayPPOTrainer-637"><a href="#AgentEvolverRayPPOTrainer-637"><span class="linenos"> 637</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[attribution_config] Using default api_max_retries: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">api_max_retries</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-638"><a href="#AgentEvolverRayPPOTrainer-638"><span class="linenos"> 638</span></a>
</span><span id="AgentEvolverRayPPOTrainer-639"><a href="#AgentEvolverRayPPOTrainer-639"><span class="linenos"> 639</span></a>        <span class="k">return</span> <span class="n">config</span>
</span><span id="AgentEvolverRayPPOTrainer-640"><a href="#AgentEvolverRayPPOTrainer-640"><span class="linenos"> 640</span></a>
</span><span id="AgentEvolverRayPPOTrainer-641"><a href="#AgentEvolverRayPPOTrainer-641"><span class="linenos"> 641</span></a>
</span><span id="AgentEvolverRayPPOTrainer-642"><a href="#AgentEvolverRayPPOTrainer-642"><span class="linenos"> 642</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_validate_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-643"><a href="#AgentEvolverRayPPOTrainer-643"><span class="linenos"> 643</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-644"><a href="#AgentEvolverRayPPOTrainer-644"><span class="linenos"> 644</span></a><span class="sd">        Validates the configuration settings to ensure they are consistent and meet the necessary requirements for the training process.</span>
</span><span id="AgentEvolverRayPPOTrainer-645"><a href="#AgentEvolverRayPPOTrainer-645"><span class="linenos"> 645</span></a>
</span><span id="AgentEvolverRayPPOTrainer-646"><a href="#AgentEvolverRayPPOTrainer-646"><span class="linenos"> 646</span></a><span class="sd">        This function checks:</span>
</span><span id="AgentEvolverRayPPOTrainer-647"><a href="#AgentEvolverRayPPOTrainer-647"><span class="linenos"> 647</span></a><span class="sd">        - The total number of GPUs and their allocation.</span>
</span><span id="AgentEvolverRayPPOTrainer-648"><a href="#AgentEvolverRayPPOTrainer-648"><span class="linenos"> 648</span></a><span class="sd">        - The total batch size and its divisibility by the minimal possible batch size.</span>
</span><span id="AgentEvolverRayPPOTrainer-649"><a href="#AgentEvolverRayPPOTrainer-649"><span class="linenos"> 649</span></a><span class="sd">        - Mutual exclusivity of certain micro-batch size parameters.</span>
</span><span id="AgentEvolverRayPPOTrainer-650"><a href="#AgentEvolverRayPPOTrainer-650"><span class="linenos"> 650</span></a><span class="sd">        - Consistency in actor, critic, and reward model configurations.</span>
</span><span id="AgentEvolverRayPPOTrainer-651"><a href="#AgentEvolverRayPPOTrainer-651"><span class="linenos"> 651</span></a><span class="sd">        - Other critical settings such as loss aggregation mode and sequence parallelism.</span>
</span><span id="AgentEvolverRayPPOTrainer-652"><a href="#AgentEvolverRayPPOTrainer-652"><span class="linenos"> 652</span></a>
</span><span id="AgentEvolverRayPPOTrainer-653"><a href="#AgentEvolverRayPPOTrainer-653"><span class="linenos"> 653</span></a><span class="sd">        Raises:</span>
</span><span id="AgentEvolverRayPPOTrainer-654"><a href="#AgentEvolverRayPPOTrainer-654"><span class="linenos"> 654</span></a><span class="sd">            AssertionError: If any of the configuration settings do not meet the required conditions.</span>
</span><span id="AgentEvolverRayPPOTrainer-655"><a href="#AgentEvolverRayPPOTrainer-655"><span class="linenos"> 655</span></a><span class="sd">            ValueError: If mutually exclusive parameters are both set or neither is set.</span>
</span><span id="AgentEvolverRayPPOTrainer-656"><a href="#AgentEvolverRayPPOTrainer-656"><span class="linenos"> 656</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-657"><a href="#AgentEvolverRayPPOTrainer-657"><span class="linenos"> 657</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
</span><span id="AgentEvolverRayPPOTrainer-658"><a href="#AgentEvolverRayPPOTrainer-658"><span class="linenos"> 658</span></a>        <span class="c1"># number of GPUs total</span>
</span><span id="AgentEvolverRayPPOTrainer-659"><a href="#AgentEvolverRayPPOTrainer-659"><span class="linenos"> 659</span></a>        <span class="n">n_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">n_gpus_per_node</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">nnodes</span>
</span><span id="AgentEvolverRayPPOTrainer-660"><a href="#AgentEvolverRayPPOTrainer-660"><span class="linenos"> 660</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;megatron&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-661"><a href="#AgentEvolverRayPPOTrainer-661"><span class="linenos"> 661</span></a>            <span class="n">model_parallel_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">tensor_model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">pipeline_model_parallel_size</span>
</span><span id="AgentEvolverRayPPOTrainer-662"><a href="#AgentEvolverRayPPOTrainer-662"><span class="linenos"> 662</span></a>            <span class="k">assert</span> <span class="n">n_gpus</span> <span class="o">%</span> <span class="p">(</span><span class="n">model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;n_gpus (</span><span class="si">{</span><span class="n">n_gpus</span><span class="si">}</span><span class="s2">) must be divisible by model_parallel_size (</span><span class="si">{</span><span class="n">model_parallel_size</span><span class="si">}</span><span class="s2">) times context_parallel_size (</span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-663"><a href="#AgentEvolverRayPPOTrainer-663"><span class="linenos"> 663</span></a>            <span class="n">megatron_dp</span> <span class="o">=</span> <span class="n">n_gpus</span> <span class="o">//</span> <span class="p">(</span><span class="n">model_parallel_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">megatron</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-664"><a href="#AgentEvolverRayPPOTrainer-664"><span class="linenos"> 664</span></a>            <span class="n">minimal_bsz</span> <span class="o">=</span> <span class="n">megatron_dp</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span>
</span><span id="AgentEvolverRayPPOTrainer-665"><a href="#AgentEvolverRayPPOTrainer-665"><span class="linenos"> 665</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-666"><a href="#AgentEvolverRayPPOTrainer-666"><span class="linenos"> 666</span></a>            <span class="n">minimal_bsz</span> <span class="o">=</span> <span class="n">n_gpus</span>
</span><span id="AgentEvolverRayPPOTrainer-667"><a href="#AgentEvolverRayPPOTrainer-667"><span class="linenos"> 667</span></a>
</span><span id="AgentEvolverRayPPOTrainer-668"><a href="#AgentEvolverRayPPOTrainer-668"><span class="linenos"> 668</span></a>        <span class="c1"># 1. Check total batch size for data correctness</span>
</span><span id="AgentEvolverRayPPOTrainer-669"><a href="#AgentEvolverRayPPOTrainer-669"><span class="linenos"> 669</span></a>        <span class="n">real_train_batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span>
</span><span id="AgentEvolverRayPPOTrainer-670"><a href="#AgentEvolverRayPPOTrainer-670"><span class="linenos"> 670</span></a>        <span class="k">assert</span> <span class="n">real_train_batch_size</span> <span class="o">%</span> <span class="n">minimal_bsz</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;real_train_batch_size (</span><span class="si">{</span><span class="n">real_train_batch_size</span><span class="si">}</span><span class="s2">) must be divisible by minimal possible batch size (</span><span class="si">{</span><span class="n">minimal_bsz</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-671"><a href="#AgentEvolverRayPPOTrainer-671"><span class="linenos"> 671</span></a>
</span><span id="AgentEvolverRayPPOTrainer-672"><a href="#AgentEvolverRayPPOTrainer-672"><span class="linenos"> 672</span></a>        <span class="c1"># A helper function to check &quot;micro_batch_size&quot; vs &quot;micro_batch_size_per_gpu&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-673"><a href="#AgentEvolverRayPPOTrainer-673"><span class="linenos"> 673</span></a>        <span class="c1"># We throw an error if the user sets both. The new convention is &quot;..._micro_batch_size_per_gpu&quot;.</span>
</span><span id="AgentEvolverRayPPOTrainer-674"><a href="#AgentEvolverRayPPOTrainer-674"><span class="linenos"> 674</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">check_mutually_exclusive</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="n">mbs_per_gpu</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-675"><a href="#AgentEvolverRayPPOTrainer-675"><span class="linenos"> 675</span></a>            <span class="n">settings</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-676"><a href="#AgentEvolverRayPPOTrainer-676"><span class="linenos"> 676</span></a>                <span class="s2">&quot;actor_rollout_ref.actor&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-677"><a href="#AgentEvolverRayPPOTrainer-677"><span class="linenos"> 677</span></a>                <span class="s2">&quot;critic&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-678"><a href="#AgentEvolverRayPPOTrainer-678"><span class="linenos"> 678</span></a>                <span class="s2">&quot;reward_model&quot;</span><span class="p">:</span> <span class="s2">&quot;micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-679"><a href="#AgentEvolverRayPPOTrainer-679"><span class="linenos"> 679</span></a>                <span class="s2">&quot;actor_rollout_ref.ref&quot;</span><span class="p">:</span> <span class="s2">&quot;log_prob_micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-680"><a href="#AgentEvolverRayPPOTrainer-680"><span class="linenos"> 680</span></a>                <span class="s2">&quot;actor_rollout_ref.rollout&quot;</span><span class="p">:</span> <span class="s2">&quot;log_prob_micro_batch_size&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-681"><a href="#AgentEvolverRayPPOTrainer-681"><span class="linenos"> 681</span></a>            <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-682"><a href="#AgentEvolverRayPPOTrainer-682"><span class="linenos"> 682</span></a>
</span><span id="AgentEvolverRayPPOTrainer-683"><a href="#AgentEvolverRayPPOTrainer-683"><span class="linenos"> 683</span></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">settings</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-684"><a href="#AgentEvolverRayPPOTrainer-684"><span class="linenos"> 684</span></a>                <span class="n">param</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-685"><a href="#AgentEvolverRayPPOTrainer-685"><span class="linenos"> 685</span></a>                <span class="n">param_per_gpu</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">_per_gpu&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-686"><a href="#AgentEvolverRayPPOTrainer-686"><span class="linenos"> 686</span></a>
</span><span id="AgentEvolverRayPPOTrainer-687"><a href="#AgentEvolverRayPPOTrainer-687"><span class="linenos"> 687</span></a>                <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-688"><a href="#AgentEvolverRayPPOTrainer-688"><span class="linenos"> 688</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] Please set at least one of &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; or &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-689"><a href="#AgentEvolverRayPPOTrainer-689"><span class="linenos"> 689</span></a>
</span><span id="AgentEvolverRayPPOTrainer-690"><a href="#AgentEvolverRayPPOTrainer-690"><span class="linenos"> 690</span></a>                <span class="k">if</span> <span class="n">mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">mbs_per_gpu</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-691"><a href="#AgentEvolverRayPPOTrainer-691"><span class="linenos"> 691</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">] You have set both &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; AND &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;. Please remove &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&#39; because only &#39;*_</span><span class="si">{</span><span class="n">param_per_gpu</span><span class="si">}</span><span class="s2">&#39;&quot;</span> <span class="o">+</span> <span class="s2">&quot;is supported (the former is deprecated).&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-692"><a href="#AgentEvolverRayPPOTrainer-692"><span class="linenos"> 692</span></a>
</span><span id="AgentEvolverRayPPOTrainer-693"><a href="#AgentEvolverRayPPOTrainer-693"><span class="linenos"> 693</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-694"><a href="#AgentEvolverRayPPOTrainer-694"><span class="linenos"> 694</span></a>            <span class="c1"># actor: ppo_micro_batch_size vs. ppo_micro_batch_size_per_gpu</span>
</span><span id="AgentEvolverRayPPOTrainer-695"><a href="#AgentEvolverRayPPOTrainer-695"><span class="linenos"> 695</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-696"><a href="#AgentEvolverRayPPOTrainer-696"><span class="linenos"> 696</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-697"><a href="#AgentEvolverRayPPOTrainer-697"><span class="linenos"> 697</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-698"><a href="#AgentEvolverRayPPOTrainer-698"><span class="linenos"> 698</span></a>                <span class="s2">&quot;actor_rollout_ref.actor&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-699"><a href="#AgentEvolverRayPPOTrainer-699"><span class="linenos"> 699</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-700"><a href="#AgentEvolverRayPPOTrainer-700"><span class="linenos"> 700</span></a>
</span><span id="AgentEvolverRayPPOTrainer-701"><a href="#AgentEvolverRayPPOTrainer-701"><span class="linenos"> 701</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-702"><a href="#AgentEvolverRayPPOTrainer-702"><span class="linenos"> 702</span></a>                <span class="c1"># reference: log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
</span><span id="AgentEvolverRayPPOTrainer-703"><a href="#AgentEvolverRayPPOTrainer-703"><span class="linenos"> 703</span></a>                <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-704"><a href="#AgentEvolverRayPPOTrainer-704"><span class="linenos"> 704</span></a>                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-705"><a href="#AgentEvolverRayPPOTrainer-705"><span class="linenos"> 705</span></a>                    <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-706"><a href="#AgentEvolverRayPPOTrainer-706"><span class="linenos"> 706</span></a>                    <span class="s2">&quot;actor_rollout_ref.ref&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-707"><a href="#AgentEvolverRayPPOTrainer-707"><span class="linenos"> 707</span></a>                <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-708"><a href="#AgentEvolverRayPPOTrainer-708"><span class="linenos"> 708</span></a>
</span><span id="AgentEvolverRayPPOTrainer-709"><a href="#AgentEvolverRayPPOTrainer-709"><span class="linenos"> 709</span></a>            <span class="c1">#  The rollout section also has log_prob_micro_batch_size vs. log_prob_micro_batch_size_per_gpu</span>
</span><span id="AgentEvolverRayPPOTrainer-710"><a href="#AgentEvolverRayPPOTrainer-710"><span class="linenos"> 710</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-711"><a href="#AgentEvolverRayPPOTrainer-711"><span class="linenos"> 711</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-712"><a href="#AgentEvolverRayPPOTrainer-712"><span class="linenos"> 712</span></a>                <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">log_prob_micro_batch_size_per_gpu</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-713"><a href="#AgentEvolverRayPPOTrainer-713"><span class="linenos"> 713</span></a>                <span class="s2">&quot;actor_rollout_ref.rollout&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-714"><a href="#AgentEvolverRayPPOTrainer-714"><span class="linenos"> 714</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-715"><a href="#AgentEvolverRayPPOTrainer-715"><span class="linenos"> 715</span></a>
</span><span id="AgentEvolverRayPPOTrainer-716"><a href="#AgentEvolverRayPPOTrainer-716"><span class="linenos"> 716</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-717"><a href="#AgentEvolverRayPPOTrainer-717"><span class="linenos"> 717</span></a>            <span class="c1"># Check for critic micro-batch size conflicts</span>
</span><span id="AgentEvolverRayPPOTrainer-718"><a href="#AgentEvolverRayPPOTrainer-718"><span class="linenos"> 718</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">,</span> <span class="s2">&quot;critic&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-719"><a href="#AgentEvolverRayPPOTrainer-719"><span class="linenos"> 719</span></a>
</span><span id="AgentEvolverRayPPOTrainer-720"><a href="#AgentEvolverRayPPOTrainer-720"><span class="linenos"> 720</span></a>        <span class="c1"># Check for reward model micro-batch size conflicts</span>
</span><span id="AgentEvolverRayPPOTrainer-721"><a href="#AgentEvolverRayPPOTrainer-721"><span class="linenos"> 721</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-722"><a href="#AgentEvolverRayPPOTrainer-722"><span class="linenos"> 722</span></a>            <span class="n">check_mutually_exclusive</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">micro_batch_size_per_gpu</span><span class="p">,</span> <span class="s2">&quot;reward_model&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-723"><a href="#AgentEvolverRayPPOTrainer-723"><span class="linenos"> 723</span></a>
</span><span id="AgentEvolverRayPPOTrainer-724"><a href="#AgentEvolverRayPPOTrainer-724"><span class="linenos"> 724</span></a>        <span class="c1"># Actor</span>
</span><span id="AgentEvolverRayPPOTrainer-725"><a href="#AgentEvolverRayPPOTrainer-725"><span class="linenos"> 725</span></a>        <span class="c1"># check if train_batch_size is larger than ppo_mini_batch_size</span>
</span><span id="AgentEvolverRayPPOTrainer-726"><a href="#AgentEvolverRayPPOTrainer-726"><span class="linenos"> 726</span></a>        <span class="c1"># if NOT dynamic_bsz, we must ensure:</span>
</span><span id="AgentEvolverRayPPOTrainer-727"><a href="#AgentEvolverRayPPOTrainer-727"><span class="linenos"> 727</span></a>        <span class="c1">#    ppo_mini_batch_size is divisible by ppo_micro_batch_size</span>
</span><span id="AgentEvolverRayPPOTrainer-728"><a href="#AgentEvolverRayPPOTrainer-728"><span class="linenos"> 728</span></a>        <span class="c1">#    ppo_micro_batch_size * sequence_parallel_size &gt;= n_gpus</span>
</span><span id="AgentEvolverRayPPOTrainer-729"><a href="#AgentEvolverRayPPOTrainer-729"><span class="linenos"> 729</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-730"><a href="#AgentEvolverRayPPOTrainer-730"><span class="linenos"> 730</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>  <span class="c1"># ‚≠ê Ensure train_batch_size is at least as large as ppo_mini_batch_size</span>
</span><span id="AgentEvolverRayPPOTrainer-731"><a href="#AgentEvolverRayPPOTrainer-731"><span class="linenos"> 731</span></a>            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-732"><a href="#AgentEvolverRayPPOTrainer-732"><span class="linenos"> 732</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-733"><a href="#AgentEvolverRayPPOTrainer-733"><span class="linenos"> 733</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># ‚≠ê Ensure ppo_mini_batch_size is divisible by ppo_micro_batch_size</span>
</span><span id="AgentEvolverRayPPOTrainer-734"><a href="#AgentEvolverRayPPOTrainer-734"><span class="linenos"> 734</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>  <span class="c1"># ‚≠ê Ensure sufficient GPU allocation for micro-batch size and sequence parallelism</span>
</span><span id="AgentEvolverRayPPOTrainer-735"><a href="#AgentEvolverRayPPOTrainer-735"><span class="linenos"> 735</span></a>
</span><span id="AgentEvolverRayPPOTrainer-736"><a href="#AgentEvolverRayPPOTrainer-736"><span class="linenos"> 736</span></a>        <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span> <span class="ow">in</span> <span class="p">[</span>
</span><span id="AgentEvolverRayPPOTrainer-737"><a href="#AgentEvolverRayPPOTrainer-737"><span class="linenos"> 737</span></a>            <span class="s2">&quot;token-mean&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-738"><a href="#AgentEvolverRayPPOTrainer-738"><span class="linenos"> 738</span></a>            <span class="s2">&quot;seq-mean-token-sum&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-739"><a href="#AgentEvolverRayPPOTrainer-739"><span class="linenos"> 739</span></a>            <span class="s2">&quot;seq-mean-token-mean&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-740"><a href="#AgentEvolverRayPPOTrainer-740"><span class="linenos"> 740</span></a>            <span class="s2">&quot;seq-mean-token-sum-norm&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-741"><a href="#AgentEvolverRayPPOTrainer-741"><span class="linenos"> 741</span></a>        <span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;Invalid loss_agg_mode: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-742"><a href="#AgentEvolverRayPPOTrainer-742"><span class="linenos"> 742</span></a>
</span><span id="AgentEvolverRayPPOTrainer-743"><a href="#AgentEvolverRayPPOTrainer-743"><span class="linenos"> 743</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">use_kl_loss</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-744"><a href="#AgentEvolverRayPPOTrainer-744"><span class="linenos"> 744</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NOTICE: You have both enabled in-reward kl and kl loss.&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-745"><a href="#AgentEvolverRayPPOTrainer-745"><span class="linenos"> 745</span></a>
</span><span id="AgentEvolverRayPPOTrainer-746"><a href="#AgentEvolverRayPPOTrainer-746"><span class="linenos"> 746</span></a>        <span class="c1"># critic</span>
</span><span id="AgentEvolverRayPPOTrainer-747"><a href="#AgentEvolverRayPPOTrainer-747"><span class="linenos"> 747</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-748"><a href="#AgentEvolverRayPPOTrainer-748"><span class="linenos"> 748</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">&gt;=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span>  <span class="c1"># ‚≠ê Ensure train_batch_size is at least as large as ppo_mini_batch_size for critic</span>
</span><span id="AgentEvolverRayPPOTrainer-749"><a href="#AgentEvolverRayPPOTrainer-749"><span class="linenos"> 749</span></a>            <span class="n">sp_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-750"><a href="#AgentEvolverRayPPOTrainer-750"><span class="linenos"> 750</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-751"><a href="#AgentEvolverRayPPOTrainer-751"><span class="linenos"> 751</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_mini_batch_size</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># ‚≠ê Ensure ppo_mini_batch_size is divisible by ppo_micro_batch_size for critic</span>
</span><span id="AgentEvolverRayPPOTrainer-752"><a href="#AgentEvolverRayPPOTrainer-752"><span class="linenos"> 752</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">ppo_micro_batch_size</span> <span class="o">*</span> <span class="n">sp_size</span> <span class="o">&gt;=</span> <span class="n">n_gpus</span>  <span class="c1"># ‚≠ê Ensure sufficient GPU allocation for micro-batch size and sequence parallelism for critic</span>
</span><span id="AgentEvolverRayPPOTrainer-753"><a href="#AgentEvolverRayPPOTrainer-753"><span class="linenos"> 753</span></a>
</span><span id="AgentEvolverRayPPOTrainer-754"><a href="#AgentEvolverRayPPOTrainer-754"><span class="linenos"> 754</span></a>        <span class="c1"># Check if use_remove_padding is enabled when using sequence parallelism for fsdp</span>
</span><span id="AgentEvolverRayPPOTrainer-755"><a href="#AgentEvolverRayPPOTrainer-755"><span class="linenos"> 755</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">ref</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-756"><a href="#AgentEvolverRayPPOTrainer-756"><span class="linenos"> 756</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span><span class="p">,</span> <span class="s2">&quot;When using sequence parallelism for actor/ref policy, you must enable `use_remove_padding`.&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-757"><a href="#AgentEvolverRayPPOTrainer-757"><span class="linenos"> 757</span></a>
</span><span id="AgentEvolverRayPPOTrainer-758"><a href="#AgentEvolverRayPPOTrainer-758"><span class="linenos"> 758</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;fsdp&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-759"><a href="#AgentEvolverRayPPOTrainer-759"><span class="linenos"> 759</span></a>            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ulysses_sequence_parallel_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-760"><a href="#AgentEvolverRayPPOTrainer-760"><span class="linenos"> 760</span></a>                <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">use_remove_padding</span><span class="p">,</span> <span class="s2">&quot;When using sequence parallelism for critic, you must enable `use_remove_padding`.&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-761"><a href="#AgentEvolverRayPPOTrainer-761"><span class="linenos"> 761</span></a>
</span><span id="AgentEvolverRayPPOTrainer-762"><a href="#AgentEvolverRayPPOTrainer-762"><span class="linenos"> 762</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_batch_size&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-763"><a href="#AgentEvolverRayPPOTrainer-763"><span class="linenos"> 763</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: val_batch_size is deprecated.&quot;</span> <span class="o">+</span> <span class="s2">&quot; Validation datasets are sent to inference engines as a whole batch,&quot;</span> <span class="o">+</span> <span class="s2">&quot; which will schedule the memory themselves.&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-764"><a href="#AgentEvolverRayPPOTrainer-764"><span class="linenos"> 764</span></a>
</span><span id="AgentEvolverRayPPOTrainer-765"><a href="#AgentEvolverRayPPOTrainer-765"><span class="linenos"> 765</span></a>        <span class="c1"># check eval config</span>
</span><span id="AgentEvolverRayPPOTrainer-766"><a href="#AgentEvolverRayPPOTrainer-766"><span class="linenos"> 766</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-767"><a href="#AgentEvolverRayPPOTrainer-767"><span class="linenos"> 767</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">temperature</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;validation gen temperature should be greater than 0 when enabling do_sample&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-768"><a href="#AgentEvolverRayPPOTrainer-768"><span class="linenos"> 768</span></a>
</span><span id="AgentEvolverRayPPOTrainer-769"><a href="#AgentEvolverRayPPOTrainer-769"><span class="linenos"> 769</span></a>        <span class="c1"># check multi_turn with tool config</span>
</span><span id="AgentEvolverRayPPOTrainer-770"><a href="#AgentEvolverRayPPOTrainer-770"><span class="linenos"> 770</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-771"><a href="#AgentEvolverRayPPOTrainer-771"><span class="linenos"> 771</span></a>            <span class="c1"># 0623 yunpeng comment: no need this tool_config_path</span>
</span><span id="AgentEvolverRayPPOTrainer-772"><a href="#AgentEvolverRayPPOTrainer-772"><span class="linenos"> 772</span></a>            <span class="c1"># assert config.actor_rollout_ref.rollout.multi_turn.tool_config_path is not None or config.actor_rollout_ref.rollout.multi_turn.interaction_config_path is not None, &quot;tool_config_path or interaction_config_path must be set when enabling multi_turn with tool, due to no role-playing support&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-773"><a href="#AgentEvolverRayPPOTrainer-773"><span class="linenos"> 773</span></a>            <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span><span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">],</span> <span class="s2">&quot;only GRPO is tested for multi-turn with tool&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-774"><a href="#AgentEvolverRayPPOTrainer-774"><span class="linenos"> 774</span></a>
</span><span id="AgentEvolverRayPPOTrainer-775"><a href="#AgentEvolverRayPPOTrainer-775"><span class="linenos"> 775</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[validate_config] All configuration checks passed successfully!&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-776"><a href="#AgentEvolverRayPPOTrainer-776"><span class="linenos"> 776</span></a>
</span><span id="AgentEvolverRayPPOTrainer-777"><a href="#AgentEvolverRayPPOTrainer-777"><span class="linenos"> 777</span></a>    <span class="c1">##################</span>
</span><span id="AgentEvolverRayPPOTrainer-778"><a href="#AgentEvolverRayPPOTrainer-778"><span class="linenos"> 778</span></a>    <span class="c1"># ANNI</span>
</span><span id="AgentEvolverRayPPOTrainer-779"><a href="#AgentEvolverRayPPOTrainer-779"><span class="linenos"> 779</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_dump_generations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span><span class="p">,</span> <span class="n">dump_path</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-780"><a href="#AgentEvolverRayPPOTrainer-780"><span class="linenos"> 780</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-781"><a href="#AgentEvolverRayPPOTrainer-781"><span class="linenos"> 781</span></a><span class="sd">        Dumps rollout/validation samples as JSONL.</span>
</span><span id="AgentEvolverRayPPOTrainer-782"><a href="#AgentEvolverRayPPOTrainer-782"><span class="linenos"> 782</span></a>
</span><span id="AgentEvolverRayPPOTrainer-783"><a href="#AgentEvolverRayPPOTrainer-783"><span class="linenos"> 783</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer-784"><a href="#AgentEvolverRayPPOTrainer-784"><span class="linenos"> 784</span></a><span class="sd">            inputs (list): List of input data.</span>
</span><span id="AgentEvolverRayPPOTrainer-785"><a href="#AgentEvolverRayPPOTrainer-785"><span class="linenos"> 785</span></a><span class="sd">            outputs (list): List of output data.</span>
</span><span id="AgentEvolverRayPPOTrainer-786"><a href="#AgentEvolverRayPPOTrainer-786"><span class="linenos"> 786</span></a><span class="sd">            scores (list): List of score data.</span>
</span><span id="AgentEvolverRayPPOTrainer-787"><a href="#AgentEvolverRayPPOTrainer-787"><span class="linenos"> 787</span></a><span class="sd">            reward_extra_infos_dict (dict): Dictionary containing additional reward information.</span>
</span><span id="AgentEvolverRayPPOTrainer-788"><a href="#AgentEvolverRayPPOTrainer-788"><span class="linenos"> 788</span></a><span class="sd">            dump_path (str): Path to the directory where the JSONL file will be saved.</span>
</span><span id="AgentEvolverRayPPOTrainer-789"><a href="#AgentEvolverRayPPOTrainer-789"><span class="linenos"> 789</span></a>
</span><span id="AgentEvolverRayPPOTrainer-790"><a href="#AgentEvolverRayPPOTrainer-790"><span class="linenos"> 790</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer-791"><a href="#AgentEvolverRayPPOTrainer-791"><span class="linenos"> 791</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-792"><a href="#AgentEvolverRayPPOTrainer-792"><span class="linenos"> 792</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-793"><a href="#AgentEvolverRayPPOTrainer-793"><span class="linenos"> 793</span></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dump_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-794"><a href="#AgentEvolverRayPPOTrainer-794"><span class="linenos"> 794</span></a>        <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dump_path</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create the filename for the JSONL file</span>
</span><span id="AgentEvolverRayPPOTrainer-795"><a href="#AgentEvolverRayPPOTrainer-795"><span class="linenos"> 795</span></a>
</span><span id="AgentEvolverRayPPOTrainer-796"><a href="#AgentEvolverRayPPOTrainer-796"><span class="linenos"> 796</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-797"><a href="#AgentEvolverRayPPOTrainer-797"><span class="linenos"> 797</span></a>        <span class="n">base_data</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-798"><a href="#AgentEvolverRayPPOTrainer-798"><span class="linenos"> 798</span></a>            <span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-799"><a href="#AgentEvolverRayPPOTrainer-799"><span class="linenos"> 799</span></a>            <span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">outputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-800"><a href="#AgentEvolverRayPPOTrainer-800"><span class="linenos"> 800</span></a>            <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">scores</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-801"><a href="#AgentEvolverRayPPOTrainer-801"><span class="linenos"> 801</span></a>            <span class="s2">&quot;step&quot;</span><span class="p">:</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-802"><a href="#AgentEvolverRayPPOTrainer-802"><span class="linenos"> 802</span></a>        <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-803"><a href="#AgentEvolverRayPPOTrainer-803"><span class="linenos"> 803</span></a>
</span><span id="AgentEvolverRayPPOTrainer-804"><a href="#AgentEvolverRayPPOTrainer-804"><span class="linenos"> 804</span></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-805"><a href="#AgentEvolverRayPPOTrainer-805"><span class="linenos"> 805</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-806"><a href="#AgentEvolverRayPPOTrainer-806"><span class="linenos"> 806</span></a>                <span class="n">base_data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
</span><span id="AgentEvolverRayPPOTrainer-807"><a href="#AgentEvolverRayPPOTrainer-807"><span class="linenos"> 807</span></a>
</span><span id="AgentEvolverRayPPOTrainer-808"><a href="#AgentEvolverRayPPOTrainer-808"><span class="linenos"> 808</span></a>        <span class="n">lines</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-809"><a href="#AgentEvolverRayPPOTrainer-809"><span class="linenos"> 809</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-810"><a href="#AgentEvolverRayPPOTrainer-810"><span class="linenos"> 810</span></a>            <span class="n">entry</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">base_data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="AgentEvolverRayPPOTrainer-811"><a href="#AgentEvolverRayPPOTrainer-811"><span class="linenos"> 811</span></a>            <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer-812"><a href="#AgentEvolverRayPPOTrainer-812"><span class="linenos"> 812</span></a>
</span><span id="AgentEvolverRayPPOTrainer-813"><a href="#AgentEvolverRayPPOTrainer-813"><span class="linenos"> 813</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-814"><a href="#AgentEvolverRayPPOTrainer-814"><span class="linenos"> 814</span></a>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Write the data to the JSONL file</span>
</span><span id="AgentEvolverRayPPOTrainer-815"><a href="#AgentEvolverRayPPOTrainer-815"><span class="linenos"> 815</span></a>
</span><span id="AgentEvolverRayPPOTrainer-816"><a href="#AgentEvolverRayPPOTrainer-816"><span class="linenos"> 816</span></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dumped generations to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-817"><a href="#AgentEvolverRayPPOTrainer-817"><span class="linenos"> 817</span></a>
</span><span id="AgentEvolverRayPPOTrainer-818"><a href="#AgentEvolverRayPPOTrainer-818"><span class="linenos"> 818</span></a>
</span><span id="AgentEvolverRayPPOTrainer-819"><a href="#AgentEvolverRayPPOTrainer-819"><span class="linenos"> 819</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-820"><a href="#AgentEvolverRayPPOTrainer-820"><span class="linenos"> 820</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-821"><a href="#AgentEvolverRayPPOTrainer-821"><span class="linenos"> 821</span></a><span class="sd">        Validates the model by generating sequences, collecting samples, and storing the results.</span>
</span><span id="AgentEvolverRayPPOTrainer-822"><a href="#AgentEvolverRayPPOTrainer-822"><span class="linenos"> 822</span></a>
</span><span id="AgentEvolverRayPPOTrainer-823"><a href="#AgentEvolverRayPPOTrainer-823"><span class="linenos"> 823</span></a><span class="sd">        This function processes each batch of validation data, generates outputs, and collects</span>
</span><span id="AgentEvolverRayPPOTrainer-824"><a href="#AgentEvolverRayPPOTrainer-824"><span class="linenos"> 824</span></a><span class="sd">        input, output, and experience information for further analysis.</span>
</span><span id="AgentEvolverRayPPOTrainer-825"><a href="#AgentEvolverRayPPOTrainer-825"><span class="linenos"> 825</span></a>
</span><span id="AgentEvolverRayPPOTrainer-826"><a href="#AgentEvolverRayPPOTrainer-826"><span class="linenos"> 826</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer-827"><a href="#AgentEvolverRayPPOTrainer-827"><span class="linenos"> 827</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-828"><a href="#AgentEvolverRayPPOTrainer-828"><span class="linenos"> 828</span></a>
</span><span id="AgentEvolverRayPPOTrainer-829"><a href="#AgentEvolverRayPPOTrainer-829"><span class="linenos"> 829</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer-830"><a href="#AgentEvolverRayPPOTrainer-830"><span class="linenos"> 830</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer-831"><a href="#AgentEvolverRayPPOTrainer-831"><span class="linenos"> 831</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-832"><a href="#AgentEvolverRayPPOTrainer-832"><span class="linenos"> 832</span></a>        <span class="n">data_source_lst</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-833"><a href="#AgentEvolverRayPPOTrainer-833"><span class="linenos"> 833</span></a>        <span class="n">reward_extra_infos_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-834"><a href="#AgentEvolverRayPPOTrainer-834"><span class="linenos"> 834</span></a>
</span><span id="AgentEvolverRayPPOTrainer-835"><a href="#AgentEvolverRayPPOTrainer-835"><span class="linenos"> 835</span></a>        <span class="c1"># Lists to collect samples for the table</span>
</span><span id="AgentEvolverRayPPOTrainer-836"><a href="#AgentEvolverRayPPOTrainer-836"><span class="linenos"> 836</span></a>        <span class="n">sample_inputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-837"><a href="#AgentEvolverRayPPOTrainer-837"><span class="linenos"> 837</span></a>        <span class="n">sample_outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-838"><a href="#AgentEvolverRayPPOTrainer-838"><span class="linenos"> 838</span></a>        <span class="n">sample_scores</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-839"><a href="#AgentEvolverRayPPOTrainer-839"><span class="linenos"> 839</span></a>
</span><span id="AgentEvolverRayPPOTrainer-840"><a href="#AgentEvolverRayPPOTrainer-840"><span class="linenos"> 840</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-841"><a href="#AgentEvolverRayPPOTrainer-841"><span class="linenos"> 841</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-842"><a href="#AgentEvolverRayPPOTrainer-842"><span class="linenos"> 842</span></a>
</span><span id="AgentEvolverRayPPOTrainer-843"><a href="#AgentEvolverRayPPOTrainer-843"><span class="linenos"> 843</span></a>            <span class="c1"># repeat test batch</span>
</span><span id="AgentEvolverRayPPOTrainer-844"><a href="#AgentEvolverRayPPOTrainer-844"><span class="linenos"> 844</span></a>            <span class="c1"># test_batch = test_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.val_kwargs.n, interleave=True)</span>
</span><span id="AgentEvolverRayPPOTrainer-845"><a href="#AgentEvolverRayPPOTrainer-845"><span class="linenos"> 845</span></a>
</span><span id="AgentEvolverRayPPOTrainer-846"><a href="#AgentEvolverRayPPOTrainer-846"><span class="linenos"> 846</span></a>            <span class="c1"># we only do validation on rule-based rm</span>
</span><span id="AgentEvolverRayPPOTrainer-847"><a href="#AgentEvolverRayPPOTrainer-847"><span class="linenos"> 847</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-848"><a href="#AgentEvolverRayPPOTrainer-848"><span class="linenos"> 848</span></a>                <span class="k">return</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-849"><a href="#AgentEvolverRayPPOTrainer-849"><span class="linenos"> 849</span></a>
</span><span id="AgentEvolverRayPPOTrainer-850"><a href="#AgentEvolverRayPPOTrainer-850"><span class="linenos"> 850</span></a>            <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-851"><a href="#AgentEvolverRayPPOTrainer-851"><span class="linenos"> 851</span></a>            <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-852"><a href="#AgentEvolverRayPPOTrainer-852"><span class="linenos"> 852</span></a>            <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-853"><a href="#AgentEvolverRayPPOTrainer-853"><span class="linenos"> 853</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-854"><a href="#AgentEvolverRayPPOTrainer-854"><span class="linenos"> 854</span></a>            <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-855"><a href="#AgentEvolverRayPPOTrainer-855"><span class="linenos"> 855</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-856"><a href="#AgentEvolverRayPPOTrainer-856"><span class="linenos"> 856</span></a>            <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-857"><a href="#AgentEvolverRayPPOTrainer-857"><span class="linenos"> 857</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-858"><a href="#AgentEvolverRayPPOTrainer-858"><span class="linenos"> 858</span></a>            <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-859"><a href="#AgentEvolverRayPPOTrainer-859"><span class="linenos"> 859</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-860"><a href="#AgentEvolverRayPPOTrainer-860"><span class="linenos"> 860</span></a>            <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-861"><a href="#AgentEvolverRayPPOTrainer-861"><span class="linenos"> 861</span></a>                <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-862"><a href="#AgentEvolverRayPPOTrainer-862"><span class="linenos"> 862</span></a>                <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-863"><a href="#AgentEvolverRayPPOTrainer-863"><span class="linenos"> 863</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-864"><a href="#AgentEvolverRayPPOTrainer-864"><span class="linenos"> 864</span></a>
</span><span id="AgentEvolverRayPPOTrainer-865"><a href="#AgentEvolverRayPPOTrainer-865"><span class="linenos"> 865</span></a>            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-866"><a href="#AgentEvolverRayPPOTrainer-866"><span class="linenos"> 866</span></a>                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-867"><a href="#AgentEvolverRayPPOTrainer-867"><span class="linenos"> 867</span></a>                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-868"><a href="#AgentEvolverRayPPOTrainer-868"><span class="linenos"> 868</span></a>                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-869"><a href="#AgentEvolverRayPPOTrainer-869"><span class="linenos"> 869</span></a>                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-870"><a href="#AgentEvolverRayPPOTrainer-870"><span class="linenos"> 870</span></a>                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-871"><a href="#AgentEvolverRayPPOTrainer-871"><span class="linenos"> 871</span></a>            <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-872"><a href="#AgentEvolverRayPPOTrainer-872"><span class="linenos"> 872</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_gen_batch meta info: </span><span class="si">{</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-873"><a href="#AgentEvolverRayPPOTrainer-873"><span class="linenos"> 873</span></a>
</span><span id="AgentEvolverRayPPOTrainer-874"><a href="#AgentEvolverRayPPOTrainer-874"><span class="linenos"> 874</span></a>            <span class="c1"># pad to be divisible by dp_size</span>
</span><span id="AgentEvolverRayPPOTrainer-875"><a href="#AgentEvolverRayPPOTrainer-875"><span class="linenos"> 875</span></a>            <span class="c1"># test_gen_batch_padded, pad_size = pad_dataproto_to_divisor(test_gen_batch, self.actor_rollout_wg.world_size)</span>
</span><span id="AgentEvolverRayPPOTrainer-876"><a href="#AgentEvolverRayPPOTrainer-876"><span class="linenos"> 876</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-877"><a href="#AgentEvolverRayPPOTrainer-877"><span class="linenos"> 877</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer-878"><a href="#AgentEvolverRayPPOTrainer-878"><span class="linenos"> 878</span></a>
</span><span id="AgentEvolverRayPPOTrainer-879"><a href="#AgentEvolverRayPPOTrainer-879"><span class="linenos"> 879</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-880"><a href="#AgentEvolverRayPPOTrainer-880"><span class="linenos"> 880</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-881"><a href="#AgentEvolverRayPPOTrainer-881"><span class="linenos"> 881</span></a>                <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-882"><a href="#AgentEvolverRayPPOTrainer-882"><span class="linenos"> 882</span></a>                            <span class="n">task_id</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-883"><a href="#AgentEvolverRayPPOTrainer-883"><span class="linenos"> 883</span></a>                            <span class="n">query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-884"><a href="#AgentEvolverRayPPOTrainer-884"><span class="linenos"> 884</span></a>                            <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-885"><a href="#AgentEvolverRayPPOTrainer-885"><span class="linenos"> 885</span></a>                            <span class="n">open_query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-886"><a href="#AgentEvolverRayPPOTrainer-886"><span class="linenos"> 886</span></a>                            <span class="c1"># evaluator=gen_batch.non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;], # avoid potential bugs</span>
</span><span id="AgentEvolverRayPPOTrainer-887"><a href="#AgentEvolverRayPPOTrainer-887"><span class="linenos"> 887</span></a>                         <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_gen_batch</span><span class="p">))]</span>
</span><span id="AgentEvolverRayPPOTrainer-888"><a href="#AgentEvolverRayPPOTrainer-888"><span class="linenos"> 888</span></a>                <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-889"><a href="#AgentEvolverRayPPOTrainer-889"><span class="linenos"> 889</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-890"><a href="#AgentEvolverRayPPOTrainer-890"><span class="linenos"> 890</span></a>                <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test.1.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Execute the rollout to generate trajectories</span>
</span><span id="AgentEvolverRayPPOTrainer-891"><a href="#AgentEvolverRayPPOTrainer-891"><span class="linenos"> 891</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-892"><a href="#AgentEvolverRayPPOTrainer-892"><span class="linenos"> 892</span></a>                <span class="n">test_output_gen_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">to_dataproto</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-893"><a href="#AgentEvolverRayPPOTrainer-893"><span class="linenos"> 893</span></a>                <span class="c1"># test_output_gen_batch_padded = self.explorer_manager.rollout(test_gen_batch_padded)</span>
</span><span id="AgentEvolverRayPPOTrainer-894"><a href="#AgentEvolverRayPPOTrainer-894"><span class="linenos"> 894</span></a>                <span class="c1"># test_output_gen_batch_padded = self.async_rollout_manager.generate_sequences(test_gen_batch_padded)</span>
</span><span id="AgentEvolverRayPPOTrainer-895"><a href="#AgentEvolverRayPPOTrainer-895"><span class="linenos"> 895</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-896"><a href="#AgentEvolverRayPPOTrainer-896"><span class="linenos"> 896</span></a>
</span><span id="AgentEvolverRayPPOTrainer-897"><a href="#AgentEvolverRayPPOTrainer-897"><span class="linenos"> 897</span></a>            <span class="c1"># unpad</span>
</span><span id="AgentEvolverRayPPOTrainer-898"><a href="#AgentEvolverRayPPOTrainer-898"><span class="linenos"> 898</span></a>            <span class="c1"># test_output_gen_batch = unpad_dataproto(test_output_gen_batch_padded, pad_size=pad_size)</span>
</span><span id="AgentEvolverRayPPOTrainer-899"><a href="#AgentEvolverRayPPOTrainer-899"><span class="linenos"> 899</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;validation generation end&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-900"><a href="#AgentEvolverRayPPOTrainer-900"><span class="linenos"> 900</span></a>
</span><span id="AgentEvolverRayPPOTrainer-901"><a href="#AgentEvolverRayPPOTrainer-901"><span class="linenos"> 901</span></a>            <span class="c1"># Store original inputs</span>
</span><span id="AgentEvolverRayPPOTrainer-902"><a href="#AgentEvolverRayPPOTrainer-902"><span class="linenos"> 902</span></a>            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">test_output_gen_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-903"><a href="#AgentEvolverRayPPOTrainer-903"><span class="linenos"> 903</span></a>            <span class="c1"># TODO: Can we keep special tokens except for padding tokens?</span>
</span><span id="AgentEvolverRayPPOTrainer-904"><a href="#AgentEvolverRayPPOTrainer-904"><span class="linenos"> 904</span></a>            <span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-905"><a href="#AgentEvolverRayPPOTrainer-905"><span class="linenos"> 905</span></a>            <span class="n">sample_inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-906"><a href="#AgentEvolverRayPPOTrainer-906"><span class="linenos"> 906</span></a>
</span><span id="AgentEvolverRayPPOTrainer-907"><a href="#AgentEvolverRayPPOTrainer-907"><span class="linenos"> 907</span></a>            <span class="c1"># Store generated outputs</span>
</span><span id="AgentEvolverRayPPOTrainer-908"><a href="#AgentEvolverRayPPOTrainer-908"><span class="linenos"> 908</span></a>            <span class="n">output_ids</span> <span class="o">=</span> <span class="n">test_output_gen_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-909"><a href="#AgentEvolverRayPPOTrainer-909"><span class="linenos"> 909</span></a>            <span class="n">output_texts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">output_ids</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-910"><a href="#AgentEvolverRayPPOTrainer-910"><span class="linenos"> 910</span></a>            <span class="n">sample_outputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output_texts</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-911"><a href="#AgentEvolverRayPPOTrainer-911"><span class="linenos"> 911</span></a>
</span><span id="AgentEvolverRayPPOTrainer-912"><a href="#AgentEvolverRayPPOTrainer-912"><span class="linenos"> 912</span></a>            <span class="c1"># repeat test batch</span>
</span><span id="AgentEvolverRayPPOTrainer-913"><a href="#AgentEvolverRayPPOTrainer-913"><span class="linenos"> 913</span></a>            <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-914"><a href="#AgentEvolverRayPPOTrainer-914"><span class="linenos"> 914</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">test_batch</span><span class="p">,</span> <span class="n">test_output_gen_batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-915"><a href="#AgentEvolverRayPPOTrainer-915"><span class="linenos"> 915</span></a>            <span class="n">test_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;validate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="AgentEvolverRayPPOTrainer-916"><a href="#AgentEvolverRayPPOTrainer-916"><span class="linenos"> 916</span></a>
</span><span id="AgentEvolverRayPPOTrainer-917"><a href="#AgentEvolverRayPPOTrainer-917"><span class="linenos"> 917</span></a>            <span class="c1"># test_batch = test_batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.val_kwargs.n, interleave=True)</span>
</span><span id="AgentEvolverRayPPOTrainer-918"><a href="#AgentEvolverRayPPOTrainer-918"><span class="linenos"> 918</span></a>            <span class="c1"># test_batch = test_batch.union(test_output_gen_batch)</span>
</span><span id="AgentEvolverRayPPOTrainer-919"><a href="#AgentEvolverRayPPOTrainer-919"><span class="linenos"> 919</span></a>
</span><span id="AgentEvolverRayPPOTrainer-920"><a href="#AgentEvolverRayPPOTrainer-920"><span class="linenos"> 920</span></a>            <span class="c1"># evaluate using reward_function</span>
</span><span id="AgentEvolverRayPPOTrainer-921"><a href="#AgentEvolverRayPPOTrainer-921"><span class="linenos"> 921</span></a>            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># ‚≠ê Evaluate the test batch using the reward function</span>
</span><span id="AgentEvolverRayPPOTrainer-922"><a href="#AgentEvolverRayPPOTrainer-922"><span class="linenos"> 922</span></a>            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reward_tensor&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-923"><a href="#AgentEvolverRayPPOTrainer-923"><span class="linenos"> 923</span></a>            <span class="n">scores</span> <span class="o">=</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-924"><a href="#AgentEvolverRayPPOTrainer-924"><span class="linenos"> 924</span></a>            <span class="n">sample_scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-925"><a href="#AgentEvolverRayPPOTrainer-925"><span class="linenos"> 925</span></a>
</span><span id="AgentEvolverRayPPOTrainer-926"><a href="#AgentEvolverRayPPOTrainer-926"><span class="linenos"> 926</span></a>            <span class="n">reward_extra_infos_dict</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-927"><a href="#AgentEvolverRayPPOTrainer-927"><span class="linenos"> 927</span></a>            <span class="k">if</span> <span class="s2">&quot;reward_extra_info&quot;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-928"><a href="#AgentEvolverRayPPOTrainer-928"><span class="linenos"> 928</span></a>                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reward_extra_info&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-929"><a href="#AgentEvolverRayPPOTrainer-929"><span class="linenos"> 929</span></a>                    <span class="n">reward_extra_infos_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-930"><a href="#AgentEvolverRayPPOTrainer-930"><span class="linenos"> 930</span></a>
</span><span id="AgentEvolverRayPPOTrainer-931"><a href="#AgentEvolverRayPPOTrainer-931"><span class="linenos"> 931</span></a>            <span class="n">data_source_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;data_source&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;unknown&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">reward_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</span><span id="AgentEvolverRayPPOTrainer-932"><a href="#AgentEvolverRayPPOTrainer-932"><span class="linenos"> 932</span></a>
</span><span id="AgentEvolverRayPPOTrainer-933"><a href="#AgentEvolverRayPPOTrainer-933"><span class="linenos"> 933</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_log_val_generations</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">sample_outputs</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">sample_scores</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-934"><a href="#AgentEvolverRayPPOTrainer-934"><span class="linenos"> 934</span></a>
</span><span id="AgentEvolverRayPPOTrainer-935"><a href="#AgentEvolverRayPPOTrainer-935"><span class="linenos"> 935</span></a>        <span class="c1"># dump generations</span>
</span><span id="AgentEvolverRayPPOTrainer-936"><a href="#AgentEvolverRayPPOTrainer-936"><span class="linenos"> 936</span></a>        <span class="n">val_data_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation_data_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-937"><a href="#AgentEvolverRayPPOTrainer-937"><span class="linenos"> 937</span></a>        <span class="c1"># val_data_dir = &quot;experiments/validation_log&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-938"><a href="#AgentEvolverRayPPOTrainer-938"><span class="linenos"> 938</span></a>        <span class="k">if</span> <span class="n">val_data_dir</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-939"><a href="#AgentEvolverRayPPOTrainer-939"><span class="linenos"> 939</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dump_generations</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-940"><a href="#AgentEvolverRayPPOTrainer-940"><span class="linenos"> 940</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="n">sample_inputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-941"><a href="#AgentEvolverRayPPOTrainer-941"><span class="linenos"> 941</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="n">sample_outputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-942"><a href="#AgentEvolverRayPPOTrainer-942"><span class="linenos"> 942</span></a>                <span class="n">scores</span><span class="o">=</span><span class="n">sample_scores</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-943"><a href="#AgentEvolverRayPPOTrainer-943"><span class="linenos"> 943</span></a>                <span class="n">reward_extra_infos_dict</span><span class="o">=</span><span class="n">reward_extra_infos_dict</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-944"><a href="#AgentEvolverRayPPOTrainer-944"><span class="linenos"> 944</span></a>                <span class="n">dump_path</span><span class="o">=</span><span class="n">val_data_dir</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-945"><a href="#AgentEvolverRayPPOTrainer-945"><span class="linenos"> 945</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-946"><a href="#AgentEvolverRayPPOTrainer-946"><span class="linenos"> 946</span></a>
</span><span id="AgentEvolverRayPPOTrainer-947"><a href="#AgentEvolverRayPPOTrainer-947"><span class="linenos"> 947</span></a>        <span class="k">for</span> <span class="n">key_info</span><span class="p">,</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-948"><a href="#AgentEvolverRayPPOTrainer-948"><span class="linenos"> 948</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_scores</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_info</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_scores</span><span class="p">)</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-949"><a href="#AgentEvolverRayPPOTrainer-949"><span class="linenos"> 949</span></a>
</span><span id="AgentEvolverRayPPOTrainer-950"><a href="#AgentEvolverRayPPOTrainer-950"><span class="linenos"> 950</span></a>        <span class="n">data_sources</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">data_source_lst</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-951"><a href="#AgentEvolverRayPPOTrainer-951"><span class="linenos"> 951</span></a>
</span><span id="AgentEvolverRayPPOTrainer-952"><a href="#AgentEvolverRayPPOTrainer-952"><span class="linenos"> 952</span></a>        <span class="n">data_src2var2metric2val</span> <span class="o">=</span> <span class="n">process_validation_metrics</span><span class="p">(</span><span class="n">data_sources</span><span class="p">,</span> <span class="n">sample_inputs</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span><span class="p">)</span>  <span class="c1"># ‚≠ê Process the validation metrics for different data sources</span>
</span><span id="AgentEvolverRayPPOTrainer-953"><a href="#AgentEvolverRayPPOTrainer-953"><span class="linenos"> 953</span></a>        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-954"><a href="#AgentEvolverRayPPOTrainer-954"><span class="linenos"> 954</span></a>        <span class="k">for</span> <span class="n">data_source</span><span class="p">,</span> <span class="n">var2metric2val</span> <span class="ow">in</span> <span class="n">data_src2var2metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-955"><a href="#AgentEvolverRayPPOTrainer-955"><span class="linenos"> 955</span></a>            <span class="n">core_var</span> <span class="o">=</span> <span class="s2">&quot;acc&quot;</span> <span class="k">if</span> <span class="s2">&quot;acc&quot;</span> <span class="ow">in</span> <span class="n">var2metric2val</span> <span class="k">else</span> <span class="s2">&quot;reward&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-956"><a href="#AgentEvolverRayPPOTrainer-956"><span class="linenos"> 956</span></a>            <span class="k">for</span> <span class="n">var_name</span><span class="p">,</span> <span class="n">metric2val</span> <span class="ow">in</span> <span class="n">var2metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-957"><a href="#AgentEvolverRayPPOTrainer-957"><span class="linenos"> 957</span></a>                <span class="n">n_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;@&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">metric2val</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span>
</span><span id="AgentEvolverRayPPOTrainer-958"><a href="#AgentEvolverRayPPOTrainer-958"><span class="linenos"> 958</span></a>                <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_val</span> <span class="ow">in</span> <span class="n">metric2val</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-959"><a href="#AgentEvolverRayPPOTrainer-959"><span class="linenos"> 959</span></a>                    <span class="k">if</span> <span class="p">(</span><span class="n">var_name</span> <span class="o">==</span> <span class="n">core_var</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">metric_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">pfx</span><span class="p">)</span> <span class="k">for</span> <span class="n">pfx</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;maj&quot;</span><span class="p">,</span> <span class="s2">&quot;best&quot;</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;@</span><span class="si">{</span><span class="n">n_max</span><span class="si">}</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">metric_name</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-960"><a href="#AgentEvolverRayPPOTrainer-960"><span class="linenos"> 960</span></a>                        <span class="n">metric_sec</span> <span class="o">=</span> <span class="s2">&quot;val-core&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-961"><a href="#AgentEvolverRayPPOTrainer-961"><span class="linenos"> 961</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-962"><a href="#AgentEvolverRayPPOTrainer-962"><span class="linenos"> 962</span></a>                        <span class="n">metric_sec</span> <span class="o">=</span> <span class="s2">&quot;val-aux&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-963"><a href="#AgentEvolverRayPPOTrainer-963"><span class="linenos"> 963</span></a>                    <span class="n">pfx</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric_sec</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">data_source</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">var_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-964"><a href="#AgentEvolverRayPPOTrainer-964"><span class="linenos"> 964</span></a>                    <span class="n">metric_dict</span><span class="p">[</span><span class="n">pfx</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric_val</span>
</span><span id="AgentEvolverRayPPOTrainer-965"><a href="#AgentEvolverRayPPOTrainer-965"><span class="linenos"> 965</span></a>
</span><span id="AgentEvolverRayPPOTrainer-966"><a href="#AgentEvolverRayPPOTrainer-966"><span class="linenos"> 966</span></a>        <span class="k">return</span> <span class="n">metric_dict</span>
</span><span id="AgentEvolverRayPPOTrainer-967"><a href="#AgentEvolverRayPPOTrainer-967"><span class="linenos"> 967</span></a>    
</span><span id="AgentEvolverRayPPOTrainer-968"><a href="#AgentEvolverRayPPOTrainer-968"><span class="linenos"> 968</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_exp_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-969"><a href="#AgentEvolverRayPPOTrainer-969"><span class="linenos"> 969</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-970"><a href="#AgentEvolverRayPPOTrainer-970"><span class="linenos"> 970</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-971"><a href="#AgentEvolverRayPPOTrainer-971"><span class="linenos"> 971</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-972"><a href="#AgentEvolverRayPPOTrainer-972"><span class="linenos"> 972</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-973"><a href="#AgentEvolverRayPPOTrainer-973"><span class="linenos"> 973</span></a>
</span><span id="AgentEvolverRayPPOTrainer-974"><a href="#AgentEvolverRayPPOTrainer-974"><span class="linenos"> 974</span></a>            <span class="c1"># we only do validation on rule-based rm</span>
</span><span id="AgentEvolverRayPPOTrainer-975"><a href="#AgentEvolverRayPPOTrainer-975"><span class="linenos"> 975</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-976"><a href="#AgentEvolverRayPPOTrainer-976"><span class="linenos"> 976</span></a>                <span class="k">return</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-977"><a href="#AgentEvolverRayPPOTrainer-977"><span class="linenos"> 977</span></a>
</span><span id="AgentEvolverRayPPOTrainer-978"><a href="#AgentEvolverRayPPOTrainer-978"><span class="linenos"> 978</span></a>            <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-979"><a href="#AgentEvolverRayPPOTrainer-979"><span class="linenos"> 979</span></a>            <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-980"><a href="#AgentEvolverRayPPOTrainer-980"><span class="linenos"> 980</span></a>            <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-981"><a href="#AgentEvolverRayPPOTrainer-981"><span class="linenos"> 981</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-982"><a href="#AgentEvolverRayPPOTrainer-982"><span class="linenos"> 982</span></a>            <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-983"><a href="#AgentEvolverRayPPOTrainer-983"><span class="linenos"> 983</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-984"><a href="#AgentEvolverRayPPOTrainer-984"><span class="linenos"> 984</span></a>            <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-985"><a href="#AgentEvolverRayPPOTrainer-985"><span class="linenos"> 985</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-986"><a href="#AgentEvolverRayPPOTrainer-986"><span class="linenos"> 986</span></a>            <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-987"><a href="#AgentEvolverRayPPOTrainer-987"><span class="linenos"> 987</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-988"><a href="#AgentEvolverRayPPOTrainer-988"><span class="linenos"> 988</span></a>            <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-989"><a href="#AgentEvolverRayPPOTrainer-989"><span class="linenos"> 989</span></a>                <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-990"><a href="#AgentEvolverRayPPOTrainer-990"><span class="linenos"> 990</span></a>                <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-991"><a href="#AgentEvolverRayPPOTrainer-991"><span class="linenos"> 991</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-992"><a href="#AgentEvolverRayPPOTrainer-992"><span class="linenos"> 992</span></a>
</span><span id="AgentEvolverRayPPOTrainer-993"><a href="#AgentEvolverRayPPOTrainer-993"><span class="linenos"> 993</span></a>            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-994"><a href="#AgentEvolverRayPPOTrainer-994"><span class="linenos"> 994</span></a>                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-995"><a href="#AgentEvolverRayPPOTrainer-995"><span class="linenos"> 995</span></a>                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-996"><a href="#AgentEvolverRayPPOTrainer-996"><span class="linenos"> 996</span></a>                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-997"><a href="#AgentEvolverRayPPOTrainer-997"><span class="linenos"> 997</span></a>                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-998"><a href="#AgentEvolverRayPPOTrainer-998"><span class="linenos"> 998</span></a>                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-999"><a href="#AgentEvolverRayPPOTrainer-999"><span class="linenos"> 999</span></a>            <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-1000"><a href="#AgentEvolverRayPPOTrainer-1000"><span class="linenos">1000</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_gen_batch meta info: </span><span class="si">{</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1001"><a href="#AgentEvolverRayPPOTrainer-1001"><span class="linenos">1001</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1002"><a href="#AgentEvolverRayPPOTrainer-1002"><span class="linenos">1002</span></a>            <span class="c1"># pad to be divisible by dp_size</span>
</span><span id="AgentEvolverRayPPOTrainer-1003"><a href="#AgentEvolverRayPPOTrainer-1003"><span class="linenos">1003</span></a>            <span class="c1"># test_gen_batch_padded, pad_size = pad_dataproto_to_divisor(test_gen_batch, self.actor_rollout_wg.world_size)</span>
</span><span id="AgentEvolverRayPPOTrainer-1004"><a href="#AgentEvolverRayPPOTrainer-1004"><span class="linenos">1004</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1005"><a href="#AgentEvolverRayPPOTrainer-1005"><span class="linenos">1005</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer-1006"><a href="#AgentEvolverRayPPOTrainer-1006"><span class="linenos">1006</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1007"><a href="#AgentEvolverRayPPOTrainer-1007"><span class="linenos">1007</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1008"><a href="#AgentEvolverRayPPOTrainer-1008"><span class="linenos">1008</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1009"><a href="#AgentEvolverRayPPOTrainer-1009"><span class="linenos">1009</span></a>                <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1010"><a href="#AgentEvolverRayPPOTrainer-1010"><span class="linenos">1010</span></a>                            <span class="n">task_id</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1011"><a href="#AgentEvolverRayPPOTrainer-1011"><span class="linenos">1011</span></a>                            <span class="n">query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1012"><a href="#AgentEvolverRayPPOTrainer-1012"><span class="linenos">1012</span></a>                            <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1013"><a href="#AgentEvolverRayPPOTrainer-1013"><span class="linenos">1013</span></a>                            <span class="n">open_query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1014"><a href="#AgentEvolverRayPPOTrainer-1014"><span class="linenos">1014</span></a>                            <span class="c1"># evaluator=gen_batch.non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;], # avoid potential bugs</span>
</span><span id="AgentEvolverRayPPOTrainer-1015"><a href="#AgentEvolverRayPPOTrainer-1015"><span class="linenos">1015</span></a>                         <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_gen_batch</span><span class="p">))]</span>
</span><span id="AgentEvolverRayPPOTrainer-1016"><a href="#AgentEvolverRayPPOTrainer-1016"><span class="linenos">1016</span></a>                <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1017"><a href="#AgentEvolverRayPPOTrainer-1017"><span class="linenos">1017</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1018"><a href="#AgentEvolverRayPPOTrainer-1018"><span class="linenos">1018</span></a>                <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test.1.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Execute the rollout to generate trajectories</span>
</span><span id="AgentEvolverRayPPOTrainer-1019"><a href="#AgentEvolverRayPPOTrainer-1019"><span class="linenos">1019</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1020"><a href="#AgentEvolverRayPPOTrainer-1020"><span class="linenos">1020</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1021"><a href="#AgentEvolverRayPPOTrainer-1021"><span class="linenos">1021</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1022"><a href="#AgentEvolverRayPPOTrainer-1022"><span class="linenos">1022</span></a>            <span class="c1"># summarize in batch: updating experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer-1023"><a href="#AgentEvolverRayPPOTrainer-1023"><span class="linenos">1023</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">summarize_in_batch</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1024"><a href="#AgentEvolverRayPPOTrainer-1024"><span class="linenos">1024</span></a>        
</span><span id="AgentEvolverRayPPOTrainer-1025"><a href="#AgentEvolverRayPPOTrainer-1025"><span class="linenos">1025</span></a>        <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer-1026"><a href="#AgentEvolverRayPPOTrainer-1026"><span class="linenos">1026</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1027"><a href="#AgentEvolverRayPPOTrainer-1027"><span class="linenos">1027</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1028"><a href="#AgentEvolverRayPPOTrainer-1028"><span class="linenos">1028</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1029"><a href="#AgentEvolverRayPPOTrainer-1029"><span class="linenos">1029</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1030"><a href="#AgentEvolverRayPPOTrainer-1030"><span class="linenos">1030</span></a><span class="sd">        The training loop of PPO.</span>
</span><span id="AgentEvolverRayPPOTrainer-1031"><a href="#AgentEvolverRayPPOTrainer-1031"><span class="linenos">1031</span></a><span class="sd">        The driver process only need to call the compute functions of the worker group through RPC</span>
</span><span id="AgentEvolverRayPPOTrainer-1032"><a href="#AgentEvolverRayPPOTrainer-1032"><span class="linenos">1032</span></a><span class="sd">        to construct the PPO dataflow.</span>
</span><span id="AgentEvolverRayPPOTrainer-1033"><a href="#AgentEvolverRayPPOTrainer-1033"><span class="linenos">1033</span></a><span class="sd">        The light-weight advantage computation is done on the driver process.</span>
</span><span id="AgentEvolverRayPPOTrainer-1034"><a href="#AgentEvolverRayPPOTrainer-1034"><span class="linenos">1034</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1035"><a href="#AgentEvolverRayPPOTrainer-1035"><span class="linenos">1035</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span>
</span><span id="AgentEvolverRayPPOTrainer-1036"><a href="#AgentEvolverRayPPOTrainer-1036"><span class="linenos">1036</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1037"><a href="#AgentEvolverRayPPOTrainer-1037"><span class="linenos">1037</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tracking</span>
</span><span id="AgentEvolverRayPPOTrainer-1038"><a href="#AgentEvolverRayPPOTrainer-1038"><span class="linenos">1038</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1039"><a href="#AgentEvolverRayPPOTrainer-1039"><span class="linenos">1039</span></a>        <span class="n">logger</span> <span class="o">=</span> <span class="n">Tracking</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1040"><a href="#AgentEvolverRayPPOTrainer-1040"><span class="linenos">1040</span></a>            <span class="n">project_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">project_name</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1041"><a href="#AgentEvolverRayPPOTrainer-1041"><span class="linenos">1041</span></a>            <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1042"><a href="#AgentEvolverRayPPOTrainer-1042"><span class="linenos">1042</span></a>            <span class="n">default_backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1043"><a href="#AgentEvolverRayPPOTrainer-1043"><span class="linenos">1043</span></a>            <span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-1044"><a href="#AgentEvolverRayPPOTrainer-1044"><span class="linenos">1044</span></a>        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1045"><a href="#AgentEvolverRayPPOTrainer-1045"><span class="linenos">1045</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1046"><a href="#AgentEvolverRayPPOTrainer-1046"><span class="linenos">1046</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="AgentEvolverRayPPOTrainer-1047"><a href="#AgentEvolverRayPPOTrainer-1047"><span class="linenos">1047</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1048"><a href="#AgentEvolverRayPPOTrainer-1048"><span class="linenos">1048</span></a>        <span class="c1"># load checkpoint before doing anything</span>
</span><span id="AgentEvolverRayPPOTrainer-1049"><a href="#AgentEvolverRayPPOTrainer-1049"><span class="linenos">1049</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_checkpoint</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1050"><a href="#AgentEvolverRayPPOTrainer-1050"><span class="linenos">1050</span></a>        <span class="c1"># spread parameters to vllm</span>
</span><span id="AgentEvolverRayPPOTrainer-1051"><a href="#AgentEvolverRayPPOTrainer-1051"><span class="linenos">1051</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1052"><a href="#AgentEvolverRayPPOTrainer-1052"><span class="linenos">1052</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1053"><a href="#AgentEvolverRayPPOTrainer-1053"><span class="linenos">1053</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1054"><a href="#AgentEvolverRayPPOTrainer-1054"><span class="linenos">1054</span></a>        <span class="c1"># initialize experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer-1055"><a href="#AgentEvolverRayPPOTrainer-1055"><span class="linenos">1055</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_before_training&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1056"><a href="#AgentEvolverRayPPOTrainer-1056"><span class="linenos">1056</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_exp_pool</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1057"><a href="#AgentEvolverRayPPOTrainer-1057"><span class="linenos">1057</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1058"><a href="#AgentEvolverRayPPOTrainer-1058"><span class="linenos">1058</span></a>                <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer-1059"><a href="#AgentEvolverRayPPOTrainer-1059"><span class="linenos">1059</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1060"><a href="#AgentEvolverRayPPOTrainer-1060"><span class="linenos">1060</span></a>        <span class="c1"># perform validation before training</span>
</span><span id="AgentEvolverRayPPOTrainer-1061"><a href="#AgentEvolverRayPPOTrainer-1061"><span class="linenos">1061</span></a>        <span class="c1"># currently, we only support validation using the reward_function.</span>
</span><span id="AgentEvolverRayPPOTrainer-1062"><a href="#AgentEvolverRayPPOTrainer-1062"><span class="linenos">1062</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_before_train&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1063"><a href="#AgentEvolverRayPPOTrainer-1063"><span class="linenos">1063</span></a>            <span class="n">val_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Perform initial validation and get the validation metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1064"><a href="#AgentEvolverRayPPOTrainer-1064"><span class="linenos">1064</span></a>            <span class="k">assert</span> <span class="n">val_metrics</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val_metrics</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1065"><a href="#AgentEvolverRayPPOTrainer-1065"><span class="linenos">1065</span></a>            <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial validation metrics: </span><span class="si">{</span><span class="n">val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1066"><a href="#AgentEvolverRayPPOTrainer-1066"><span class="linenos">1066</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">val_metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1067"><a href="#AgentEvolverRayPPOTrainer-1067"><span class="linenos">1067</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1068"><a href="#AgentEvolverRayPPOTrainer-1068"><span class="linenos">1068</span></a>                <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer-1069"><a href="#AgentEvolverRayPPOTrainer-1069"><span class="linenos">1069</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1070"><a href="#AgentEvolverRayPPOTrainer-1070"><span class="linenos">1070</span></a>        <span class="c1"># [0616] qingxu: add `RAY_DEBUG_POST_MORTEM` env var to activate breakpoint debugging</span>
</span><span id="AgentEvolverRayPPOTrainer-1071"><a href="#AgentEvolverRayPPOTrainer-1071"><span class="linenos">1071</span></a>        <span class="c1"># vscode_conditional_breakpoint()</span>
</span><span id="AgentEvolverRayPPOTrainer-1072"><a href="#AgentEvolverRayPPOTrainer-1072"><span class="linenos">1072</span></a>        <span class="c1"># breakpoint()</span>
</span><span id="AgentEvolverRayPPOTrainer-1073"><a href="#AgentEvolverRayPPOTrainer-1073"><span class="linenos">1073</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1074"><a href="#AgentEvolverRayPPOTrainer-1074"><span class="linenos">1074</span></a>        <span class="c1"># add tqdm</span>
</span><span id="AgentEvolverRayPPOTrainer-1075"><a href="#AgentEvolverRayPPOTrainer-1075"><span class="linenos">1075</span></a>        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Progress&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1076"><a href="#AgentEvolverRayPPOTrainer-1076"><span class="linenos">1076</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1077"><a href="#AgentEvolverRayPPOTrainer-1077"><span class="linenos">1077</span></a>        <span class="c1"># we start from step 1</span>
</span><span id="AgentEvolverRayPPOTrainer-1078"><a href="#AgentEvolverRayPPOTrainer-1078"><span class="linenos">1078</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="AgentEvolverRayPPOTrainer-1079"><a href="#AgentEvolverRayPPOTrainer-1079"><span class="linenos">1079</span></a>        <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer-1080"><a href="#AgentEvolverRayPPOTrainer-1080"><span class="linenos">1080</span></a>        
</span><span id="AgentEvolverRayPPOTrainer-1081"><a href="#AgentEvolverRayPPOTrainer-1081"><span class="linenos">1081</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1082"><a href="#AgentEvolverRayPPOTrainer-1082"><span class="linenos">1082</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1083"><a href="#AgentEvolverRayPPOTrainer-1083"><span class="linenos">1083</span></a>                <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-1084"><a href="#AgentEvolverRayPPOTrainer-1084"><span class="linenos">1084</span></a>                <span class="n">timing_raw</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer-1085"><a href="#AgentEvolverRayPPOTrainer-1085"><span class="linenos">1085</span></a>                <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1086"><a href="#AgentEvolverRayPPOTrainer-1086"><span class="linenos">1086</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1087"><a href="#AgentEvolverRayPPOTrainer-1087"><span class="linenos">1087</span></a>                <span class="c1"># pop those keys for generation</span>
</span><span id="AgentEvolverRayPPOTrainer-1088"><a href="#AgentEvolverRayPPOTrainer-1088"><span class="linenos">1088</span></a>                <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1089"><a href="#AgentEvolverRayPPOTrainer-1089"><span class="linenos">1089</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1090"><a href="#AgentEvolverRayPPOTrainer-1090"><span class="linenos">1090</span></a>                <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1091"><a href="#AgentEvolverRayPPOTrainer-1091"><span class="linenos">1091</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1092"><a href="#AgentEvolverRayPPOTrainer-1092"><span class="linenos">1092</span></a>                <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1093"><a href="#AgentEvolverRayPPOTrainer-1093"><span class="linenos">1093</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1094"><a href="#AgentEvolverRayPPOTrainer-1094"><span class="linenos">1094</span></a>                <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1095"><a href="#AgentEvolverRayPPOTrainer-1095"><span class="linenos">1095</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1096"><a href="#AgentEvolverRayPPOTrainer-1096"><span class="linenos">1096</span></a>                <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1097"><a href="#AgentEvolverRayPPOTrainer-1097"><span class="linenos">1097</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1098"><a href="#AgentEvolverRayPPOTrainer-1098"><span class="linenos">1098</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer-1099"><a href="#AgentEvolverRayPPOTrainer-1099"><span class="linenos">1099</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1100"><a href="#AgentEvolverRayPPOTrainer-1100"><span class="linenos">1100</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer-1101"><a href="#AgentEvolverRayPPOTrainer-1101"><span class="linenos">1101</span></a>                <span class="n">gen_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1102"><a href="#AgentEvolverRayPPOTrainer-1102"><span class="linenos">1102</span></a>                    <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1103"><a href="#AgentEvolverRayPPOTrainer-1103"><span class="linenos">1103</span></a>                    <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1104"><a href="#AgentEvolverRayPPOTrainer-1104"><span class="linenos">1104</span></a>                <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1105"><a href="#AgentEvolverRayPPOTrainer-1105"><span class="linenos">1105</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1106"><a href="#AgentEvolverRayPPOTrainer-1106"><span class="linenos">1106</span></a>                <span class="n">is_last_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer-1107"><a href="#AgentEvolverRayPPOTrainer-1107"><span class="linenos">1107</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1108"><a href="#AgentEvolverRayPPOTrainer-1108"><span class="linenos">1108</span></a>                <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1109"><a href="#AgentEvolverRayPPOTrainer-1109"><span class="linenos">1109</span></a>                    <span class="c1"># generate a batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1110"><a href="#AgentEvolverRayPPOTrainer-1110"><span class="linenos">1110</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1111"><a href="#AgentEvolverRayPPOTrainer-1111"><span class="linenos">1111</span></a>                        <span class="n">trajectories</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Trajectory</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer-1112"><a href="#AgentEvolverRayPPOTrainer-1112"><span class="linenos">1112</span></a>                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1113"><a href="#AgentEvolverRayPPOTrainer-1113"><span class="linenos">1113</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1114"><a href="#AgentEvolverRayPPOTrainer-1114"><span class="linenos">1114</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1115"><a href="#AgentEvolverRayPPOTrainer-1115"><span class="linenos">1115</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1116"><a href="#AgentEvolverRayPPOTrainer-1116"><span class="linenos">1116</span></a>                            <span class="c1"># gen_batch_output = self.explorer_manager.rollout(gen_batch)</span>
</span><span id="AgentEvolverRayPPOTrainer-1117"><a href="#AgentEvolverRayPPOTrainer-1117"><span class="linenos">1117</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1118"><a href="#AgentEvolverRayPPOTrainer-1118"><span class="linenos">1118</span></a>                            <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1119"><a href="#AgentEvolverRayPPOTrainer-1119"><span class="linenos">1119</span></a>                                        <span class="n">task_id</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1120"><a href="#AgentEvolverRayPPOTrainer-1120"><span class="linenos">1120</span></a>                                        <span class="n">query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1121"><a href="#AgentEvolverRayPPOTrainer-1121"><span class="linenos">1121</span></a>                                        <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1122"><a href="#AgentEvolverRayPPOTrainer-1122"><span class="linenos">1122</span></a>                                        <span class="n">open_query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1123"><a href="#AgentEvolverRayPPOTrainer-1123"><span class="linenos">1123</span></a>                                        <span class="n">evaluator</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer-1124"><a href="#AgentEvolverRayPPOTrainer-1124"><span class="linenos">1124</span></a>                                        <span class="n">ground_truth</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;ground_truth&#39;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1125"><a href="#AgentEvolverRayPPOTrainer-1125"><span class="linenos">1125</span></a>                                    <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer-1126"><a href="#AgentEvolverRayPPOTrainer-1126"><span class="linenos">1126</span></a>                            <span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1127"><a href="#AgentEvolverRayPPOTrainer-1127"><span class="linenos">1127</span></a>                            <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1128"><a href="#AgentEvolverRayPPOTrainer-1128"><span class="linenos">1128</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_exp_configs</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">),</span> <span class="s2">&quot;{len(task_exp_configs)=}, {len(gen_batch)=}&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1129"><a href="#AgentEvolverRayPPOTrainer-1129"><span class="linenos">1129</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1130"><a href="#AgentEvolverRayPPOTrainer-1130"><span class="linenos">1130</span></a>                            <span class="c1"># TODO enable tracing by jinli 0619</span>
</span><span id="AgentEvolverRayPPOTrainer-1131"><a href="#AgentEvolverRayPPOTrainer-1131"><span class="linenos">1131</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1132"><a href="#AgentEvolverRayPPOTrainer-1132"><span class="linenos">1132</span></a>                            <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train.</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate trajectories using the environment manager</span>
</span><span id="AgentEvolverRayPPOTrainer-1133"><a href="#AgentEvolverRayPPOTrainer-1133"><span class="linenos">1133</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;{len(trajectories)=}?&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1134"><a href="#AgentEvolverRayPPOTrainer-1134"><span class="linenos">1134</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1135"><a href="#AgentEvolverRayPPOTrainer-1135"><span class="linenos">1135</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">to_dataproto</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1136"><a href="#AgentEvolverRayPPOTrainer-1136"><span class="linenos">1136</span></a>                            
</span><span id="AgentEvolverRayPPOTrainer-1137"><a href="#AgentEvolverRayPPOTrainer-1137"><span class="linenos">1137</span></a>                            <span class="c1"># update metrics about experience manager</span>
</span><span id="AgentEvolverRayPPOTrainer-1138"><a href="#AgentEvolverRayPPOTrainer-1138"><span class="linenos">1138</span></a>                            <span class="n">exp_mask_ratio</span> <span class="o">=</span> <span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;exp_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1139"><a href="#AgentEvolverRayPPOTrainer-1139"><span class="linenos">1139</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_mask_ratio&quot;</span><span class="p">:</span> <span class="n">exp_mask_ratio</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
</span><span id="AgentEvolverRayPPOTrainer-1140"><a href="#AgentEvolverRayPPOTrainer-1140"><span class="linenos">1140</span></a>                            <span class="n">context_time_cost</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;context_time_cost&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trajectories</span> <span class="k">if</span> <span class="s2">&quot;context_time_cost&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1141"><a href="#AgentEvolverRayPPOTrainer-1141"><span class="linenos">1141</span></a>                            <span class="k">if</span> <span class="n">context_time_cost</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1142"><a href="#AgentEvolverRayPPOTrainer-1142"><span class="linenos">1142</span></a>                                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
</span><span id="AgentEvolverRayPPOTrainer-1143"><a href="#AgentEvolverRayPPOTrainer-1143"><span class="linenos">1143</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_avg&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-1144"><a href="#AgentEvolverRayPPOTrainer-1144"><span class="linenos">1144</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_max&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-1145"><a href="#AgentEvolverRayPPOTrainer-1145"><span class="linenos">1145</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_min&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer-1146"><a href="#AgentEvolverRayPPOTrainer-1146"><span class="linenos">1146</span></a>                                <span class="p">})</span>
</span><span id="AgentEvolverRayPPOTrainer-1147"><a href="#AgentEvolverRayPPOTrainer-1147"><span class="linenos">1147</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1148"><a href="#AgentEvolverRayPPOTrainer-1148"><span class="linenos">1148</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gen_batch_output.info batch.keys=</span><span class="si">{</span><span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1149"><a href="#AgentEvolverRayPPOTrainer-1149"><span class="linenos">1149</span></a>                            <span class="n">num_term_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">traj</span><span class="o">.</span><span class="n">is_terminated</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer-1150"><a href="#AgentEvolverRayPPOTrainer-1150"><span class="linenos">1150</span></a>                            <span class="n">num_not_none_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer-1151"><a href="#AgentEvolverRayPPOTrainer-1151"><span class="linenos">1151</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1152"><a href="#AgentEvolverRayPPOTrainer-1152"><span class="linenos">1152</span></a>                            <span class="c1"># gen_batch_output = self.async_rollout_manager.generate_sequences(gen_batch)</span>
</span><span id="AgentEvolverRayPPOTrainer-1153"><a href="#AgentEvolverRayPPOTrainer-1153"><span class="linenos">1153</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1154"><a href="#AgentEvolverRayPPOTrainer-1154"><span class="linenos">1154</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1155"><a href="#AgentEvolverRayPPOTrainer-1155"><span class="linenos">1155</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1156"><a href="#AgentEvolverRayPPOTrainer-1156"><span class="linenos">1156</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen_max&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1157"><a href="#AgentEvolverRayPPOTrainer-1157"><span class="linenos">1157</span></a>                            <span class="n">gen_baseline_batch</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1158"><a href="#AgentEvolverRayPPOTrainer-1158"><span class="linenos">1158</span></a>                            <span class="n">gen_baseline_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;do_sample&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer-1159"><a href="#AgentEvolverRayPPOTrainer-1159"><span class="linenos">1159</span></a>                            <span class="n">gen_baseline_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_baseline_batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate baseline sequences for advantage estimation</span>
</span><span id="AgentEvolverRayPPOTrainer-1160"><a href="#AgentEvolverRayPPOTrainer-1160"><span class="linenos">1160</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1161"><a href="#AgentEvolverRayPPOTrainer-1161"><span class="linenos">1161</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1162"><a href="#AgentEvolverRayPPOTrainer-1162"><span class="linenos">1162</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1163"><a href="#AgentEvolverRayPPOTrainer-1163"><span class="linenos">1163</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1164"><a href="#AgentEvolverRayPPOTrainer-1164"><span class="linenos">1164</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1165"><a href="#AgentEvolverRayPPOTrainer-1165"><span class="linenos">1165</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">batch_keys</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</span><span id="AgentEvolverRayPPOTrainer-1166"><a href="#AgentEvolverRayPPOTrainer-1166"><span class="linenos">1166</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1167"><a href="#AgentEvolverRayPPOTrainer-1167"><span class="linenos">1167</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span>  <span class="c1"># ‚≠ê Add reward baselines to the batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1168"><a href="#AgentEvolverRayPPOTrainer-1168"><span class="linenos">1168</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1169"><a href="#AgentEvolverRayPPOTrainer-1169"><span class="linenos">1169</span></a>                            <span class="k">del</span> <span class="n">gen_baseline_batch</span><span class="p">,</span> <span class="n">gen_baseline_output</span>
</span><span id="AgentEvolverRayPPOTrainer-1170"><a href="#AgentEvolverRayPPOTrainer-1170"><span class="linenos">1170</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1171"><a href="#AgentEvolverRayPPOTrainer-1171"><span class="linenos">1171</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate unique UIDs for each item in the batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1172"><a href="#AgentEvolverRayPPOTrainer-1172"><span class="linenos">1172</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1173"><a href="#AgentEvolverRayPPOTrainer-1173"><span class="linenos">1173</span></a>                    <span class="c1"># in the new code, the rollout process generates new extras, which should be merged with the original extra.</span>
</span><span id="AgentEvolverRayPPOTrainer-1174"><a href="#AgentEvolverRayPPOTrainer-1174"><span class="linenos">1174</span></a>                    <span class="c1"># by now, they are stored seperately.</span>
</span><span id="AgentEvolverRayPPOTrainer-1175"><a href="#AgentEvolverRayPPOTrainer-1175"><span class="linenos">1175</span></a>                    <span class="c1"># assert len(gen_batch_output.non_tensor_batch[&quot;extras&quot;].keys()&amp;batch_extras.keys())==0, &quot;extra of extra should not overlap with existing extra...how funny...&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer-1176"><a href="#AgentEvolverRayPPOTrainer-1176"><span class="linenos">1176</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;original_extras&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">batch_extras</span>  <span class="c1"># ‚≠ê Store original extras before scaling</span>
</span><span id="AgentEvolverRayPPOTrainer-1177"><a href="#AgentEvolverRayPPOTrainer-1177"><span class="linenos">1177</span></a>                    <span class="n">batch</span> <span class="o">=</span> <span class="n">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">gen_batch_output</span><span class="p">)</span>  <span class="c1"># ‚≠ê Merge generated batch with the current batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1178"><a href="#AgentEvolverRayPPOTrainer-1178"><span class="linenos">1178</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1179"><a href="#AgentEvolverRayPPOTrainer-1179"><span class="linenos">1179</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute and add response mask to the batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1180"><a href="#AgentEvolverRayPPOTrainer-1180"><span class="linenos">1180</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1181"><a href="#AgentEvolverRayPPOTrainer-1181"><span class="linenos">1181</span></a>                    <span class="c1"># update experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer-1182"><a href="#AgentEvolverRayPPOTrainer-1182"><span class="linenos">1182</span></a>                    <span class="n">summary_task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">submit_summary_task</span><span class="p">(</span><span class="n">trajectories</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1183"><a href="#AgentEvolverRayPPOTrainer-1183"><span class="linenos">1183</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1184"><a href="#AgentEvolverRayPPOTrainer-1184"><span class="linenos">1184</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1185"><a href="#AgentEvolverRayPPOTrainer-1185"><span class="linenos">1185</span></a>                    <span class="c1"># balance the number of valid tokens on each dp rank.</span>
</span><span id="AgentEvolverRayPPOTrainer-1186"><a href="#AgentEvolverRayPPOTrainer-1186"><span class="linenos">1186</span></a>                    <span class="c1"># Note that this breaks the order of data inside the batch.</span>
</span><span id="AgentEvolverRayPPOTrainer-1187"><a href="#AgentEvolverRayPPOTrainer-1187"><span class="linenos">1187</span></a>                    <span class="c1"># Please take care when you implement group based adv computation such as GRPO and rloo</span>
</span><span id="AgentEvolverRayPPOTrainer-1188"><a href="#AgentEvolverRayPPOTrainer-1188"><span class="linenos">1188</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">balance_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1189"><a href="#AgentEvolverRayPPOTrainer-1189"><span class="linenos">1189</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_balance_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>  <span class="c1"># ‚≠ê Balance the batch to distribute valid tokens evenly</span>
</span><span id="AgentEvolverRayPPOTrainer-1190"><a href="#AgentEvolverRayPPOTrainer-1190"><span class="linenos">1190</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1191"><a href="#AgentEvolverRayPPOTrainer-1191"><span class="linenos">1191</span></a>                    <span class="c1"># compute global_valid tokens</span>
</span><span id="AgentEvolverRayPPOTrainer-1192"><a href="#AgentEvolverRayPPOTrainer-1192"><span class="linenos">1192</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;global_token_num&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ‚≠ê Compute and store the global token numbers</span>
</span><span id="AgentEvolverRayPPOTrainer-1193"><a href="#AgentEvolverRayPPOTrainer-1193"><span class="linenos">1193</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1194"><a href="#AgentEvolverRayPPOTrainer-1194"><span class="linenos">1194</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;reward&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1195"><a href="#AgentEvolverRayPPOTrainer-1195"><span class="linenos">1195</span></a>                        <span class="c1"># compute reward model score</span>
</span><span id="AgentEvolverRayPPOTrainer-1196"><a href="#AgentEvolverRayPPOTrainer-1196"><span class="linenos">1196</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1197"><a href="#AgentEvolverRayPPOTrainer-1197"><span class="linenos">1197</span></a>                            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">compute_rm_score</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reward scores using the reward model</span>
</span><span id="AgentEvolverRayPPOTrainer-1198"><a href="#AgentEvolverRayPPOTrainer-1198"><span class="linenos">1198</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1199"><a href="#AgentEvolverRayPPOTrainer-1199"><span class="linenos">1199</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1200"><a href="#AgentEvolverRayPPOTrainer-1200"><span class="linenos">1200</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1201"><a href="#AgentEvolverRayPPOTrainer-1201"><span class="linenos">1201</span></a>                            <span class="n">future_reward</span> <span class="o">=</span> <span class="n">compute_reward_async</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1202"><a href="#AgentEvolverRayPPOTrainer-1202"><span class="linenos">1202</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1203"><a href="#AgentEvolverRayPPOTrainer-1203"><span class="linenos">1203</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">compute_reward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute rewards and extra information</span>
</span><span id="AgentEvolverRayPPOTrainer-1204"><a href="#AgentEvolverRayPPOTrainer-1204"><span class="linenos">1204</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1205"><a href="#AgentEvolverRayPPOTrainer-1205"><span class="linenos">1205</span></a>                    <span class="c1"># recompute old_log_probs</span>
</span><span id="AgentEvolverRayPPOTrainer-1206"><a href="#AgentEvolverRayPPOTrainer-1206"><span class="linenos">1206</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;old_log_prob&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1207"><a href="#AgentEvolverRayPPOTrainer-1207"><span class="linenos">1207</span></a>                        <span class="n">old_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute old log probabilities</span>
</span><span id="AgentEvolverRayPPOTrainer-1208"><a href="#AgentEvolverRayPPOTrainer-1208"><span class="linenos">1208</span></a>                        <span class="n">entropys</span> <span class="o">=</span> <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;entropys&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1209"><a href="#AgentEvolverRayPPOTrainer-1209"><span class="linenos">1209</span></a>                        <span class="n">response_masks</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1210"><a href="#AgentEvolverRayPPOTrainer-1210"><span class="linenos">1210</span></a>                        <span class="n">loss_agg_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span>
</span><span id="AgentEvolverRayPPOTrainer-1211"><a href="#AgentEvolverRayPPOTrainer-1211"><span class="linenos">1211</span></a>                        <span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">agg_loss</span><span class="p">(</span><span class="n">loss_mat</span><span class="o">=</span><span class="n">entropys</span><span class="p">,</span> <span class="n">loss_mask</span><span class="o">=</span><span class="n">response_masks</span><span class="p">,</span> <span class="n">loss_agg_mode</span><span class="o">=</span><span class="n">loss_agg_mode</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1212"><a href="#AgentEvolverRayPPOTrainer-1212"><span class="linenos">1212</span></a>                        <span class="n">old_log_prob_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;actor/entropy_loss&quot;</span><span class="p">:</span> <span class="n">entropy_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
</span><span id="AgentEvolverRayPPOTrainer-1213"><a href="#AgentEvolverRayPPOTrainer-1213"><span class="linenos">1213</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">old_log_prob_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1214"><a href="#AgentEvolverRayPPOTrainer-1214"><span class="linenos">1214</span></a>                        <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;entropys&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1215"><a href="#AgentEvolverRayPPOTrainer-1215"><span class="linenos">1215</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">old_log_prob</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1216"><a href="#AgentEvolverRayPPOTrainer-1216"><span class="linenos">1216</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1217"><a href="#AgentEvolverRayPPOTrainer-1217"><span class="linenos">1217</span></a>                        <span class="k">if</span> <span class="s2">&quot;rollout_log_probs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer-1218"><a href="#AgentEvolverRayPPOTrainer-1218"><span class="linenos">1218</span></a>                            <span class="c1"># TODO: we may want to add diff of probs too.</span>
</span><span id="AgentEvolverRayPPOTrainer-1219"><a href="#AgentEvolverRayPPOTrainer-1219"><span class="linenos">1219</span></a>                            <span class="n">rollout_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rollout_log_probs&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1220"><a href="#AgentEvolverRayPPOTrainer-1220"><span class="linenos">1220</span></a>                            <span class="n">actor_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;old_log_probs&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1221"><a href="#AgentEvolverRayPPOTrainer-1221"><span class="linenos">1221</span></a>                            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1222"><a href="#AgentEvolverRayPPOTrainer-1222"><span class="linenos">1222</span></a>                            <span class="n">responses</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1223"><a href="#AgentEvolverRayPPOTrainer-1223"><span class="linenos">1223</span></a>                            <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1224"><a href="#AgentEvolverRayPPOTrainer-1224"><span class="linenos">1224</span></a>                            <span class="n">response_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
</span><span id="AgentEvolverRayPPOTrainer-1225"><a href="#AgentEvolverRayPPOTrainer-1225"><span class="linenos">1225</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1226"><a href="#AgentEvolverRayPPOTrainer-1226"><span class="linenos">1226</span></a>                            <span class="n">rollout_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">rollout_old_log_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1227"><a href="#AgentEvolverRayPPOTrainer-1227"><span class="linenos">1227</span></a>                            <span class="n">actor_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">actor_old_log_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1228"><a href="#AgentEvolverRayPPOTrainer-1228"><span class="linenos">1228</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">rollout_probs</span> <span class="o">-</span> <span class="n">actor_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1229"><a href="#AgentEvolverRayPPOTrainer-1229"><span class="linenos">1229</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">,</span> <span class="n">response_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer-1230"><a href="#AgentEvolverRayPPOTrainer-1230"><span class="linenos">1230</span></a>                            <span class="n">rollout_probs_diff_max</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1231"><a href="#AgentEvolverRayPPOTrainer-1231"><span class="linenos">1231</span></a>                            <span class="n">rollout_probs_diff_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1232"><a href="#AgentEvolverRayPPOTrainer-1232"><span class="linenos">1232</span></a>                            <span class="n">rollout_probs_diff_std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1233"><a href="#AgentEvolverRayPPOTrainer-1233"><span class="linenos">1233</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1234"><a href="#AgentEvolverRayPPOTrainer-1234"><span class="linenos">1234</span></a>                                <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-1235"><a href="#AgentEvolverRayPPOTrainer-1235"><span class="linenos">1235</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_max&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_max</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer-1236"><a href="#AgentEvolverRayPPOTrainer-1236"><span class="linenos">1236</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_mean&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer-1237"><a href="#AgentEvolverRayPPOTrainer-1237"><span class="linenos">1237</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_std&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_std</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer-1238"><a href="#AgentEvolverRayPPOTrainer-1238"><span class="linenos">1238</span></a>                                <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-1239"><a href="#AgentEvolverRayPPOTrainer-1239"><span class="linenos">1239</span></a>                            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1240"><a href="#AgentEvolverRayPPOTrainer-1240"><span class="linenos">1240</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1241"><a href="#AgentEvolverRayPPOTrainer-1241"><span class="linenos">1241</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1242"><a href="#AgentEvolverRayPPOTrainer-1242"><span class="linenos">1242</span></a>                        <span class="c1"># compute reference log_prob</span>
</span><span id="AgentEvolverRayPPOTrainer-1243"><a href="#AgentEvolverRayPPOTrainer-1243"><span class="linenos">1243</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;ref&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1244"><a href="#AgentEvolverRayPPOTrainer-1244"><span class="linenos">1244</span></a>                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1245"><a href="#AgentEvolverRayPPOTrainer-1245"><span class="linenos">1245</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reference log probabilities</span>
</span><span id="AgentEvolverRayPPOTrainer-1246"><a href="#AgentEvolverRayPPOTrainer-1246"><span class="linenos">1246</span></a>                            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1247"><a href="#AgentEvolverRayPPOTrainer-1247"><span class="linenos">1247</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1248"><a href="#AgentEvolverRayPPOTrainer-1248"><span class="linenos">1248</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">ref_log_prob</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1249"><a href="#AgentEvolverRayPPOTrainer-1249"><span class="linenos">1249</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1250"><a href="#AgentEvolverRayPPOTrainer-1250"><span class="linenos">1250</span></a>                    <span class="c1"># compute values</span>
</span><span id="AgentEvolverRayPPOTrainer-1251"><a href="#AgentEvolverRayPPOTrainer-1251"><span class="linenos">1251</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1252"><a href="#AgentEvolverRayPPOTrainer-1252"><span class="linenos">1252</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1253"><a href="#AgentEvolverRayPPOTrainer-1253"><span class="linenos">1253</span></a>                            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">compute_values</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute values using the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer-1254"><a href="#AgentEvolverRayPPOTrainer-1254"><span class="linenos">1254</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1255"><a href="#AgentEvolverRayPPOTrainer-1255"><span class="linenos">1255</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1256"><a href="#AgentEvolverRayPPOTrainer-1256"><span class="linenos">1256</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;adv&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1257"><a href="#AgentEvolverRayPPOTrainer-1257"><span class="linenos">1257</span></a>                        <span class="c1"># we combine with rule-based rm</span>
</span><span id="AgentEvolverRayPPOTrainer-1258"><a href="#AgentEvolverRayPPOTrainer-1258"><span class="linenos">1258</span></a>                        <span class="n">reward_extra_infos_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1259"><a href="#AgentEvolverRayPPOTrainer-1259"><span class="linenos">1259</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1260"><a href="#AgentEvolverRayPPOTrainer-1260"><span class="linenos">1260</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">future_reward</span><span class="p">)</span>  <span class="c1"># ‚≠ê Get the reward tensor and extra info from the async call</span>
</span><span id="AgentEvolverRayPPOTrainer-1261"><a href="#AgentEvolverRayPPOTrainer-1261"><span class="linenos">1261</span></a>                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_tensor</span>
</span><span id="AgentEvolverRayPPOTrainer-1262"><a href="#AgentEvolverRayPPOTrainer-1262"><span class="linenos">1262</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1263"><a href="#AgentEvolverRayPPOTrainer-1263"><span class="linenos">1263</span></a>                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1264"><a href="#AgentEvolverRayPPOTrainer-1264"><span class="linenos">1264</span></a>                        <span class="k">if</span> <span class="n">reward_extra_infos_dict</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1265"><a href="#AgentEvolverRayPPOTrainer-1265"><span class="linenos">1265</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
</span><span id="AgentEvolverRayPPOTrainer-1266"><a href="#AgentEvolverRayPPOTrainer-1266"><span class="linenos">1266</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1267"><a href="#AgentEvolverRayPPOTrainer-1267"><span class="linenos">1267</span></a>                        <span class="c1"># compute rewards. apply_kl_penalty if available</span>
</span><span id="AgentEvolverRayPPOTrainer-1268"><a href="#AgentEvolverRayPPOTrainer-1268"><span class="linenos">1268</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1269"><a href="#AgentEvolverRayPPOTrainer-1269"><span class="linenos">1269</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">kl_metrics</span> <span class="o">=</span> <span class="n">apply_kl_penalty</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">kl_ctrl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span><span class="p">,</span> <span class="n">kl_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_penalty</span><span class="p">)</span>  <span class="c1"># ‚≠ê Apply KL divergence penalty</span>
</span><span id="AgentEvolverRayPPOTrainer-1270"><a href="#AgentEvolverRayPPOTrainer-1270"><span class="linenos">1270</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kl_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1271"><a href="#AgentEvolverRayPPOTrainer-1271"><span class="linenos">1271</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1272"><a href="#AgentEvolverRayPPOTrainer-1272"><span class="linenos">1272</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1273"><a href="#AgentEvolverRayPPOTrainer-1273"><span class="linenos">1273</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1274"><a href="#AgentEvolverRayPPOTrainer-1274"><span class="linenos">1274</span></a>                        <span class="c1"># compute advantages, executed on the driver process</span>
</span><span id="AgentEvolverRayPPOTrainer-1275"><a href="#AgentEvolverRayPPOTrainer-1275"><span class="linenos">1275</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># GRPO adv normalization factor</span>
</span><span id="AgentEvolverRayPPOTrainer-1276"><a href="#AgentEvolverRayPPOTrainer-1276"><span class="linenos">1276</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;disable_adv_std&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1277"><a href="#AgentEvolverRayPPOTrainer-1277"><span class="linenos">1277</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1278"><a href="#AgentEvolverRayPPOTrainer-1278"><span class="linenos">1278</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change norm_adv_by_std_in_grpo from True to False, using batch std!&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1279"><a href="#AgentEvolverRayPPOTrainer-1279"><span class="linenos">1279</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer-1280"><a href="#AgentEvolverRayPPOTrainer-1280"><span class="linenos">1280</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1281"><a href="#AgentEvolverRayPPOTrainer-1281"><span class="linenos">1281</span></a>                        <span class="c1"># call the original compute_advantage for compatibility</span>
</span><span id="AgentEvolverRayPPOTrainer-1282"><a href="#AgentEvolverRayPPOTrainer-1282"><span class="linenos">1282</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1283"><a href="#AgentEvolverRayPPOTrainer-1283"><span class="linenos">1283</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1284"><a href="#AgentEvolverRayPPOTrainer-1284"><span class="linenos">1284</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">compute_advantage</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1285"><a href="#AgentEvolverRayPPOTrainer-1285"><span class="linenos">1285</span></a>                            <span class="n">batch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1286"><a href="#AgentEvolverRayPPOTrainer-1286"><span class="linenos">1286</span></a>                            <span class="n">adv_estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1287"><a href="#AgentEvolverRayPPOTrainer-1287"><span class="linenos">1287</span></a>                            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1288"><a href="#AgentEvolverRayPPOTrainer-1288"><span class="linenos">1288</span></a>                            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1289"><a href="#AgentEvolverRayPPOTrainer-1289"><span class="linenos">1289</span></a>                            <span class="n">num_repeat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1290"><a href="#AgentEvolverRayPPOTrainer-1290"><span class="linenos">1290</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="n">norm_adv_by_std_in_grpo</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1291"><a href="#AgentEvolverRayPPOTrainer-1291"><span class="linenos">1291</span></a>                            <span class="n">multi_turn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1292"><a href="#AgentEvolverRayPPOTrainer-1292"><span class="linenos">1292</span></a>                            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1293"><a href="#AgentEvolverRayPPOTrainer-1293"><span class="linenos">1293</span></a>                        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1294"><a href="#AgentEvolverRayPPOTrainer-1294"><span class="linenos">1294</span></a>                        <span class="c1"># shuchang</span>
</span><span id="AgentEvolverRayPPOTrainer-1295"><a href="#AgentEvolverRayPPOTrainer-1295"><span class="linenos">1295</span></a>                        <span class="c1"># ==================== Begin ADCA GRPO  ====================</span>
</span><span id="AgentEvolverRayPPOTrainer-1296"><a href="#AgentEvolverRayPPOTrainer-1296"><span class="linenos">1296</span></a>                        <span class="n">attribution_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_attribution_config</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1297"><a href="#AgentEvolverRayPPOTrainer-1297"><span class="linenos">1297</span></a>                        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">attribution_cfg</span><span class="p">,</span> <span class="s1">&#39;enable&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1298"><a href="#AgentEvolverRayPPOTrainer-1298"><span class="linenos">1298</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">adca_metrics</span> <span class="o">=</span> <span class="n">apply_adca_grpo</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1299"><a href="#AgentEvolverRayPPOTrainer-1299"><span class="linenos">1299</span></a>                                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1300"><a href="#AgentEvolverRayPPOTrainer-1300"><span class="linenos">1300</span></a>                                <span class="n">attribution_cfg</span><span class="o">=</span><span class="n">attribution_cfg</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1301"><a href="#AgentEvolverRayPPOTrainer-1301"><span class="linenos">1301</span></a>                                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1302"><a href="#AgentEvolverRayPPOTrainer-1302"><span class="linenos">1302</span></a>                                <span class="n">global_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1303"><a href="#AgentEvolverRayPPOTrainer-1303"><span class="linenos">1303</span></a>                                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1304"><a href="#AgentEvolverRayPPOTrainer-1304"><span class="linenos">1304</span></a>                                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1305"><a href="#AgentEvolverRayPPOTrainer-1305"><span class="linenos">1305</span></a>                            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1306"><a href="#AgentEvolverRayPPOTrainer-1306"><span class="linenos">1306</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">adca_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1307"><a href="#AgentEvolverRayPPOTrainer-1307"><span class="linenos">1307</span></a>                        <span class="c1"># ==================== End ADCA GRPO ====================</span>
</span><span id="AgentEvolverRayPPOTrainer-1308"><a href="#AgentEvolverRayPPOTrainer-1308"><span class="linenos">1308</span></a>                        <span class="c1"># Apply decay factor of 0.5 to non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;] != &#39;env&#39;</span>
</span><span id="AgentEvolverRayPPOTrainer-1309"><a href="#AgentEvolverRayPPOTrainer-1309"><span class="linenos">1309</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;synth_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1310"><a href="#AgentEvolverRayPPOTrainer-1310"><span class="linenos">1310</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1311"><a href="#AgentEvolverRayPPOTrainer-1311"><span class="linenos">1311</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1312"><a href="#AgentEvolverRayPPOTrainer-1312"><span class="linenos">1312</span></a>                            <span class="k">assert</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1313"><a href="#AgentEvolverRayPPOTrainer-1313"><span class="linenos">1313</span></a>                            <span class="k">if</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1314"><a href="#AgentEvolverRayPPOTrainer-1314"><span class="linenos">1314</span></a>                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">])):</span>
</span><span id="AgentEvolverRayPPOTrainer-1315"><a href="#AgentEvolverRayPPOTrainer-1315"><span class="linenos">1315</span></a>                                    <span class="k">assert</span> <span class="s1">&#39;evaluator&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1316"><a href="#AgentEvolverRayPPOTrainer-1316"><span class="linenos">1316</span></a>                                    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer-1317"><a href="#AgentEvolverRayPPOTrainer-1317"><span class="linenos">1317</span></a>                                    <span class="k">if</span> <span class="n">evaluator</span> <span class="o">!=</span> <span class="s1">&#39;env&#39;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1318"><a href="#AgentEvolverRayPPOTrainer-1318"><span class="linenos">1318</span></a>                                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span>  <span class="c1"># ‚≠ê Apply decay factor to synthetic data</span>
</span><span id="AgentEvolverRayPPOTrainer-1319"><a href="#AgentEvolverRayPPOTrainer-1319"><span class="linenos">1319</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1320"><a href="#AgentEvolverRayPPOTrainer-1320"><span class="linenos">1320</span></a>                    <span class="c1"># update critic</span>
</span><span id="AgentEvolverRayPPOTrainer-1321"><a href="#AgentEvolverRayPPOTrainer-1321"><span class="linenos">1321</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1322"><a href="#AgentEvolverRayPPOTrainer-1322"><span class="linenos">1322</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_critic&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1323"><a href="#AgentEvolverRayPPOTrainer-1323"><span class="linenos">1323</span></a>                            <span class="n">critic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">update_critic</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer-1324"><a href="#AgentEvolverRayPPOTrainer-1324"><span class="linenos">1324</span></a>                        <span class="n">critic_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">critic_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer-1325"><a href="#AgentEvolverRayPPOTrainer-1325"><span class="linenos">1325</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">critic_output_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1326"><a href="#AgentEvolverRayPPOTrainer-1326"><span class="linenos">1326</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1327"><a href="#AgentEvolverRayPPOTrainer-1327"><span class="linenos">1327</span></a>                    <span class="c1"># implement critic warmup</span>
</span><span id="AgentEvolverRayPPOTrainer-1328"><a href="#AgentEvolverRayPPOTrainer-1328"><span class="linenos">1328</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">critic_warmup</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1329"><a href="#AgentEvolverRayPPOTrainer-1329"><span class="linenos">1329</span></a>                        <span class="c1"># update actor</span>
</span><span id="AgentEvolverRayPPOTrainer-1330"><a href="#AgentEvolverRayPPOTrainer-1330"><span class="linenos">1330</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_actor&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1331"><a href="#AgentEvolverRayPPOTrainer-1331"><span class="linenos">1331</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;multi_turn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span>
</span><span id="AgentEvolverRayPPOTrainer-1332"><a href="#AgentEvolverRayPPOTrainer-1332"><span class="linenos">1332</span></a>                            <span class="n">actor_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">update_actor</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the actor with the new batch</span>
</span><span id="AgentEvolverRayPPOTrainer-1333"><a href="#AgentEvolverRayPPOTrainer-1333"><span class="linenos">1333</span></a>                        <span class="n">actor_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">actor_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer-1334"><a href="#AgentEvolverRayPPOTrainer-1334"><span class="linenos">1334</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">actor_output_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1335"><a href="#AgentEvolverRayPPOTrainer-1335"><span class="linenos">1335</span></a>                    
</span><span id="AgentEvolverRayPPOTrainer-1336"><a href="#AgentEvolverRayPPOTrainer-1336"><span class="linenos">1336</span></a>                    <span class="c1"># collect summary tasks</span>
</span><span id="AgentEvolverRayPPOTrainer-1337"><a href="#AgentEvolverRayPPOTrainer-1337"><span class="linenos">1337</span></a>                    <span class="k">if</span> <span class="n">summary_task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1338"><a href="#AgentEvolverRayPPOTrainer-1338"><span class="linenos">1338</span></a>                        <span class="n">time_cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">collect_summary_result</span><span class="p">(</span><span class="n">summary_task</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1339"><a href="#AgentEvolverRayPPOTrainer-1339"><span class="linenos">1339</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_manager/summary&quot;</span><span class="p">:</span> <span class="n">time_cost</span><span class="p">})</span>
</span><span id="AgentEvolverRayPPOTrainer-1340"><a href="#AgentEvolverRayPPOTrainer-1340"><span class="linenos">1340</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1341"><a href="#AgentEvolverRayPPOTrainer-1341"><span class="linenos">1341</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1342"><a href="#AgentEvolverRayPPOTrainer-1342"><span class="linenos">1342</span></a>                    <span class="c1"># Log rollout generations if enabled</span>
</span><span id="AgentEvolverRayPPOTrainer-1343"><a href="#AgentEvolverRayPPOTrainer-1343"><span class="linenos">1343</span></a>                    <span class="n">rollout_data_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rollout_data_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1344"><a href="#AgentEvolverRayPPOTrainer-1344"><span class="linenos">1344</span></a>                    <span class="k">if</span> <span class="n">rollout_data_dir</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1345"><a href="#AgentEvolverRayPPOTrainer-1345"><span class="linenos">1345</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;dump_rollout_generations&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1346"><a href="#AgentEvolverRayPPOTrainer-1346"><span class="linenos">1346</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer-1347"><a href="#AgentEvolverRayPPOTrainer-1347"><span class="linenos">1347</span></a>                            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1348"><a href="#AgentEvolverRayPPOTrainer-1348"><span class="linenos">1348</span></a>                            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1349"><a href="#AgentEvolverRayPPOTrainer-1349"><span class="linenos">1349</span></a>                            <span class="n">scores</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1350"><a href="#AgentEvolverRayPPOTrainer-1350"><span class="linenos">1350</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_dump_generations</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1351"><a href="#AgentEvolverRayPPOTrainer-1351"><span class="linenos">1351</span></a>                                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1352"><a href="#AgentEvolverRayPPOTrainer-1352"><span class="linenos">1352</span></a>                                <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1353"><a href="#AgentEvolverRayPPOTrainer-1353"><span class="linenos">1353</span></a>                                <span class="n">scores</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1354"><a href="#AgentEvolverRayPPOTrainer-1354"><span class="linenos">1354</span></a>                                <span class="n">reward_extra_infos_dict</span><span class="o">=</span><span class="n">reward_extra_infos_dict</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1355"><a href="#AgentEvolverRayPPOTrainer-1355"><span class="linenos">1355</span></a>                                <span class="n">dump_path</span><span class="o">=</span><span class="n">rollout_data_dir</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1356"><a href="#AgentEvolverRayPPOTrainer-1356"><span class="linenos">1356</span></a>                            <span class="p">)</span>  <span class="c1"># ‚≠ê Dump the generated experiences and trajectories</span>
</span><span id="AgentEvolverRayPPOTrainer-1357"><a href="#AgentEvolverRayPPOTrainer-1357"><span class="linenos">1357</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1358"><a href="#AgentEvolverRayPPOTrainer-1358"><span class="linenos">1358</span></a>                            <span class="c1"># save original trajectory</span>
</span><span id="AgentEvolverRayPPOTrainer-1359"><a href="#AgentEvolverRayPPOTrainer-1359"><span class="linenos">1359</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;traj_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1360"><a href="#AgentEvolverRayPPOTrainer-1360"><span class="linenos">1360</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1361"><a href="#AgentEvolverRayPPOTrainer-1361"><span class="linenos">1361</span></a>                                <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1362"><a href="#AgentEvolverRayPPOTrainer-1362"><span class="linenos">1362</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1363"><a href="#AgentEvolverRayPPOTrainer-1363"><span class="linenos">1363</span></a>                            <span class="c1"># save tasks</span>
</span><span id="AgentEvolverRayPPOTrainer-1364"><a href="#AgentEvolverRayPPOTrainer-1364"><span class="linenos">1364</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;task_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1365"><a href="#AgentEvolverRayPPOTrainer-1365"><span class="linenos">1365</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1366"><a href="#AgentEvolverRayPPOTrainer-1366"><span class="linenos">1366</span></a>                                <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span> <span class="c1"># this must be bounded # type: ignore</span>
</span><span id="AgentEvolverRayPPOTrainer-1367"><a href="#AgentEvolverRayPPOTrainer-1367"><span class="linenos">1367</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1368"><a href="#AgentEvolverRayPPOTrainer-1368"><span class="linenos">1368</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1369"><a href="#AgentEvolverRayPPOTrainer-1369"><span class="linenos">1369</span></a>                    <span class="c1"># validate</span>
</span><span id="AgentEvolverRayPPOTrainer-1370"><a href="#AgentEvolverRayPPOTrainer-1370"><span class="linenos">1370</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1371"><a href="#AgentEvolverRayPPOTrainer-1371"><span class="linenos">1371</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1372"><a href="#AgentEvolverRayPPOTrainer-1372"><span class="linenos">1372</span></a>                            <span class="n">val_metrics</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Validate the model and collect validation metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1373"><a href="#AgentEvolverRayPPOTrainer-1373"><span class="linenos">1373</span></a>                            <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1374"><a href="#AgentEvolverRayPPOTrainer-1374"><span class="linenos">1374</span></a>                                <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="n">val_metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1375"><a href="#AgentEvolverRayPPOTrainer-1375"><span class="linenos">1375</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1376"><a href="#AgentEvolverRayPPOTrainer-1376"><span class="linenos">1376</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1377"><a href="#AgentEvolverRayPPOTrainer-1377"><span class="linenos">1377</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1378"><a href="#AgentEvolverRayPPOTrainer-1378"><span class="linenos">1378</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer-1379"><a href="#AgentEvolverRayPPOTrainer-1379"><span class="linenos">1379</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">()</span>  <span class="c1"># ‚≠ê Save the current state of the model as a checkpoint</span>
</span><span id="AgentEvolverRayPPOTrainer-1380"><a href="#AgentEvolverRayPPOTrainer-1380"><span class="linenos">1380</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1381"><a href="#AgentEvolverRayPPOTrainer-1381"><span class="linenos">1381</span></a>                <span class="c1"># training metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1382"><a href="#AgentEvolverRayPPOTrainer-1382"><span class="linenos">1382</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer-1383"><a href="#AgentEvolverRayPPOTrainer-1383"><span class="linenos">1383</span></a>                    <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer-1384"><a href="#AgentEvolverRayPPOTrainer-1384"><span class="linenos">1384</span></a>                        <span class="s2">&quot;training/global_step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1385"><a href="#AgentEvolverRayPPOTrainer-1385"><span class="linenos">1385</span></a>                        <span class="s2">&quot;training/epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1386"><a href="#AgentEvolverRayPPOTrainer-1386"><span class="linenos">1386</span></a>                        <span class="s2">&quot;training/num_not_none_traj&quot;</span><span class="p">:</span> <span class="n">num_not_none_traj</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer-1387"><a href="#AgentEvolverRayPPOTrainer-1387"><span class="linenos">1387</span></a>                        <span class="s2">&quot;training/num_term_traj&quot;</span><span class="p">:</span> <span class="n">num_term_traj</span>
</span><span id="AgentEvolverRayPPOTrainer-1388"><a href="#AgentEvolverRayPPOTrainer-1388"><span class="linenos">1388</span></a>                    <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer-1389"><a href="#AgentEvolverRayPPOTrainer-1389"><span class="linenos">1389</span></a>                <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1390"><a href="#AgentEvolverRayPPOTrainer-1390"><span class="linenos">1390</span></a>                <span class="c1"># collect metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1391"><a href="#AgentEvolverRayPPOTrainer-1391"><span class="linenos">1391</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_data_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">use_critic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer-1392"><a href="#AgentEvolverRayPPOTrainer-1392"><span class="linenos">1392</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_timing_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer-1393"><a href="#AgentEvolverRayPPOTrainer-1393"><span class="linenos">1393</span></a>                <span class="c1"># TODO: implement actual tflpo and theoretical tflpo</span>
</span><span id="AgentEvolverRayPPOTrainer-1394"><a href="#AgentEvolverRayPPOTrainer-1394"><span class="linenos">1394</span></a>                <span class="n">n_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_n_gpus</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1395"><a href="#AgentEvolverRayPPOTrainer-1395"><span class="linenos">1395</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_throughout_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">,</span> <span class="n">n_gpus</span><span class="o">=</span><span class="n">n_gpus</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer-1396"><a href="#AgentEvolverRayPPOTrainer-1396"><span class="linenos">1396</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1397"><a href="#AgentEvolverRayPPOTrainer-1397"><span class="linenos">1397</span></a>                <span class="c1"># TODO: make a canonical logger that supports various backend</span>
</span><span id="AgentEvolverRayPPOTrainer-1398"><a href="#AgentEvolverRayPPOTrainer-1398"><span class="linenos">1398</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>  <span class="c1"># ‚≠ê Log the collected metrics</span>
</span><span id="AgentEvolverRayPPOTrainer-1399"><a href="#AgentEvolverRayPPOTrainer-1399"><span class="linenos">1399</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1400"><a href="#AgentEvolverRayPPOTrainer-1400"><span class="linenos">1400</span></a>                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1401"><a href="#AgentEvolverRayPPOTrainer-1401"><span class="linenos">1401</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="AgentEvolverRayPPOTrainer-1402"><a href="#AgentEvolverRayPPOTrainer-1402"><span class="linenos">1402</span></a>                <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1403"><a href="#AgentEvolverRayPPOTrainer-1403"><span class="linenos">1403</span></a>                    <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final validation metrics: </span><span class="si">{</span><span class="n">last_val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1404"><a href="#AgentEvolverRayPPOTrainer-1404"><span class="linenos">1404</span></a>                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer-1405"><a href="#AgentEvolverRayPPOTrainer-1405"><span class="linenos">1405</span></a>                    <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer-1406"><a href="#AgentEvolverRayPPOTrainer-1406"><span class="linenos">1406</span></a>
</span><span id="AgentEvolverRayPPOTrainer-1407"><a href="#AgentEvolverRayPPOTrainer-1407"><span class="linenos">1407</span></a>            <span class="c1"># we expect the train dataset is fully explored at the beginning, no reload needed.</span>
</span><span id="AgentEvolverRayPPOTrainer-1408"><a href="#AgentEvolverRayPPOTrainer-1408"><span class="linenos">1408</span></a>            <span class="c1"># if isinstance(self.train_dataset, FullDataset):</span>
</span><span id="AgentEvolverRayPPOTrainer-1409"><a href="#AgentEvolverRayPPOTrainer-1409"><span class="linenos">1409</span></a>            <span class="c1">#     self.train_dataset.reload()</span>
</span><span id="AgentEvolverRayPPOTrainer-1410"><a href="#AgentEvolverRayPPOTrainer-1410"><span class="linenos">1410</span></a>            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ratio_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer-1411"><a href="#AgentEvolverRayPPOTrainer-1411"><span class="linenos">1411</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager.data_mixture</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedMixtureStrategy</span>
</span><span id="AgentEvolverRayPPOTrainer-1412"><a href="#AgentEvolverRayPPOTrainer-1412"><span class="linenos">1412</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1413"><a href="#AgentEvolverRayPPOTrainer-1413"><span class="linenos">1413</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span><span class="n">UnifiedMixtureStrategy</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer-1414"><a href="#AgentEvolverRayPPOTrainer-1414"><span class="linenos">1414</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="o">.</span><span class="n">_synthetic_ratio</span><span class="o">-=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span> <span class="c1"># initial 1, 0 at about epoch 5 (about step 30)</span>
</span><span id="AgentEvolverRayPPOTrainer-1415"><a href="#AgentEvolverRayPPOTrainer-1415"><span class="linenos">1415</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>  <span class="c1"># ‚≠ê Update the training dataset for the next iteration</span>
</span></pre></div>


            <div class="docstring"><p>Note that this trainer runs on the driver process on a single CPU/GPU node.</p>
</div>


                            <div id="AgentEvolverRayPPOTrainer.__init__" class="classattr">
                                        <input id="AgentEvolverRayPPOTrainer.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">AgentEvolverRayPPOTrainer</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">config</span>,</span><span class="param">	<span class="n">tokenizer</span>,</span><span class="param">	<span class="n">role_worker_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">verl</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">ppo</span><span class="o">.</span><span class="n">ray_trainer</span><span class="o">.</span><span class="n">Role</span><span class="p">,</span> <span class="n">typing</span><span class="o">.</span><span class="n">Type</span><span class="p">[</span><span class="n">verl</span><span class="o">.</span><span class="n">single_controller</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">Worker</span><span class="p">]]</span>,</span><span class="param">	<span class="n">resource_pool_manager</span><span class="p">:</span> <span class="n">verl</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">ppo</span><span class="o">.</span><span class="n">ray_trainer</span><span class="o">.</span><span class="n">ResourcePoolManager</span>,</span><span class="param">	<span class="n">train_task_manager</span><span class="p">:</span> <span class="n"><a href="../task_manager.html#TaskManager">agentevolver.module.task_manager.TaskManager</a></span>,</span><span class="param">	<span class="n">val_task_manager</span><span class="p">:</span> <span class="n"><a href="../task_manager.html#TaskManager">agentevolver.module.task_manager.TaskManager</a></span>,</span><span class="param">	ray_worker_group_cls: verl.single_controller.ray.base.RayWorkerGroup = &lt;class &#x27;verl.single_controller.ray.base.RayWorkerGroup&#x27;&gt;,</span><span class="param">	<span class="n">processor</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">reward_fn</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">val_reward_fn</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">shuffle_trainset</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">device_name</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span></span>)</span>

                <label class="view-source-button" for="AgentEvolverRayPPOTrainer.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AgentEvolverRayPPOTrainer.__init__-306"><a href="#AgentEvolverRayPPOTrainer.__init__-306"><span class="linenos">306</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-307"><a href="#AgentEvolverRayPPOTrainer.__init__-307"><span class="linenos">307</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-308"><a href="#AgentEvolverRayPPOTrainer.__init__-308"><span class="linenos">308</span></a>        <span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-309"><a href="#AgentEvolverRayPPOTrainer.__init__-309"><span class="linenos">309</span></a>        <span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-310"><a href="#AgentEvolverRayPPOTrainer.__init__-310"><span class="linenos">310</span></a>        <span class="n">role_worker_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Role</span><span class="p">,</span> <span class="n">WorkerType</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-311"><a href="#AgentEvolverRayPPOTrainer.__init__-311"><span class="linenos">311</span></a>        <span class="n">resource_pool_manager</span><span class="p">:</span> <span class="n">ResourcePoolManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-312"><a href="#AgentEvolverRayPPOTrainer.__init__-312"><span class="linenos">312</span></a>        <span class="n">train_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-313"><a href="#AgentEvolverRayPPOTrainer.__init__-313"><span class="linenos">313</span></a>        <span class="n">val_task_manager</span><span class="p">:</span><span class="n">TaskManager</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-314"><a href="#AgentEvolverRayPPOTrainer.__init__-314"><span class="linenos">314</span></a>        <span class="n">ray_worker_group_cls</span><span class="p">:</span> <span class="n">RayWorkerGroup</span> <span class="o">=</span> <span class="n">RayWorkerGroup</span><span class="p">,</span> <span class="c1"># type: ignore</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-315"><a href="#AgentEvolverRayPPOTrainer.__init__-315"><span class="linenos">315</span></a>        <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-316"><a href="#AgentEvolverRayPPOTrainer.__init__-316"><span class="linenos">316</span></a>        <span class="n">reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-317"><a href="#AgentEvolverRayPPOTrainer.__init__-317"><span class="linenos">317</span></a>        <span class="n">val_reward_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-318"><a href="#AgentEvolverRayPPOTrainer.__init__-318"><span class="linenos">318</span></a>        <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-319"><a href="#AgentEvolverRayPPOTrainer.__init__-319"><span class="linenos">319</span></a>        <span class="n">shuffle_trainset</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-320"><a href="#AgentEvolverRayPPOTrainer.__init__-320"><span class="linenos">320</span></a>        <span class="n">device_name</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-321"><a href="#AgentEvolverRayPPOTrainer.__init__-321"><span class="linenos">321</span></a>    <span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-322"><a href="#AgentEvolverRayPPOTrainer.__init__-322"><span class="linenos">322</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-323"><a href="#AgentEvolverRayPPOTrainer.__init__-323"><span class="linenos">323</span></a><span class="sd">        Initialize distributed PPO trainer with Ray backend.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-324"><a href="#AgentEvolverRayPPOTrainer.__init__-324"><span class="linenos">324</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-325"><a href="#AgentEvolverRayPPOTrainer.__init__-325"><span class="linenos">325</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-326"><a href="#AgentEvolverRayPPOTrainer.__init__-326"><span class="linenos">326</span></a><span class="sd">            config: Configuration object containing various settings.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-327"><a href="#AgentEvolverRayPPOTrainer.__init__-327"><span class="linenos">327</span></a><span class="sd">            tokenizer: Tokenizer used for processing text.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-328"><a href="#AgentEvolverRayPPOTrainer.__init__-328"><span class="linenos">328</span></a><span class="sd">            role_worker_mapping (dict[Role, WorkerType]): Mapping of roles to worker types.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-329"><a href="#AgentEvolverRayPPOTrainer.__init__-329"><span class="linenos">329</span></a><span class="sd">            resource_pool_manager (ResourcePoolManager): Manager for resource pools.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-330"><a href="#AgentEvolverRayPPOTrainer.__init__-330"><span class="linenos">330</span></a><span class="sd">            train_task_manager (TaskManager): Task manager for training tasks.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-331"><a href="#AgentEvolverRayPPOTrainer.__init__-331"><span class="linenos">331</span></a><span class="sd">            val_task_manager (TaskManager): Task manager for validation tasks.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-332"><a href="#AgentEvolverRayPPOTrainer.__init__-332"><span class="linenos">332</span></a><span class="sd">            ray_worker_group_cls (RayWorkerGroup, optional): Class for Ray worker groups. Defaults to RayWorkerGroup.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-333"><a href="#AgentEvolverRayPPOTrainer.__init__-333"><span class="linenos">333</span></a><span class="sd">            processor (optional): Processor for additional data processing.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-334"><a href="#AgentEvolverRayPPOTrainer.__init__-334"><span class="linenos">334</span></a><span class="sd">            reward_fn (optional): Function to compute rewards.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-335"><a href="#AgentEvolverRayPPOTrainer.__init__-335"><span class="linenos">335</span></a><span class="sd">            val_reward_fn (optional): Function to compute validation rewards.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-336"><a href="#AgentEvolverRayPPOTrainer.__init__-336"><span class="linenos">336</span></a><span class="sd">            collate_fn (optional): Function to collate data.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-337"><a href="#AgentEvolverRayPPOTrainer.__init__-337"><span class="linenos">337</span></a><span class="sd">            shuffle_trainset (bool, optional): Whether to shuffle the training dataset. Defaults to False.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-338"><a href="#AgentEvolverRayPPOTrainer.__init__-338"><span class="linenos">338</span></a><span class="sd">            device_name (str, optional): Name of the device to use. Defaults to &quot;cuda&quot;.</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-339"><a href="#AgentEvolverRayPPOTrainer.__init__-339"><span class="linenos">339</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-340"><a href="#AgentEvolverRayPPOTrainer.__init__-340"><span class="linenos">340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-341"><a href="#AgentEvolverRayPPOTrainer.__init__-341"><span class="linenos">341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-342"><a href="#AgentEvolverRayPPOTrainer.__init__-342"><span class="linenos">342</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-343"><a href="#AgentEvolverRayPPOTrainer.__init__-343"><span class="linenos">343</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">reward_fn</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-344"><a href="#AgentEvolverRayPPOTrainer.__init__-344"><span class="linenos">344</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">val_reward_fn</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-345"><a href="#AgentEvolverRayPPOTrainer.__init__-345"><span class="linenos">345</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-346"><a href="#AgentEvolverRayPPOTrainer.__init__-346"><span class="linenos">346</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">hybrid_engine</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-347"><a href="#AgentEvolverRayPPOTrainer.__init__-347"><span class="linenos">347</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">,</span> <span class="s2">&quot;Currently, only support hybrid engine&quot;</span>  <span class="c1"># ‚≠ê Ensure the hybrid engine is supported</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-348"><a href="#AgentEvolverRayPPOTrainer.__init__-348"><span class="linenos">348</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-349"><a href="#AgentEvolverRayPPOTrainer.__init__-349"><span class="linenos">349</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-350"><a href="#AgentEvolverRayPPOTrainer.__init__-350"><span class="linenos">350</span></a>            <span class="k">assert</span> <span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">role_worker_mapping</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">=}</span><span class="s2">&quot;</span>  <span class="c1"># ‚≠ê Ensure ActorRollout role is present in the mapping</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-351"><a href="#AgentEvolverRayPPOTrainer.__init__-351"><span class="linenos">351</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-352"><a href="#AgentEvolverRayPPOTrainer.__init__-352"><span class="linenos">352</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span> <span class="o">=</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-353"><a href="#AgentEvolverRayPPOTrainer.__init__-353"><span class="linenos">353</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span> <span class="o">=</span> <span class="n">resource_pool_manager</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-354"><a href="#AgentEvolverRayPPOTrainer.__init__-354"><span class="linenos">354</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-355"><a href="#AgentEvolverRayPPOTrainer.__init__-355"><span class="linenos">355</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span> <span class="o">=</span> <span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span> <span class="ow">in</span> <span class="n">role_worker_mapping</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-356"><a href="#AgentEvolverRayPPOTrainer.__init__-356"><span class="linenos">356</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span> <span class="o">=</span> <span class="n">ray_worker_group_cls</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-357"><a href="#AgentEvolverRayPPOTrainer.__init__-357"><span class="linenos">357</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device_name</span> <span class="o">=</span> <span class="n">device_name</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-358"><a href="#AgentEvolverRayPPOTrainer.__init__-358"><span class="linenos">358</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">validation_generations_logger</span> <span class="o">=</span> <span class="n">ValidationGenerationsLogger</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-359"><a href="#AgentEvolverRayPPOTrainer.__init__-359"><span class="linenos">359</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-360"><a href="#AgentEvolverRayPPOTrainer.__init__-360"><span class="linenos">360</span></a>        <span class="c1"># if ref_in_actor is True, the reference policy will be actor without lora applied</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-361"><a href="#AgentEvolverRayPPOTrainer.__init__-361"><span class="linenos">361</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lora_rank&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-362"><a href="#AgentEvolverRayPPOTrainer.__init__-362"><span class="linenos">362</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-363"><a href="#AgentEvolverRayPPOTrainer.__init__-363"><span class="linenos">363</span></a>        <span class="c1"># define in-reward KL control</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-364"><a href="#AgentEvolverRayPPOTrainer.__init__-364"><span class="linenos">364</span></a>        <span class="c1"># kl loss control currently not suppoorted</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-365"><a href="#AgentEvolverRayPPOTrainer.__init__-365"><span class="linenos">365</span></a>        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-366"><a href="#AgentEvolverRayPPOTrainer.__init__-366"><span class="linenos">366</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span> <span class="o">=</span> <span class="n">core_algos</span><span class="o">.</span><span class="n">get_kl_controller</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_ctrl</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-367"><a href="#AgentEvolverRayPPOTrainer.__init__-367"><span class="linenos">367</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-368"><a href="#AgentEvolverRayPPOTrainer.__init__-368"><span class="linenos">368</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GAE</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-369"><a href="#AgentEvolverRayPPOTrainer.__init__-369"><span class="linenos">369</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-370"><a href="#AgentEvolverRayPPOTrainer.__init__-370"><span class="linenos">370</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="ow">in</span> <span class="p">[</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-371"><a href="#AgentEvolverRayPPOTrainer.__init__-371"><span class="linenos">371</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-372"><a href="#AgentEvolverRayPPOTrainer.__init__-372"><span class="linenos">372</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">GRPO_PASSK</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-373"><a href="#AgentEvolverRayPPOTrainer.__init__-373"><span class="linenos">373</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-374"><a href="#AgentEvolverRayPPOTrainer.__init__-374"><span class="linenos">374</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-375"><a href="#AgentEvolverRayPPOTrainer.__init__-375"><span class="linenos">375</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">RLOO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-376"><a href="#AgentEvolverRayPPOTrainer.__init__-376"><span class="linenos">376</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">OPO</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-377"><a href="#AgentEvolverRayPPOTrainer.__init__-377"><span class="linenos">377</span></a>            <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REINFORCE_PLUS_PLUS_BASELINE</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-378"><a href="#AgentEvolverRayPPOTrainer.__init__-378"><span class="linenos">378</span></a>        <span class="p">]:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-379"><a href="#AgentEvolverRayPPOTrainer.__init__-379"><span class="linenos">379</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-380"><a href="#AgentEvolverRayPPOTrainer.__init__-380"><span class="linenos">380</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-381"><a href="#AgentEvolverRayPPOTrainer.__init__-381"><span class="linenos">381</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-382"><a href="#AgentEvolverRayPPOTrainer.__init__-382"><span class="linenos">382</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-383"><a href="#AgentEvolverRayPPOTrainer.__init__-383"><span class="linenos">383</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_config</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-384"><a href="#AgentEvolverRayPPOTrainer.__init__-384"><span class="linenos">384</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-385"><a href="#AgentEvolverRayPPOTrainer.__init__-385"><span class="linenos">385</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="p">:</span> <span class="n">ParallelEnvManager</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-386"><a href="#AgentEvolverRayPPOTrainer.__init__-386"><span class="linenos">386</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span><span class="p">:</span> <span class="n">ThreadPoolExecutor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-387"><a href="#AgentEvolverRayPPOTrainer.__init__-387"><span class="linenos">387</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-388"><a href="#AgentEvolverRayPPOTrainer.__init__-388"><span class="linenos">388</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">train_task_manager</span><span class="o">=</span><span class="n">train_task_manager</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-389"><a href="#AgentEvolverRayPPOTrainer.__init__-389"><span class="linenos">389</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_task_manager</span><span class="o">=</span><span class="n">val_task_manager</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-390"><a href="#AgentEvolverRayPPOTrainer.__init__-390"><span class="linenos">390</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
</span><span id="AgentEvolverRayPPOTrainer.__init__-391"><a href="#AgentEvolverRayPPOTrainer.__init__-391"><span class="linenos">391</span></a>
</span><span id="AgentEvolverRayPPOTrainer.__init__-392"><a href="#AgentEvolverRayPPOTrainer.__init__-392"><span class="linenos">392</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_create_dataloader_from_manager</span><span class="p">(</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">shuffle_trainset</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create dataloader from the provided manager</span>
</span></pre></div>


            <div class="docstring"><p>Initialize distributed PPO trainer with Ray backend.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>config:</strong>  Configuration object containing various settings.</li>
<li><strong>tokenizer:</strong>  Tokenizer used for processing text.</li>
<li><strong>role_worker_mapping (dict[Role, WorkerType]):</strong>  Mapping of roles to worker types.</li>
<li><strong>resource_pool_manager (ResourcePoolManager):</strong>  Manager for resource pools.</li>
<li><strong>train_task_manager (TaskManager):</strong>  Task manager for training tasks.</li>
<li><strong>val_task_manager (TaskManager):</strong>  Task manager for validation tasks.</li>
<li><strong>ray_worker_group_cls (RayWorkerGroup, optional):</strong>  Class for Ray worker groups. Defaults to RayWorkerGroup.</li>
<li><strong>processor (optional):</strong>  Processor for additional data processing.</li>
<li><strong>reward_fn (optional):</strong>  Function to compute rewards.</li>
<li><strong>val_reward_fn (optional):</strong>  Function to compute validation rewards.</li>
<li><strong>collate_fn (optional):</strong>  Function to collate data.</li>
<li><strong>shuffle_trainset (bool, optional):</strong>  Whether to shuffle the training dataset. Defaults to False.</li>
<li><strong>device_name (str, optional):</strong>  Name of the device to use. Defaults to "cuda".</li>
</ul>
</div>


                            </div>
                            <div id="AgentEvolverRayPPOTrainer.tokenizer" class="classattr">
                                <div class="attr variable">
            <span class="name">tokenizer</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.tokenizer"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.processor" class="classattr">
                                <div class="attr variable">
            <span class="name">processor</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.processor"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.config" class="classattr">
                                <div class="attr variable">
            <span class="name">config</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.config"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.reward_fn" class="classattr">
                                <div class="attr variable">
            <span class="name">reward_fn</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.reward_fn"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.val_reward_fn" class="classattr">
                                <div class="attr variable">
            <span class="name">val_reward_fn</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.val_reward_fn"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.hybrid_engine" class="classattr">
                                <div class="attr variable">
            <span class="name">hybrid_engine</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.hybrid_engine"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.role_worker_mapping" class="classattr">
                                <div class="attr variable">
            <span class="name">role_worker_mapping</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.role_worker_mapping"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.resource_pool_manager" class="classattr">
                                <div class="attr variable">
            <span class="name">resource_pool_manager</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.resource_pool_manager"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.use_reference_policy" class="classattr">
                                <div class="attr variable">
            <span class="name">use_reference_policy</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.use_reference_policy"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.use_rm" class="classattr">
                                <div class="attr variable">
            <span class="name">use_rm</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.use_rm"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.ray_worker_group_cls" class="classattr">
                                <div class="attr variable">
            <span class="name">ray_worker_group_cls</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.ray_worker_group_cls"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.device_name" class="classattr">
                                <div class="attr variable">
            <span class="name">device_name</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.device_name"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.validation_generations_logger" class="classattr">
                                <div class="attr variable">
            <span class="name">validation_generations_logger</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.validation_generations_logger"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.ref_in_actor" class="classattr">
                                <div class="attr variable">
            <span class="name">ref_in_actor</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.ref_in_actor"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.env_manager" class="classattr">
                                <div class="attr variable">
            <span class="name">env_manager</span><span class="annotation">: <a href="../env_manager/env_manager.html#ParallelEnvManager">agentevolver.module.env_manager.env_manager.ParallelEnvManager</a> | None</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.env_manager"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.thread_pool" class="classattr">
                                <div class="attr variable">
            <span class="name">thread_pool</span><span class="annotation">: concurrent.futures.thread.ThreadPoolExecutor | None</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.thread_pool"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.train_task_manager" class="classattr">
                                <div class="attr variable">
            <span class="name">train_task_manager</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.train_task_manager"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.val_task_manager" class="classattr">
                                <div class="attr variable">
            <span class="name">val_task_manager</span>

        
    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.val_task_manager"></a>
    
    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.init_workers" class="classattr">
                                        <input id="AgentEvolverRayPPOTrainer.init_workers-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">init_workers</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AgentEvolverRayPPOTrainer.init_workers-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.init_workers"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AgentEvolverRayPPOTrainer.init_workers-395"><a href="#AgentEvolverRayPPOTrainer.init_workers-395"><span class="linenos">395</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">init_workers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-396"><a href="#AgentEvolverRayPPOTrainer.init_workers-396"><span class="linenos">396</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-397"><a href="#AgentEvolverRayPPOTrainer.init_workers-397"><span class="linenos">397</span></a><span class="sd">        Initializes distributed training workers using the Ray backend.</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-398"><a href="#AgentEvolverRayPPOTrainer.init_workers-398"><span class="linenos">398</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-399"><a href="#AgentEvolverRayPPOTrainer.init_workers-399"><span class="linenos">399</span></a><span class="sd">        This function creates:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-400"><a href="#AgentEvolverRayPPOTrainer.init_workers-400"><span class="linenos">400</span></a><span class="sd">        1. Ray resource pools from configuration</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-401"><a href="#AgentEvolverRayPPOTrainer.init_workers-401"><span class="linenos">401</span></a><span class="sd">        2. Worker groups for each role (actor, critic, etc.)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-402"><a href="#AgentEvolverRayPPOTrainer.init_workers-402"><span class="linenos">402</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-403"><a href="#AgentEvolverRayPPOTrainer.init_workers-403"><span class="linenos">403</span></a><span class="sd">        Args:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-404"><a href="#AgentEvolverRayPPOTrainer.init_workers-404"><span class="linenos">404</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-405"><a href="#AgentEvolverRayPPOTrainer.init_workers-405"><span class="linenos">405</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-406"><a href="#AgentEvolverRayPPOTrainer.init_workers-406"><span class="linenos">406</span></a><span class="sd">        Returns:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-407"><a href="#AgentEvolverRayPPOTrainer.init_workers-407"><span class="linenos">407</span></a><span class="sd">            None</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-408"><a href="#AgentEvolverRayPPOTrainer.init_workers-408"><span class="linenos">408</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-409"><a href="#AgentEvolverRayPPOTrainer.init_workers-409"><span class="linenos">409</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">create_resource_pool</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the resource pools</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-410"><a href="#AgentEvolverRayPPOTrainer.init_workers-410"><span class="linenos">410</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-411"><a href="#AgentEvolverRayPPOTrainer.init_workers-411"><span class="linenos">411</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span> <span class="o">=</span> <span class="p">{</span><span class="n">pool</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">pool</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">resource_pool_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-412"><a href="#AgentEvolverRayPPOTrainer.init_workers-412"><span class="linenos">412</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-413"><a href="#AgentEvolverRayPPOTrainer.init_workers-413"><span class="linenos">413</span></a>        <span class="c1"># create actor and rollout</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-414"><a href="#AgentEvolverRayPPOTrainer.init_workers-414"><span class="linenos">414</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hybrid_engine</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-415"><a href="#AgentEvolverRayPPOTrainer.init_workers-415"><span class="linenos">415</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-416"><a href="#AgentEvolverRayPPOTrainer.init_workers-416"><span class="linenos">416</span></a>            <span class="n">actor_rollout_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-417"><a href="#AgentEvolverRayPPOTrainer.init_workers-417"><span class="linenos">417</span></a>                <span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">ActorRollout</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-418"><a href="#AgentEvolverRayPPOTrainer.init_workers-418"><span class="linenos">418</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-419"><a href="#AgentEvolverRayPPOTrainer.init_workers-419"><span class="linenos">419</span></a>                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-420"><a href="#AgentEvolverRayPPOTrainer.init_workers-420"><span class="linenos">420</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-421"><a href="#AgentEvolverRayPPOTrainer.init_workers-421"><span class="linenos">421</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">actor_rollout_cls</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-422"><a href="#AgentEvolverRayPPOTrainer.init_workers-422"><span class="linenos">422</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-423"><a href="#AgentEvolverRayPPOTrainer.init_workers-423"><span class="linenos">423</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-424"><a href="#AgentEvolverRayPPOTrainer.init_workers-424"><span class="linenos">424</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-425"><a href="#AgentEvolverRayPPOTrainer.init_workers-425"><span class="linenos">425</span></a>        <span class="c1"># create critic</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-426"><a href="#AgentEvolverRayPPOTrainer.init_workers-426"><span class="linenos">426</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-427"><a href="#AgentEvolverRayPPOTrainer.init_workers-427"><span class="linenos">427</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-428"><a href="#AgentEvolverRayPPOTrainer.init_workers-428"><span class="linenos">428</span></a>            <span class="n">critic_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">cls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">Critic</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-429"><a href="#AgentEvolverRayPPOTrainer.init_workers-429"><span class="linenos">429</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">critic_cls</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-430"><a href="#AgentEvolverRayPPOTrainer.init_workers-430"><span class="linenos">430</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-431"><a href="#AgentEvolverRayPPOTrainer.init_workers-431"><span class="linenos">431</span></a>        <span class="c1"># create reference policy if needed</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-432"><a href="#AgentEvolverRayPPOTrainer.init_workers-432"><span class="linenos">432</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-433"><a href="#AgentEvolverRayPPOTrainer.init_workers-433"><span class="linenos">433</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-434"><a href="#AgentEvolverRayPPOTrainer.init_workers-434"><span class="linenos">434</span></a>            <span class="n">ref_policy_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RefPolicy</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-435"><a href="#AgentEvolverRayPPOTrainer.init_workers-435"><span class="linenos">435</span></a>                                                  <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="p">,</span> <span class="n">role</span><span class="o">=</span><span class="s2">&quot;ref&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-436"><a href="#AgentEvolverRayPPOTrainer.init_workers-436"><span class="linenos">436</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_policy_cls</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-437"><a href="#AgentEvolverRayPPOTrainer.init_workers-437"><span class="linenos">437</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-438"><a href="#AgentEvolverRayPPOTrainer.init_workers-438"><span class="linenos">438</span></a>        <span class="c1"># create a reward model if reward_fn is None</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-439"><a href="#AgentEvolverRayPPOTrainer.init_workers-439"><span class="linenos">439</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-440"><a href="#AgentEvolverRayPPOTrainer.init_workers-440"><span class="linenos">440</span></a>            <span class="c1"># we create a RM here</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-441"><a href="#AgentEvolverRayPPOTrainer.init_workers-441"><span class="linenos">441</span></a>            <span class="n">resource_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_resource_pool</span><span class="p">(</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-442"><a href="#AgentEvolverRayPPOTrainer.init_workers-442"><span class="linenos">442</span></a>            <span class="n">rm_cls</span> <span class="o">=</span> <span class="n">RayClassWithInitArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">role_worker_mapping</span><span class="p">[</span><span class="n">Role</span><span class="o">.</span><span class="n">RewardModel</span><span class="p">],</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-443"><a href="#AgentEvolverRayPPOTrainer.init_workers-443"><span class="linenos">443</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="p">[</span><span class="n">resource_pool</span><span class="p">][</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rm_cls</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-444"><a href="#AgentEvolverRayPPOTrainer.init_workers-444"><span class="linenos">444</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-445"><a href="#AgentEvolverRayPPOTrainer.init_workers-445"><span class="linenos">445</span></a>        <span class="c1"># initialize WorkerGroup</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-446"><a href="#AgentEvolverRayPPOTrainer.init_workers-446"><span class="linenos">446</span></a>        <span class="c1"># NOTE: if you want to use a different resource pool for each role, which can support different parallel size,</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-447"><a href="#AgentEvolverRayPPOTrainer.init_workers-447"><span class="linenos">447</span></a>        <span class="c1"># you should not use `create_colocated_worker_cls`.</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-448"><a href="#AgentEvolverRayPPOTrainer.init_workers-448"><span class="linenos">448</span></a>        <span class="c1"># Instead, directly pass different resource pool to different worker groups.</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-449"><a href="#AgentEvolverRayPPOTrainer.init_workers-449"><span class="linenos">449</span></a>        <span class="c1"># See https://github.com/volcengine/verl/blob/master/examples/ray/tutorial.ipynb for more information.</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-450"><a href="#AgentEvolverRayPPOTrainer.init_workers-450"><span class="linenos">450</span></a>        <span class="n">all_wg</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-451"><a href="#AgentEvolverRayPPOTrainer.init_workers-451"><span class="linenos">451</span></a>        <span class="n">wg_kwargs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Setting up kwargs for RayWorkerGroup</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-452"><a href="#AgentEvolverRayPPOTrainer.init_workers-452"><span class="linenos">452</span></a>        <span class="k">if</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-453"><a href="#AgentEvolverRayPPOTrainer.init_workers-453"><span class="linenos">453</span></a>            <span class="n">wg_kwargs</span><span class="p">[</span><span class="s2">&quot;ray_wait_register_center_timeout&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">ray_wait_register_center_timeout</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-454"><a href="#AgentEvolverRayPPOTrainer.init_workers-454"><span class="linenos">454</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-455"><a href="#AgentEvolverRayPPOTrainer.init_workers-455"><span class="linenos">455</span></a>        <span class="k">for</span> <span class="n">resource_pool</span><span class="p">,</span> <span class="n">class_dict</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_to_cls</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-456"><a href="#AgentEvolverRayPPOTrainer.init_workers-456"><span class="linenos">456</span></a>            <span class="n">worker_dict_cls</span> <span class="o">=</span> <span class="n">create_colocated_worker_cls</span><span class="p">(</span><span class="n">class_dict</span><span class="o">=</span><span class="n">class_dict</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-457"><a href="#AgentEvolverRayPPOTrainer.init_workers-457"><span class="linenos">457</span></a>            <span class="n">wg_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ray_worker_group_cls</span><span class="p">(</span><span class="n">resource_pool</span><span class="o">=</span><span class="n">resource_pool</span><span class="p">,</span> <span class="n">ray_cls_with_init</span><span class="o">=</span><span class="n">worker_dict_cls</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-458"><a href="#AgentEvolverRayPPOTrainer.init_workers-458"><span class="linenos">458</span></a>                                                <span class="n">device_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="o">**</span><span class="n">wg_kwargs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-459"><a href="#AgentEvolverRayPPOTrainer.init_workers-459"><span class="linenos">459</span></a>            <span class="n">spawn_wg</span> <span class="o">=</span> <span class="n">wg_dict</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">prefix_set</span><span class="o">=</span><span class="n">class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-460"><a href="#AgentEvolverRayPPOTrainer.init_workers-460"><span class="linenos">460</span></a>            <span class="n">all_wg</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">spawn_wg</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-461"><a href="#AgentEvolverRayPPOTrainer.init_workers-461"><span class="linenos">461</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-462"><a href="#AgentEvolverRayPPOTrainer.init_workers-462"><span class="linenos">462</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-463"><a href="#AgentEvolverRayPPOTrainer.init_workers-463"><span class="linenos">463</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;critic&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-464"><a href="#AgentEvolverRayPPOTrainer.init_workers-464"><span class="linenos">464</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-465"><a href="#AgentEvolverRayPPOTrainer.init_workers-465"><span class="linenos">465</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-466"><a href="#AgentEvolverRayPPOTrainer.init_workers-466"><span class="linenos">466</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-467"><a href="#AgentEvolverRayPPOTrainer.init_workers-467"><span class="linenos">467</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;ref&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-468"><a href="#AgentEvolverRayPPOTrainer.init_workers-468"><span class="linenos">468</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reference policy model</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-469"><a href="#AgentEvolverRayPPOTrainer.init_workers-469"><span class="linenos">469</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-470"><a href="#AgentEvolverRayPPOTrainer.init_workers-470"><span class="linenos">470</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-471"><a href="#AgentEvolverRayPPOTrainer.init_workers-471"><span class="linenos">471</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;rm&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-472"><a href="#AgentEvolverRayPPOTrainer.init_workers-472"><span class="linenos">472</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the reward model</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-473"><a href="#AgentEvolverRayPPOTrainer.init_workers-473"><span class="linenos">473</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-474"><a href="#AgentEvolverRayPPOTrainer.init_workers-474"><span class="linenos">474</span></a>        <span class="c1"># we should create rollout at the end so that vllm can have a better estimation of kv cache memory</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-475"><a href="#AgentEvolverRayPPOTrainer.init_workers-475"><span class="linenos">475</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span> <span class="o">=</span> <span class="n">all_wg</span><span class="p">[</span><span class="s2">&quot;actor_rollout&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-476"><a href="#AgentEvolverRayPPOTrainer.init_workers-476"><span class="linenos">476</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">init_model</span><span class="p">()</span>  <span class="c1"># ‚≠ê Initialize the actor rollout model</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-477"><a href="#AgentEvolverRayPPOTrainer.init_workers-477"><span class="linenos">477</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-478"><a href="#AgentEvolverRayPPOTrainer.init_workers-478"><span class="linenos">478</span></a>        <span class="c1"># create async rollout manager and request scheduler</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-479"><a href="#AgentEvolverRayPPOTrainer.init_workers-479"><span class="linenos">479</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-480"><a href="#AgentEvolverRayPPOTrainer.init_workers-480"><span class="linenos">480</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;async&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-481"><a href="#AgentEvolverRayPPOTrainer.init_workers-481"><span class="linenos">481</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.trainer.ae_async_llm_server_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaAsyncLLMServerManager</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-482"><a href="#AgentEvolverRayPPOTrainer.init_workers-482"><span class="linenos">482</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-483"><a href="#AgentEvolverRayPPOTrainer.init_workers-483"><span class="linenos">483</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span> <span class="o">=</span> <span class="n">BaAsyncLLMServerManager</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-484"><a href="#AgentEvolverRayPPOTrainer.init_workers-484"><span class="linenos">484</span></a>                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-485"><a href="#AgentEvolverRayPPOTrainer.init_workers-485"><span class="linenos">485</span></a>                <span class="n">worker_group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="p">)</span>  <span class="c1"># ‚≠ê Create the asynchronous rollout manager</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-486"><a href="#AgentEvolverRayPPOTrainer.init_workers-486"><span class="linenos">486</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-487"><a href="#AgentEvolverRayPPOTrainer.init_workers-487"><span class="linenos">487</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-488"><a href="#AgentEvolverRayPPOTrainer.init_workers-488"><span class="linenos">488</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="o">=</span> <span class="n">parse_reward_from_dataproto</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-489"><a href="#AgentEvolverRayPPOTrainer.init_workers-489"><span class="linenos">489</span></a>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-490"><a href="#AgentEvolverRayPPOTrainer.init_workers-490"><span class="linenos">490</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span> <span class="o">=</span> <span class="n">ParallelEnvManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">async_rollout_manager</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="p">,</span> <span class="n">max_parallel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">max_env_worker</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-491"><a href="#AgentEvolverRayPPOTrainer.init_workers-491"><span class="linenos">491</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">thread_pool</span><span class="o">.</span><span class="n">max_workers</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.init_workers-492"><a href="#AgentEvolverRayPPOTrainer.init_workers-492"><span class="linenos">492</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span> <span class="o">=</span> <span class="n">ExperienceManager</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes distributed training workers using the Ray backend.</p>

<p>This function creates:</p>

<ol>
<li>Ray resource pools from configuration</li>
<li>Worker groups for each role (actor, critic, etc.)</li>
</ol>

<h6 id="arguments">Arguments:</h6>

<ul>
<li>None</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="AgentEvolverRayPPOTrainer.initialize_exp_pool" class="classattr">
                                        <input id="AgentEvolverRayPPOTrainer.initialize_exp_pool-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">initialize_exp_pool</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AgentEvolverRayPPOTrainer.initialize_exp_pool-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.initialize_exp_pool"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-968"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-968"><span class="linenos"> 968</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_exp_pool</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-969"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-969"><span class="linenos"> 969</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-970"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-970"><span class="linenos"> 970</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-971"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-971"><span class="linenos"> 971</span></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">test_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-972"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-972"><span class="linenos"> 972</span></a>            <span class="n">test_batch</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-973"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-973"><span class="linenos"> 973</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-974"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-974"><span class="linenos"> 974</span></a>            <span class="c1"># we only do validation on rule-based rm</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-975"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-975"><span class="linenos"> 975</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">enable</span> <span class="ow">and</span> <span class="n">test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;reward_model&quot;</span><span class="p">][</span><span class="s2">&quot;style&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-976"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-976"><span class="linenos"> 976</span></a>                <span class="k">return</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-977"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-977"><span class="linenos"> 977</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-978"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-978"><span class="linenos"> 978</span></a>            <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-979"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-979"><span class="linenos"> 979</span></a>            <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-980"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-980"><span class="linenos"> 980</span></a>            <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-981"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-981"><span class="linenos"> 981</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-982"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-982"><span class="linenos"> 982</span></a>            <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-983"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-983"><span class="linenos"> 983</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-984"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-984"><span class="linenos"> 984</span></a>            <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-985"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-985"><span class="linenos"> 985</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-986"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-986"><span class="linenos"> 986</span></a>            <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-987"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-987"><span class="linenos"> 987</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-988"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-988"><span class="linenos"> 988</span></a>            <span class="n">test_gen_batch</span> <span class="o">=</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-989"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-989"><span class="linenos"> 989</span></a>                <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-990"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-990"><span class="linenos"> 990</span></a>                <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-991"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-991"><span class="linenos"> 991</span></a>            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-992"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-992"><span class="linenos"> 992</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-993"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-993"><span class="linenos"> 993</span></a>            <span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-994"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-994"><span class="linenos"> 994</span></a>                <span class="s2">&quot;eos_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-995"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-995"><span class="linenos"> 995</span></a>                <span class="s2">&quot;pad_token_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-996"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-996"><span class="linenos"> 996</span></a>                <span class="s2">&quot;recompute_log_prob&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-997"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-997"><span class="linenos"> 997</span></a>                <span class="s2">&quot;do_sample&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">val_kwargs</span><span class="o">.</span><span class="n">do_sample</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-998"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-998"><span class="linenos"> 998</span></a>                <span class="s2">&quot;validate&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-999"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-999"><span class="linenos"> 999</span></a>            <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1000"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1000"><span class="linenos">1000</span></a>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test_gen_batch meta info: </span><span class="si">{</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1001"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1001"><span class="linenos">1001</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1002"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1002"><span class="linenos">1002</span></a>            <span class="c1"># pad to be divisible by dp_size</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1003"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1003"><span class="linenos">1003</span></a>            <span class="c1"># test_gen_batch_padded, pad_size = pad_dataproto_to_divisor(test_gen_batch, self.actor_rollout_wg.world_size)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1004"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1004"><span class="linenos">1004</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1005"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1005"><span class="linenos">1005</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1006"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1006"><span class="linenos">1006</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1007"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1007"><span class="linenos">1007</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1008"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1008"><span class="linenos">1008</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1009"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1009"><span class="linenos">1009</span></a>                <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1010"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1010"><span class="linenos">1010</span></a>                            <span class="n">task_id</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1011"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1011"><span class="linenos">1011</span></a>                            <span class="n">query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1012"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1012"><span class="linenos">1012</span></a>                            <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1013"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1013"><span class="linenos">1013</span></a>                            <span class="n">open_query</span><span class="o">=</span><span class="n">test_gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1014"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1014"><span class="linenos">1014</span></a>                            <span class="c1"># evaluator=gen_batch.non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;], # avoid potential bugs</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1015"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1015"><span class="linenos">1015</span></a>                         <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_gen_batch</span><span class="p">))]</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1016"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1016"><span class="linenos">1016</span></a>                <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1017"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1017"><span class="linenos">1017</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1018"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1018"><span class="linenos">1018</span></a>                <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validate&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;test.1.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Execute the rollout to generate trajectories</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1019"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1019"><span class="linenos">1019</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end validate rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1020"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1020"><span class="linenos">1020</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1021"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1021"><span class="linenos">1021</span></a>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1022"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1022"><span class="linenos">1022</span></a>            <span class="c1"># summarize in batch: updating experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1023"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1023"><span class="linenos">1023</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">summarize_in_batch</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1024"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1024"><span class="linenos">1024</span></a>        
</span><span id="AgentEvolverRayPPOTrainer.initialize_exp_pool-1025"><a href="#AgentEvolverRayPPOTrainer.initialize_exp_pool-1025"><span class="linenos">1025</span></a>        <span class="k">return</span>
</span></pre></div>


    

                            </div>
                            <div id="AgentEvolverRayPPOTrainer.fit" class="classattr">
                                        <input id="AgentEvolverRayPPOTrainer.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AgentEvolverRayPPOTrainer.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AgentEvolverRayPPOTrainer.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AgentEvolverRayPPOTrainer.fit-1028"><a href="#AgentEvolverRayPPOTrainer.fit-1028"><span class="linenos">1028</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1029"><a href="#AgentEvolverRayPPOTrainer.fit-1029"><span class="linenos">1029</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1030"><a href="#AgentEvolverRayPPOTrainer.fit-1030"><span class="linenos">1030</span></a><span class="sd">        The training loop of PPO.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1031"><a href="#AgentEvolverRayPPOTrainer.fit-1031"><span class="linenos">1031</span></a><span class="sd">        The driver process only need to call the compute functions of the worker group through RPC</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1032"><a href="#AgentEvolverRayPPOTrainer.fit-1032"><span class="linenos">1032</span></a><span class="sd">        to construct the PPO dataflow.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1033"><a href="#AgentEvolverRayPPOTrainer.fit-1033"><span class="linenos">1033</span></a><span class="sd">        The light-weight advantage computation is done on the driver process.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1034"><a href="#AgentEvolverRayPPOTrainer.fit-1034"><span class="linenos">1034</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1035"><a href="#AgentEvolverRayPPOTrainer.fit-1035"><span class="linenos">1035</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1036"><a href="#AgentEvolverRayPPOTrainer.fit-1036"><span class="linenos">1036</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1037"><a href="#AgentEvolverRayPPOTrainer.fit-1037"><span class="linenos">1037</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.utils.tracking</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tracking</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1038"><a href="#AgentEvolverRayPPOTrainer.fit-1038"><span class="linenos">1038</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1039"><a href="#AgentEvolverRayPPOTrainer.fit-1039"><span class="linenos">1039</span></a>        <span class="n">logger</span> <span class="o">=</span> <span class="n">Tracking</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1040"><a href="#AgentEvolverRayPPOTrainer.fit-1040"><span class="linenos">1040</span></a>            <span class="n">project_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">project_name</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1041"><a href="#AgentEvolverRayPPOTrainer.fit-1041"><span class="linenos">1041</span></a>            <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1042"><a href="#AgentEvolverRayPPOTrainer.fit-1042"><span class="linenos">1042</span></a>            <span class="n">default_backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1043"><a href="#AgentEvolverRayPPOTrainer.fit-1043"><span class="linenos">1043</span></a>            <span class="n">config</span><span class="o">=</span><span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1044"><a href="#AgentEvolverRayPPOTrainer.fit-1044"><span class="linenos">1044</span></a>        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1045"><a href="#AgentEvolverRayPPOTrainer.fit-1045"><span class="linenos">1045</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1046"><a href="#AgentEvolverRayPPOTrainer.fit-1046"><span class="linenos">1046</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1047"><a href="#AgentEvolverRayPPOTrainer.fit-1047"><span class="linenos">1047</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1048"><a href="#AgentEvolverRayPPOTrainer.fit-1048"><span class="linenos">1048</span></a>        <span class="c1"># load checkpoint before doing anything</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1049"><a href="#AgentEvolverRayPPOTrainer.fit-1049"><span class="linenos">1049</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_checkpoint</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1050"><a href="#AgentEvolverRayPPOTrainer.fit-1050"><span class="linenos">1050</span></a>        <span class="c1"># spread parameters to vllm</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1051"><a href="#AgentEvolverRayPPOTrainer.fit-1051"><span class="linenos">1051</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1052"><a href="#AgentEvolverRayPPOTrainer.fit-1052"><span class="linenos">1052</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1053"><a href="#AgentEvolverRayPPOTrainer.fit-1053"><span class="linenos">1053</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1054"><a href="#AgentEvolverRayPPOTrainer.fit-1054"><span class="linenos">1054</span></a>        <span class="c1"># initialize experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1055"><a href="#AgentEvolverRayPPOTrainer.fit-1055"><span class="linenos">1055</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_before_training&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1056"><a href="#AgentEvolverRayPPOTrainer.fit-1056"><span class="linenos">1056</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_exp_pool</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1057"><a href="#AgentEvolverRayPPOTrainer.fit-1057"><span class="linenos">1057</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;init_exp_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1058"><a href="#AgentEvolverRayPPOTrainer.fit-1058"><span class="linenos">1058</span></a>                <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1059"><a href="#AgentEvolverRayPPOTrainer.fit-1059"><span class="linenos">1059</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1060"><a href="#AgentEvolverRayPPOTrainer.fit-1060"><span class="linenos">1060</span></a>        <span class="c1"># perform validation before training</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1061"><a href="#AgentEvolverRayPPOTrainer.fit-1061"><span class="linenos">1061</span></a>        <span class="c1"># currently, we only support validation using the reward_function.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1062"><a href="#AgentEvolverRayPPOTrainer.fit-1062"><span class="linenos">1062</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_before_train&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1063"><a href="#AgentEvolverRayPPOTrainer.fit-1063"><span class="linenos">1063</span></a>            <span class="n">val_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Perform initial validation and get the validation metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1064"><a href="#AgentEvolverRayPPOTrainer.fit-1064"><span class="linenos">1064</span></a>            <span class="k">assert</span> <span class="n">val_metrics</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val_metrics</span><span class="si">=}</span><span class="s2">&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1065"><a href="#AgentEvolverRayPPOTrainer.fit-1065"><span class="linenos">1065</span></a>            <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial validation metrics: </span><span class="si">{</span><span class="n">val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1066"><a href="#AgentEvolverRayPPOTrainer.fit-1066"><span class="linenos">1066</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">val_metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1067"><a href="#AgentEvolverRayPPOTrainer.fit-1067"><span class="linenos">1067</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val_only&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1068"><a href="#AgentEvolverRayPPOTrainer.fit-1068"><span class="linenos">1068</span></a>                <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1069"><a href="#AgentEvolverRayPPOTrainer.fit-1069"><span class="linenos">1069</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1070"><a href="#AgentEvolverRayPPOTrainer.fit-1070"><span class="linenos">1070</span></a>        <span class="c1"># [0616] qingxu: add `RAY_DEBUG_POST_MORTEM` env var to activate breakpoint debugging</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1071"><a href="#AgentEvolverRayPPOTrainer.fit-1071"><span class="linenos">1071</span></a>        <span class="c1"># vscode_conditional_breakpoint()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1072"><a href="#AgentEvolverRayPPOTrainer.fit-1072"><span class="linenos">1072</span></a>        <span class="c1"># breakpoint()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1073"><a href="#AgentEvolverRayPPOTrainer.fit-1073"><span class="linenos">1073</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1074"><a href="#AgentEvolverRayPPOTrainer.fit-1074"><span class="linenos">1074</span></a>        <span class="c1"># add tqdm</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1075"><a href="#AgentEvolverRayPPOTrainer.fit-1075"><span class="linenos">1075</span></a>        <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Progress&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1076"><a href="#AgentEvolverRayPPOTrainer.fit-1076"><span class="linenos">1076</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1077"><a href="#AgentEvolverRayPPOTrainer.fit-1077"><span class="linenos">1077</span></a>        <span class="c1"># we start from step 1</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1078"><a href="#AgentEvolverRayPPOTrainer.fit-1078"><span class="linenos">1078</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1079"><a href="#AgentEvolverRayPPOTrainer.fit-1079"><span class="linenos">1079</span></a>        <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1080"><a href="#AgentEvolverRayPPOTrainer.fit-1080"><span class="linenos">1080</span></a>        
</span><span id="AgentEvolverRayPPOTrainer.fit-1081"><a href="#AgentEvolverRayPPOTrainer.fit-1081"><span class="linenos">1081</span></a>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">total_epochs</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1082"><a href="#AgentEvolverRayPPOTrainer.fit-1082"><span class="linenos">1082</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1083"><a href="#AgentEvolverRayPPOTrainer.fit-1083"><span class="linenos">1083</span></a>                <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1084"><a href="#AgentEvolverRayPPOTrainer.fit-1084"><span class="linenos">1084</span></a>                <span class="n">timing_raw</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1085"><a href="#AgentEvolverRayPPOTrainer.fit-1085"><span class="linenos">1085</span></a>                <span class="n">batch</span><span class="p">:</span> <span class="n">DataProto</span> <span class="o">=</span> <span class="n">DataProto</span><span class="o">.</span><span class="n">from_single_dict</span><span class="p">(</span><span class="n">batch_dict</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1086"><a href="#AgentEvolverRayPPOTrainer.fit-1086"><span class="linenos">1086</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1087"><a href="#AgentEvolverRayPPOTrainer.fit-1087"><span class="linenos">1087</span></a>                <span class="c1"># pop those keys for generation</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1088"><a href="#AgentEvolverRayPPOTrainer.fit-1088"><span class="linenos">1088</span></a>                <span class="n">batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">,</span> <span class="s2">&quot;position_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1089"><a href="#AgentEvolverRayPPOTrainer.fit-1089"><span class="linenos">1089</span></a>                <span class="n">non_tensor_batch_keys_to_pop</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;raw_prompt_ids&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1090"><a href="#AgentEvolverRayPPOTrainer.fit-1090"><span class="linenos">1090</span></a>                <span class="k">if</span> <span class="s2">&quot;multi_modal_data&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1091"><a href="#AgentEvolverRayPPOTrainer.fit-1091"><span class="linenos">1091</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1092"><a href="#AgentEvolverRayPPOTrainer.fit-1092"><span class="linenos">1092</span></a>                <span class="k">if</span> <span class="s2">&quot;raw_prompt&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1093"><a href="#AgentEvolverRayPPOTrainer.fit-1093"><span class="linenos">1093</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;raw_prompt&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1094"><a href="#AgentEvolverRayPPOTrainer.fit-1094"><span class="linenos">1094</span></a>                <span class="k">if</span> <span class="s2">&quot;tools_kwargs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1095"><a href="#AgentEvolverRayPPOTrainer.fit-1095"><span class="linenos">1095</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;tools_kwargs&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1096"><a href="#AgentEvolverRayPPOTrainer.fit-1096"><span class="linenos">1096</span></a>                <span class="k">if</span> <span class="s2">&quot;extras&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1097"><a href="#AgentEvolverRayPPOTrainer.fit-1097"><span class="linenos">1097</span></a>                    <span class="n">non_tensor_batch_keys_to_pop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;extras&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1098"><a href="#AgentEvolverRayPPOTrainer.fit-1098"><span class="linenos">1098</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1099"><a href="#AgentEvolverRayPPOTrainer.fit-1099"><span class="linenos">1099</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1100"><a href="#AgentEvolverRayPPOTrainer.fit-1100"><span class="linenos">1100</span></a>                    <span class="n">batch_extras</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1101"><a href="#AgentEvolverRayPPOTrainer.fit-1101"><span class="linenos">1101</span></a>                <span class="n">gen_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1102"><a href="#AgentEvolverRayPPOTrainer.fit-1102"><span class="linenos">1102</span></a>                    <span class="n">batch_keys</span><span class="o">=</span><span class="n">batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1103"><a href="#AgentEvolverRayPPOTrainer.fit-1103"><span class="linenos">1103</span></a>                    <span class="n">non_tensor_batch_keys</span><span class="o">=</span><span class="n">non_tensor_batch_keys_to_pop</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1104"><a href="#AgentEvolverRayPPOTrainer.fit-1104"><span class="linenos">1104</span></a>                <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1105"><a href="#AgentEvolverRayPPOTrainer.fit-1105"><span class="linenos">1105</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1106"><a href="#AgentEvolverRayPPOTrainer.fit-1106"><span class="linenos">1106</span></a>                <span class="n">is_last_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_training_steps</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1107"><a href="#AgentEvolverRayPPOTrainer.fit-1107"><span class="linenos">1107</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1108"><a href="#AgentEvolverRayPPOTrainer.fit-1108"><span class="linenos">1108</span></a>                <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1109"><a href="#AgentEvolverRayPPOTrainer.fit-1109"><span class="linenos">1109</span></a>                    <span class="c1"># generate a batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1110"><a href="#AgentEvolverRayPPOTrainer.fit-1110"><span class="linenos">1110</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1111"><a href="#AgentEvolverRayPPOTrainer.fit-1111"><span class="linenos">1111</span></a>                        <span class="n">trajectories</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Trajectory</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1112"><a href="#AgentEvolverRayPPOTrainer.fit-1112"><span class="linenos">1112</span></a>                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_mode</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1113"><a href="#AgentEvolverRayPPOTrainer.fit-1113"><span class="linenos">1113</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1114"><a href="#AgentEvolverRayPPOTrainer.fit-1114"><span class="linenos">1114</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1115"><a href="#AgentEvolverRayPPOTrainer.fit-1115"><span class="linenos">1115</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1116"><a href="#AgentEvolverRayPPOTrainer.fit-1116"><span class="linenos">1116</span></a>                            <span class="c1"># gen_batch_output = self.explorer_manager.rollout(gen_batch)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1117"><a href="#AgentEvolverRayPPOTrainer.fit-1117"><span class="linenos">1117</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1118"><a href="#AgentEvolverRayPPOTrainer.fit-1118"><span class="linenos">1118</span></a>                            <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="n">Task</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1119"><a href="#AgentEvolverRayPPOTrainer.fit-1119"><span class="linenos">1119</span></a>                                        <span class="n">task_id</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;task_id&quot;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1120"><a href="#AgentEvolverRayPPOTrainer.fit-1120"><span class="linenos">1120</span></a>                                        <span class="n">query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;new_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1121"><a href="#AgentEvolverRayPPOTrainer.fit-1121"><span class="linenos">1121</span></a>                                        <span class="n">env_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">env_service</span><span class="o">.</span><span class="n">env_type</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1122"><a href="#AgentEvolverRayPPOTrainer.fit-1122"><span class="linenos">1122</span></a>                                        <span class="n">open_query</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;extras&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;open_query&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1123"><a href="#AgentEvolverRayPPOTrainer.fit-1123"><span class="linenos">1123</span></a>                                        <span class="n">evaluator</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">],</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1124"><a href="#AgentEvolverRayPPOTrainer.fit-1124"><span class="linenos">1124</span></a>                                        <span class="n">ground_truth</span><span class="o">=</span><span class="n">gen_batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;ground_truth&#39;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1125"><a href="#AgentEvolverRayPPOTrainer.fit-1125"><span class="linenos">1125</span></a>                                    <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1126"><a href="#AgentEvolverRayPPOTrainer.fit-1126"><span class="linenos">1126</span></a>                            <span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1127"><a href="#AgentEvolverRayPPOTrainer.fit-1127"><span class="linenos">1127</span></a>                            <span class="n">task_exp_configs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">get_complete_exp_configs</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1128"><a href="#AgentEvolverRayPPOTrainer.fit-1128"><span class="linenos">1128</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_exp_configs</span><span class="p">)</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="n">tasks</span><span class="p">),</span> <span class="s2">&quot;{len(task_exp_configs)=}, {len(gen_batch)=}&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1129"><a href="#AgentEvolverRayPPOTrainer.fit-1129"><span class="linenos">1129</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1130"><a href="#AgentEvolverRayPPOTrainer.fit-1130"><span class="linenos">1130</span></a>                            <span class="c1"># TODO enable tracing by jinli 0619</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1131"><a href="#AgentEvolverRayPPOTrainer.fit-1131"><span class="linenos">1131</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;start fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1132"><a href="#AgentEvolverRayPPOTrainer.fit-1132"><span class="linenos">1132</span></a>                            <span class="n">trajectories</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">rollout</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">task_exp_configs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train.</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate trajectories using the environment manager</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1133"><a href="#AgentEvolverRayPPOTrainer.fit-1133"><span class="linenos">1133</span></a>                            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;{len(trajectories)=}?&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1134"><a href="#AgentEvolverRayPPOTrainer.fit-1134"><span class="linenos">1134</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="s2">&quot;end fit rollout&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1135"><a href="#AgentEvolverRayPPOTrainer.fit-1135"><span class="linenos">1135</span></a>                            <span class="n">gen_batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_manager</span><span class="o">.</span><span class="n">to_dataproto</span><span class="p">(</span><span class="n">trajectories</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1136"><a href="#AgentEvolverRayPPOTrainer.fit-1136"><span class="linenos">1136</span></a>                            
</span><span id="AgentEvolverRayPPOTrainer.fit-1137"><a href="#AgentEvolverRayPPOTrainer.fit-1137"><span class="linenos">1137</span></a>                            <span class="c1"># update metrics about experience manager</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1138"><a href="#AgentEvolverRayPPOTrainer.fit-1138"><span class="linenos">1138</span></a>                            <span class="n">exp_mask_ratio</span> <span class="o">=</span> <span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;exp_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1139"><a href="#AgentEvolverRayPPOTrainer.fit-1139"><span class="linenos">1139</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_mask_ratio&quot;</span><span class="p">:</span> <span class="n">exp_mask_ratio</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1140"><a href="#AgentEvolverRayPPOTrainer.fit-1140"><span class="linenos">1140</span></a>                            <span class="n">context_time_cost</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;context_time_cost&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trajectories</span> <span class="k">if</span> <span class="s2">&quot;context_time_cost&quot;</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">metadata</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1141"><a href="#AgentEvolverRayPPOTrainer.fit-1141"><span class="linenos">1141</span></a>                            <span class="k">if</span> <span class="n">context_time_cost</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1142"><a href="#AgentEvolverRayPPOTrainer.fit-1142"><span class="linenos">1142</span></a>                                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1143"><a href="#AgentEvolverRayPPOTrainer.fit-1143"><span class="linenos">1143</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_avg&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1144"><a href="#AgentEvolverRayPPOTrainer.fit-1144"><span class="linenos">1144</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_max&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1145"><a href="#AgentEvolverRayPPOTrainer.fit-1145"><span class="linenos">1145</span></a>                                  <span class="s2">&quot;exp_manager/context_cost_min&quot;</span><span class="p">:</span>   <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">context_time_cost</span><span class="p">),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1146"><a href="#AgentEvolverRayPPOTrainer.fit-1146"><span class="linenos">1146</span></a>                                <span class="p">})</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1147"><a href="#AgentEvolverRayPPOTrainer.fit-1147"><span class="linenos">1147</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1148"><a href="#AgentEvolverRayPPOTrainer.fit-1148"><span class="linenos">1148</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;gen_batch_output.info batch.keys=</span><span class="si">{</span><span class="n">gen_batch_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1149"><a href="#AgentEvolverRayPPOTrainer.fit-1149"><span class="linenos">1149</span></a>                            <span class="n">num_term_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">traj</span><span class="o">.</span><span class="n">is_terminated</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1150"><a href="#AgentEvolverRayPPOTrainer.fit-1150"><span class="linenos">1150</span></a>                            <span class="n">num_not_none_traj</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span>  <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1151"><a href="#AgentEvolverRayPPOTrainer.fit-1151"><span class="linenos">1151</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1152"><a href="#AgentEvolverRayPPOTrainer.fit-1152"><span class="linenos">1152</span></a>                            <span class="c1"># gen_batch_output = self.async_rollout_manager.generate_sequences(gen_batch)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1153"><a href="#AgentEvolverRayPPOTrainer.fit-1153"><span class="linenos">1153</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">async_rollout_manager</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1154"><a href="#AgentEvolverRayPPOTrainer.fit-1154"><span class="linenos">1154</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1155"><a href="#AgentEvolverRayPPOTrainer.fit-1155"><span class="linenos">1155</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span> <span class="o">==</span> <span class="n">AdvantageEstimator</span><span class="o">.</span><span class="n">REMAX</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1156"><a href="#AgentEvolverRayPPOTrainer.fit-1156"><span class="linenos">1156</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;gen_max&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1157"><a href="#AgentEvolverRayPPOTrainer.fit-1157"><span class="linenos">1157</span></a>                            <span class="n">gen_baseline_batch</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">gen_batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1158"><a href="#AgentEvolverRayPPOTrainer.fit-1158"><span class="linenos">1158</span></a>                            <span class="n">gen_baseline_batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;do_sample&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1159"><a href="#AgentEvolverRayPPOTrainer.fit-1159"><span class="linenos">1159</span></a>                            <span class="n">gen_baseline_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">generate_sequences</span><span class="p">(</span><span class="n">gen_baseline_batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate baseline sequences for advantage estimation</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1160"><a href="#AgentEvolverRayPPOTrainer.fit-1160"><span class="linenos">1160</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1161"><a href="#AgentEvolverRayPPOTrainer.fit-1161"><span class="linenos">1161</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1162"><a href="#AgentEvolverRayPPOTrainer.fit-1162"><span class="linenos">1162</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1163"><a href="#AgentEvolverRayPPOTrainer.fit-1163"><span class="linenos">1163</span></a>                            <span class="n">reward_baseline_tensor</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1164"><a href="#AgentEvolverRayPPOTrainer.fit-1164"><span class="linenos">1164</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1165"><a href="#AgentEvolverRayPPOTrainer.fit-1165"><span class="linenos">1165</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">batch_keys</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">gen_baseline_output</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1166"><a href="#AgentEvolverRayPPOTrainer.fit-1166"><span class="linenos">1166</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1167"><a href="#AgentEvolverRayPPOTrainer.fit-1167"><span class="linenos">1167</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;reward_baselines&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_baseline_tensor</span>  <span class="c1"># ‚≠ê Add reward baselines to the batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1168"><a href="#AgentEvolverRayPPOTrainer.fit-1168"><span class="linenos">1168</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1169"><a href="#AgentEvolverRayPPOTrainer.fit-1169"><span class="linenos">1169</span></a>                            <span class="k">del</span> <span class="n">gen_baseline_batch</span><span class="p">,</span> <span class="n">gen_baseline_output</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1170"><a href="#AgentEvolverRayPPOTrainer.fit-1170"><span class="linenos">1170</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1171"><a href="#AgentEvolverRayPPOTrainer.fit-1171"><span class="linenos">1171</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s2">&quot;uid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">))],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>  <span class="c1"># ‚≠ê Generate unique UIDs for each item in the batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1172"><a href="#AgentEvolverRayPPOTrainer.fit-1172"><span class="linenos">1172</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1173"><a href="#AgentEvolverRayPPOTrainer.fit-1173"><span class="linenos">1173</span></a>                    <span class="c1"># in the new code, the rollout process generates new extras, which should be merged with the original extra.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1174"><a href="#AgentEvolverRayPPOTrainer.fit-1174"><span class="linenos">1174</span></a>                    <span class="c1"># by now, they are stored seperately.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1175"><a href="#AgentEvolverRayPPOTrainer.fit-1175"><span class="linenos">1175</span></a>                    <span class="c1"># assert len(gen_batch_output.non_tensor_batch[&quot;extras&quot;].keys()&amp;batch_extras.keys())==0, &quot;extra of extra should not overlap with existing extra...how funny...&quot;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1176"><a href="#AgentEvolverRayPPOTrainer.fit-1176"><span class="linenos">1176</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;original_extras&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">batch_extras</span>  <span class="c1"># ‚≠ê Store original extras before scaling</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1177"><a href="#AgentEvolverRayPPOTrainer.fit-1177"><span class="linenos">1177</span></a>                    <span class="n">batch</span> <span class="o">=</span> <span class="n">union_gen_batch_via_task_id</span><span class="p">(</span><span class="n">tasks</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">gen_batch_output</span><span class="p">)</span>  <span class="c1"># ‚≠ê Merge generated batch with the current batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1178"><a href="#AgentEvolverRayPPOTrainer.fit-1178"><span class="linenos">1178</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1179"><a href="#AgentEvolverRayPPOTrainer.fit-1179"><span class="linenos">1179</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_response_mask</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute and add response mask to the batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1180"><a href="#AgentEvolverRayPPOTrainer.fit-1180"><span class="linenos">1180</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1181"><a href="#AgentEvolverRayPPOTrainer.fit-1181"><span class="linenos">1181</span></a>                    <span class="c1"># update experience pool</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1182"><a href="#AgentEvolverRayPPOTrainer.fit-1182"><span class="linenos">1182</span></a>                    <span class="n">summary_task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">submit_summary_task</span><span class="p">(</span><span class="n">trajectories</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1183"><a href="#AgentEvolverRayPPOTrainer.fit-1183"><span class="linenos">1183</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1184"><a href="#AgentEvolverRayPPOTrainer.fit-1184"><span class="linenos">1184</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1185"><a href="#AgentEvolverRayPPOTrainer.fit-1185"><span class="linenos">1185</span></a>                    <span class="c1"># balance the number of valid tokens on each dp rank.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1186"><a href="#AgentEvolverRayPPOTrainer.fit-1186"><span class="linenos">1186</span></a>                    <span class="c1"># Note that this breaks the order of data inside the batch.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1187"><a href="#AgentEvolverRayPPOTrainer.fit-1187"><span class="linenos">1187</span></a>                    <span class="c1"># Please take care when you implement group based adv computation such as GRPO and rloo</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1188"><a href="#AgentEvolverRayPPOTrainer.fit-1188"><span class="linenos">1188</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">balance_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1189"><a href="#AgentEvolverRayPPOTrainer.fit-1189"><span class="linenos">1189</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">_balance_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">)</span>  <span class="c1"># ‚≠ê Balance the batch to distribute valid tokens evenly</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1190"><a href="#AgentEvolverRayPPOTrainer.fit-1190"><span class="linenos">1190</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1191"><a href="#AgentEvolverRayPPOTrainer.fit-1191"><span class="linenos">1191</span></a>                    <span class="c1"># compute global_valid tokens</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1192"><a href="#AgentEvolverRayPPOTrainer.fit-1192"><span class="linenos">1192</span></a>                    <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;global_token_num&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># ‚≠ê Compute and store the global token numbers</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1193"><a href="#AgentEvolverRayPPOTrainer.fit-1193"><span class="linenos">1193</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1194"><a href="#AgentEvolverRayPPOTrainer.fit-1194"><span class="linenos">1194</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;reward&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1195"><a href="#AgentEvolverRayPPOTrainer.fit-1195"><span class="linenos">1195</span></a>                        <span class="c1"># compute reward model score</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1196"><a href="#AgentEvolverRayPPOTrainer.fit-1196"><span class="linenos">1196</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_rm</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1197"><a href="#AgentEvolverRayPPOTrainer.fit-1197"><span class="linenos">1197</span></a>                            <span class="n">reward_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rm_wg</span><span class="o">.</span><span class="n">compute_rm_score</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reward scores using the reward model</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1198"><a href="#AgentEvolverRayPPOTrainer.fit-1198"><span class="linenos">1198</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">reward_tensor</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1199"><a href="#AgentEvolverRayPPOTrainer.fit-1199"><span class="linenos">1199</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1200"><a href="#AgentEvolverRayPPOTrainer.fit-1200"><span class="linenos">1200</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1201"><a href="#AgentEvolverRayPPOTrainer.fit-1201"><span class="linenos">1201</span></a>                            <span class="n">future_reward</span> <span class="o">=</span> <span class="n">compute_reward_async</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1202"><a href="#AgentEvolverRayPPOTrainer.fit-1202"><span class="linenos">1202</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1203"><a href="#AgentEvolverRayPPOTrainer.fit-1203"><span class="linenos">1203</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">compute_reward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute rewards and extra information</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1204"><a href="#AgentEvolverRayPPOTrainer.fit-1204"><span class="linenos">1204</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1205"><a href="#AgentEvolverRayPPOTrainer.fit-1205"><span class="linenos">1205</span></a>                    <span class="c1"># recompute old_log_probs</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1206"><a href="#AgentEvolverRayPPOTrainer.fit-1206"><span class="linenos">1206</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;old_log_prob&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1207"><a href="#AgentEvolverRayPPOTrainer.fit-1207"><span class="linenos">1207</span></a>                        <span class="n">old_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute old log probabilities</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1208"><a href="#AgentEvolverRayPPOTrainer.fit-1208"><span class="linenos">1208</span></a>                        <span class="n">entropys</span> <span class="o">=</span> <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;entropys&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1209"><a href="#AgentEvolverRayPPOTrainer.fit-1209"><span class="linenos">1209</span></a>                        <span class="n">response_masks</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;response_mask&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1210"><a href="#AgentEvolverRayPPOTrainer.fit-1210"><span class="linenos">1210</span></a>                        <span class="n">loss_agg_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">loss_agg_mode</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1211"><a href="#AgentEvolverRayPPOTrainer.fit-1211"><span class="linenos">1211</span></a>                        <span class="n">entropy_loss</span> <span class="o">=</span> <span class="n">agg_loss</span><span class="p">(</span><span class="n">loss_mat</span><span class="o">=</span><span class="n">entropys</span><span class="p">,</span> <span class="n">loss_mask</span><span class="o">=</span><span class="n">response_masks</span><span class="p">,</span> <span class="n">loss_agg_mode</span><span class="o">=</span><span class="n">loss_agg_mode</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1212"><a href="#AgentEvolverRayPPOTrainer.fit-1212"><span class="linenos">1212</span></a>                        <span class="n">old_log_prob_metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;actor/entropy_loss&quot;</span><span class="p">:</span> <span class="n">entropy_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1213"><a href="#AgentEvolverRayPPOTrainer.fit-1213"><span class="linenos">1213</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">old_log_prob_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1214"><a href="#AgentEvolverRayPPOTrainer.fit-1214"><span class="linenos">1214</span></a>                        <span class="n">old_log_prob</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;entropys&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1215"><a href="#AgentEvolverRayPPOTrainer.fit-1215"><span class="linenos">1215</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">old_log_prob</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1216"><a href="#AgentEvolverRayPPOTrainer.fit-1216"><span class="linenos">1216</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1217"><a href="#AgentEvolverRayPPOTrainer.fit-1217"><span class="linenos">1217</span></a>                        <span class="k">if</span> <span class="s2">&quot;rollout_log_probs&quot;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1218"><a href="#AgentEvolverRayPPOTrainer.fit-1218"><span class="linenos">1218</span></a>                            <span class="c1"># TODO: we may want to add diff of probs too.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1219"><a href="#AgentEvolverRayPPOTrainer.fit-1219"><span class="linenos">1219</span></a>                            <span class="n">rollout_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;rollout_log_probs&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1220"><a href="#AgentEvolverRayPPOTrainer.fit-1220"><span class="linenos">1220</span></a>                            <span class="n">actor_old_log_probs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;old_log_probs&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1221"><a href="#AgentEvolverRayPPOTrainer.fit-1221"><span class="linenos">1221</span></a>                            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1222"><a href="#AgentEvolverRayPPOTrainer.fit-1222"><span class="linenos">1222</span></a>                            <span class="n">responses</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1223"><a href="#AgentEvolverRayPPOTrainer.fit-1223"><span class="linenos">1223</span></a>                            <span class="n">response_length</span> <span class="o">=</span> <span class="n">responses</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1224"><a href="#AgentEvolverRayPPOTrainer.fit-1224"><span class="linenos">1224</span></a>                            <span class="n">response_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">response_length</span><span class="p">:]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1225"><a href="#AgentEvolverRayPPOTrainer.fit-1225"><span class="linenos">1225</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1226"><a href="#AgentEvolverRayPPOTrainer.fit-1226"><span class="linenos">1226</span></a>                            <span class="n">rollout_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">rollout_old_log_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1227"><a href="#AgentEvolverRayPPOTrainer.fit-1227"><span class="linenos">1227</span></a>                            <span class="n">actor_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">actor_old_log_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1228"><a href="#AgentEvolverRayPPOTrainer.fit-1228"><span class="linenos">1228</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">rollout_probs</span> <span class="o">-</span> <span class="n">actor_probs</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1229"><a href="#AgentEvolverRayPPOTrainer.fit-1229"><span class="linenos">1229</span></a>                            <span class="n">rollout_probs_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">,</span> <span class="n">response_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1230"><a href="#AgentEvolverRayPPOTrainer.fit-1230"><span class="linenos">1230</span></a>                            <span class="n">rollout_probs_diff_max</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1231"><a href="#AgentEvolverRayPPOTrainer.fit-1231"><span class="linenos">1231</span></a>                            <span class="n">rollout_probs_diff_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1232"><a href="#AgentEvolverRayPPOTrainer.fit-1232"><span class="linenos">1232</span></a>                            <span class="n">rollout_probs_diff_std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rollout_probs_diff</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1233"><a href="#AgentEvolverRayPPOTrainer.fit-1233"><span class="linenos">1233</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1234"><a href="#AgentEvolverRayPPOTrainer.fit-1234"><span class="linenos">1234</span></a>                                <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1235"><a href="#AgentEvolverRayPPOTrainer.fit-1235"><span class="linenos">1235</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_max&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_max</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1236"><a href="#AgentEvolverRayPPOTrainer.fit-1236"><span class="linenos">1236</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_mean&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1237"><a href="#AgentEvolverRayPPOTrainer.fit-1237"><span class="linenos">1237</span></a>                                    <span class="s2">&quot;training/rollout_probs_diff_std&quot;</span><span class="p">:</span> <span class="n">rollout_probs_diff_std</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1238"><a href="#AgentEvolverRayPPOTrainer.fit-1238"><span class="linenos">1238</span></a>                                <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1239"><a href="#AgentEvolverRayPPOTrainer.fit-1239"><span class="linenos">1239</span></a>                            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1240"><a href="#AgentEvolverRayPPOTrainer.fit-1240"><span class="linenos">1240</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1241"><a href="#AgentEvolverRayPPOTrainer.fit-1241"><span class="linenos">1241</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_reference_policy</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1242"><a href="#AgentEvolverRayPPOTrainer.fit-1242"><span class="linenos">1242</span></a>                        <span class="c1"># compute reference log_prob</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1243"><a href="#AgentEvolverRayPPOTrainer.fit-1243"><span class="linenos">1243</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;ref&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1244"><a href="#AgentEvolverRayPPOTrainer.fit-1244"><span class="linenos">1244</span></a>                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_in_actor</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1245"><a href="#AgentEvolverRayPPOTrainer.fit-1245"><span class="linenos">1245</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_policy_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute reference log probabilities</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1246"><a href="#AgentEvolverRayPPOTrainer.fit-1246"><span class="linenos">1246</span></a>                            <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1247"><a href="#AgentEvolverRayPPOTrainer.fit-1247"><span class="linenos">1247</span></a>                                <span class="n">ref_log_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">compute_ref_log_prob</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1248"><a href="#AgentEvolverRayPPOTrainer.fit-1248"><span class="linenos">1248</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">ref_log_prob</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1249"><a href="#AgentEvolverRayPPOTrainer.fit-1249"><span class="linenos">1249</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1250"><a href="#AgentEvolverRayPPOTrainer.fit-1250"><span class="linenos">1250</span></a>                    <span class="c1"># compute values</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1251"><a href="#AgentEvolverRayPPOTrainer.fit-1251"><span class="linenos">1251</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1252"><a href="#AgentEvolverRayPPOTrainer.fit-1252"><span class="linenos">1252</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1253"><a href="#AgentEvolverRayPPOTrainer.fit-1253"><span class="linenos">1253</span></a>                            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">compute_values</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Compute values using the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1254"><a href="#AgentEvolverRayPPOTrainer.fit-1254"><span class="linenos">1254</span></a>                            <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1255"><a href="#AgentEvolverRayPPOTrainer.fit-1255"><span class="linenos">1255</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1256"><a href="#AgentEvolverRayPPOTrainer.fit-1256"><span class="linenos">1256</span></a>                    <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;adv&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1257"><a href="#AgentEvolverRayPPOTrainer.fit-1257"><span class="linenos">1257</span></a>                        <span class="c1"># we combine with rule-based rm</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1258"><a href="#AgentEvolverRayPPOTrainer.fit-1258"><span class="linenos">1258</span></a>                        <span class="n">reward_extra_infos_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1259"><a href="#AgentEvolverRayPPOTrainer.fit-1259"><span class="linenos">1259</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">reward_model</span><span class="o">.</span><span class="n">launch_reward_fn_async</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1260"><a href="#AgentEvolverRayPPOTrainer.fit-1260"><span class="linenos">1260</span></a>                            <span class="n">reward_tensor</span><span class="p">,</span> <span class="n">reward_extra_infos_dict</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">future_reward</span><span class="p">)</span>  <span class="c1"># ‚≠ê Get the reward tensor and extra info from the async call</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1261"><a href="#AgentEvolverRayPPOTrainer.fit-1261"><span class="linenos">1261</span></a>                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward_tensor</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1262"><a href="#AgentEvolverRayPPOTrainer.fit-1262"><span class="linenos">1262</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1263"><a href="#AgentEvolverRayPPOTrainer.fit-1263"><span class="linenos">1263</span></a>                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1264"><a href="#AgentEvolverRayPPOTrainer.fit-1264"><span class="linenos">1264</span></a>                        <span class="k">if</span> <span class="n">reward_extra_infos_dict</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1265"><a href="#AgentEvolverRayPPOTrainer.fit-1265"><span class="linenos">1265</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">reward_extra_infos_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1266"><a href="#AgentEvolverRayPPOTrainer.fit-1266"><span class="linenos">1266</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1267"><a href="#AgentEvolverRayPPOTrainer.fit-1267"><span class="linenos">1267</span></a>                        <span class="c1"># compute rewards. apply_kl_penalty if available</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1268"><a href="#AgentEvolverRayPPOTrainer.fit-1268"><span class="linenos">1268</span></a>                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">use_kl_in_reward</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1269"><a href="#AgentEvolverRayPPOTrainer.fit-1269"><span class="linenos">1269</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">kl_metrics</span> <span class="o">=</span> <span class="n">apply_kl_penalty</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">kl_ctrl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kl_ctrl_in_reward</span><span class="p">,</span> <span class="n">kl_penalty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">kl_penalty</span><span class="p">)</span>  <span class="c1"># ‚≠ê Apply KL divergence penalty</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1270"><a href="#AgentEvolverRayPPOTrainer.fit-1270"><span class="linenos">1270</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kl_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1271"><a href="#AgentEvolverRayPPOTrainer.fit-1271"><span class="linenos">1271</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1272"><a href="#AgentEvolverRayPPOTrainer.fit-1272"><span class="linenos">1272</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_rewards&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1273"><a href="#AgentEvolverRayPPOTrainer.fit-1273"><span class="linenos">1273</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1274"><a href="#AgentEvolverRayPPOTrainer.fit-1274"><span class="linenos">1274</span></a>                        <span class="c1"># compute advantages, executed on the driver process</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1275"><a href="#AgentEvolverRayPPOTrainer.fit-1275"><span class="linenos">1275</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>  <span class="c1"># GRPO adv normalization factor</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1276"><a href="#AgentEvolverRayPPOTrainer.fit-1276"><span class="linenos">1276</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;disable_adv_std&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1277"><a href="#AgentEvolverRayPPOTrainer.fit-1277"><span class="linenos">1277</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1278"><a href="#AgentEvolverRayPPOTrainer.fit-1278"><span class="linenos">1278</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change norm_adv_by_std_in_grpo from True to False, using batch std!&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1279"><a href="#AgentEvolverRayPPOTrainer.fit-1279"><span class="linenos">1279</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1280"><a href="#AgentEvolverRayPPOTrainer.fit-1280"><span class="linenos">1280</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1281"><a href="#AgentEvolverRayPPOTrainer.fit-1281"><span class="linenos">1281</span></a>                        <span class="c1"># call the original compute_advantage for compatibility</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1282"><a href="#AgentEvolverRayPPOTrainer.fit-1282"><span class="linenos">1282</span></a>                        <span class="n">norm_adv_by_std_in_grpo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;norm_adv_by_std_in_grpo&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1283"><a href="#AgentEvolverRayPPOTrainer.fit-1283"><span class="linenos">1283</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1284"><a href="#AgentEvolverRayPPOTrainer.fit-1284"><span class="linenos">1284</span></a>                        <span class="n">batch</span> <span class="o">=</span> <span class="n">compute_advantage</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1285"><a href="#AgentEvolverRayPPOTrainer.fit-1285"><span class="linenos">1285</span></a>                            <span class="n">batch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1286"><a href="#AgentEvolverRayPPOTrainer.fit-1286"><span class="linenos">1286</span></a>                            <span class="n">adv_estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">adv_estimator</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1287"><a href="#AgentEvolverRayPPOTrainer.fit-1287"><span class="linenos">1287</span></a>                            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1288"><a href="#AgentEvolverRayPPOTrainer.fit-1288"><span class="linenos">1288</span></a>                            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="o">.</span><span class="n">lam</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1289"><a href="#AgentEvolverRayPPOTrainer.fit-1289"><span class="linenos">1289</span></a>                            <span class="n">num_repeat</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">n</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1290"><a href="#AgentEvolverRayPPOTrainer.fit-1290"><span class="linenos">1290</span></a>                            <span class="n">norm_adv_by_std_in_grpo</span><span class="o">=</span><span class="n">norm_adv_by_std_in_grpo</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1291"><a href="#AgentEvolverRayPPOTrainer.fit-1291"><span class="linenos">1291</span></a>                            <span class="n">multi_turn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1292"><a href="#AgentEvolverRayPPOTrainer.fit-1292"><span class="linenos">1292</span></a>                            <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">algorithm</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1293"><a href="#AgentEvolverRayPPOTrainer.fit-1293"><span class="linenos">1293</span></a>                        <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1294"><a href="#AgentEvolverRayPPOTrainer.fit-1294"><span class="linenos">1294</span></a>                        <span class="c1"># shuchang</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1295"><a href="#AgentEvolverRayPPOTrainer.fit-1295"><span class="linenos">1295</span></a>                        <span class="c1"># ==================== Begin ADCA GRPO  ====================</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1296"><a href="#AgentEvolverRayPPOTrainer.fit-1296"><span class="linenos">1296</span></a>                        <span class="n">attribution_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_attribution_config</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1297"><a href="#AgentEvolverRayPPOTrainer.fit-1297"><span class="linenos">1297</span></a>                        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">attribution_cfg</span><span class="p">,</span> <span class="s1">&#39;enable&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1298"><a href="#AgentEvolverRayPPOTrainer.fit-1298"><span class="linenos">1298</span></a>                            <span class="n">batch</span><span class="p">,</span> <span class="n">adca_metrics</span> <span class="o">=</span> <span class="n">apply_adca_grpo</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1299"><a href="#AgentEvolverRayPPOTrainer.fit-1299"><span class="linenos">1299</span></a>                                <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1300"><a href="#AgentEvolverRayPPOTrainer.fit-1300"><span class="linenos">1300</span></a>                                <span class="n">attribution_cfg</span><span class="o">=</span><span class="n">attribution_cfg</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1301"><a href="#AgentEvolverRayPPOTrainer.fit-1301"><span class="linenos">1301</span></a>                                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1302"><a href="#AgentEvolverRayPPOTrainer.fit-1302"><span class="linenos">1302</span></a>                                <span class="n">global_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1303"><a href="#AgentEvolverRayPPOTrainer.fit-1303"><span class="linenos">1303</span></a>                                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1304"><a href="#AgentEvolverRayPPOTrainer.fit-1304"><span class="linenos">1304</span></a>                                <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1305"><a href="#AgentEvolverRayPPOTrainer.fit-1305"><span class="linenos">1305</span></a>                            <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1306"><a href="#AgentEvolverRayPPOTrainer.fit-1306"><span class="linenos">1306</span></a>                            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">adca_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1307"><a href="#AgentEvolverRayPPOTrainer.fit-1307"><span class="linenos">1307</span></a>                        <span class="c1"># ==================== End ADCA GRPO ====================</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1308"><a href="#AgentEvolverRayPPOTrainer.fit-1308"><span class="linenos">1308</span></a>                        <span class="c1"># Apply decay factor of 0.5 to non_tensor_batch[&#39;extras&#39;][i][&#39;evaluator&#39;] != &#39;env&#39;</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1309"><a href="#AgentEvolverRayPPOTrainer.fit-1309"><span class="linenos">1309</span></a>                        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;synth_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1310"><a href="#AgentEvolverRayPPOTrainer.fit-1310"><span class="linenos">1310</span></a>                            <span class="k">if</span> <span class="n">epoch</span><span class="o">==</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1311"><a href="#AgentEvolverRayPPOTrainer.fit-1311"><span class="linenos">1311</span></a>                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1312"><a href="#AgentEvolverRayPPOTrainer.fit-1312"><span class="linenos">1312</span></a>                            <span class="k">assert</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1313"><a href="#AgentEvolverRayPPOTrainer.fit-1313"><span class="linenos">1313</span></a>                            <span class="k">if</span> <span class="s1">&#39;extras&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1314"><a href="#AgentEvolverRayPPOTrainer.fit-1314"><span class="linenos">1314</span></a>                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">])):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1315"><a href="#AgentEvolverRayPPOTrainer.fit-1315"><span class="linenos">1315</span></a>                                    <span class="k">assert</span> <span class="s1">&#39;evaluator&#39;</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1316"><a href="#AgentEvolverRayPPOTrainer.fit-1316"><span class="linenos">1316</span></a>                                    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">non_tensor_batch</span><span class="p">[</span><span class="s1">&#39;extras&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;evaluator&#39;</span><span class="p">]</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1317"><a href="#AgentEvolverRayPPOTrainer.fit-1317"><span class="linenos">1317</span></a>                                    <span class="k">if</span> <span class="n">evaluator</span> <span class="o">!=</span> <span class="s1">&#39;env&#39;</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1318"><a href="#AgentEvolverRayPPOTrainer.fit-1318"><span class="linenos">1318</span></a>                                        <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span>  <span class="c1"># ‚≠ê Apply decay factor to synthetic data</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1319"><a href="#AgentEvolverRayPPOTrainer.fit-1319"><span class="linenos">1319</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1320"><a href="#AgentEvolverRayPPOTrainer.fit-1320"><span class="linenos">1320</span></a>                    <span class="c1"># update critic</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1321"><a href="#AgentEvolverRayPPOTrainer.fit-1321"><span class="linenos">1321</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1322"><a href="#AgentEvolverRayPPOTrainer.fit-1322"><span class="linenos">1322</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_critic&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1323"><a href="#AgentEvolverRayPPOTrainer.fit-1323"><span class="linenos">1323</span></a>                            <span class="n">critic_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic_wg</span><span class="o">.</span><span class="n">update_critic</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the critic model</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1324"><a href="#AgentEvolverRayPPOTrainer.fit-1324"><span class="linenos">1324</span></a>                        <span class="n">critic_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">critic_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1325"><a href="#AgentEvolverRayPPOTrainer.fit-1325"><span class="linenos">1325</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">critic_output_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1326"><a href="#AgentEvolverRayPPOTrainer.fit-1326"><span class="linenos">1326</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1327"><a href="#AgentEvolverRayPPOTrainer.fit-1327"><span class="linenos">1327</span></a>                    <span class="c1"># implement critic warmup</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1328"><a href="#AgentEvolverRayPPOTrainer.fit-1328"><span class="linenos">1328</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">critic_warmup</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1329"><a href="#AgentEvolverRayPPOTrainer.fit-1329"><span class="linenos">1329</span></a>                        <span class="c1"># update actor</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1330"><a href="#AgentEvolverRayPPOTrainer.fit-1330"><span class="linenos">1330</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;update_actor&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1331"><a href="#AgentEvolverRayPPOTrainer.fit-1331"><span class="linenos">1331</span></a>                            <span class="n">batch</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;multi_turn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_rollout_ref</span><span class="o">.</span><span class="n">rollout</span><span class="o">.</span><span class="n">multi_turn</span><span class="o">.</span><span class="n">enable</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1332"><a href="#AgentEvolverRayPPOTrainer.fit-1332"><span class="linenos">1332</span></a>                            <span class="n">actor_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor_rollout_wg</span><span class="o">.</span><span class="n">update_actor</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># ‚≠ê Update the actor with the new batch</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1333"><a href="#AgentEvolverRayPPOTrainer.fit-1333"><span class="linenos">1333</span></a>                        <span class="n">actor_output_metrics</span> <span class="o">=</span> <span class="n">reduce_metrics</span><span class="p">(</span><span class="n">actor_output</span><span class="o">.</span><span class="n">meta_info</span><span class="p">[</span><span class="s2">&quot;metrics&quot;</span><span class="p">])</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1334"><a href="#AgentEvolverRayPPOTrainer.fit-1334"><span class="linenos">1334</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">actor_output_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1335"><a href="#AgentEvolverRayPPOTrainer.fit-1335"><span class="linenos">1335</span></a>                    
</span><span id="AgentEvolverRayPPOTrainer.fit-1336"><a href="#AgentEvolverRayPPOTrainer.fit-1336"><span class="linenos">1336</span></a>                    <span class="c1"># collect summary tasks</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1337"><a href="#AgentEvolverRayPPOTrainer.fit-1337"><span class="linenos">1337</span></a>                    <span class="k">if</span> <span class="n">summary_task</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1338"><a href="#AgentEvolverRayPPOTrainer.fit-1338"><span class="linenos">1338</span></a>                        <span class="n">time_cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">collect_summary_result</span><span class="p">(</span><span class="n">summary_task</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1339"><a href="#AgentEvolverRayPPOTrainer.fit-1339"><span class="linenos">1339</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;exp_manager/summary&quot;</span><span class="p">:</span> <span class="n">time_cost</span><span class="p">})</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1340"><a href="#AgentEvolverRayPPOTrainer.fit-1340"><span class="linenos">1340</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1341"><a href="#AgentEvolverRayPPOTrainer.fit-1341"><span class="linenos">1341</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1342"><a href="#AgentEvolverRayPPOTrainer.fit-1342"><span class="linenos">1342</span></a>                    <span class="c1"># Log rollout generations if enabled</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1343"><a href="#AgentEvolverRayPPOTrainer.fit-1343"><span class="linenos">1343</span></a>                    <span class="n">rollout_data_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;rollout_data_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1344"><a href="#AgentEvolverRayPPOTrainer.fit-1344"><span class="linenos">1344</span></a>                    <span class="k">if</span> <span class="n">rollout_data_dir</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1345"><a href="#AgentEvolverRayPPOTrainer.fit-1345"><span class="linenos">1345</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;dump_rollout_generations&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1346"><a href="#AgentEvolverRayPPOTrainer.fit-1346"><span class="linenos">1346</span></a>                            <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1347"><a href="#AgentEvolverRayPPOTrainer.fit-1347"><span class="linenos">1347</span></a>                            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;prompts&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1348"><a href="#AgentEvolverRayPPOTrainer.fit-1348"><span class="linenos">1348</span></a>                            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;responses&quot;</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1349"><a href="#AgentEvolverRayPPOTrainer.fit-1349"><span class="linenos">1349</span></a>                            <span class="n">scores</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;token_level_scores&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1350"><a href="#AgentEvolverRayPPOTrainer.fit-1350"><span class="linenos">1350</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_dump_generations</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1351"><a href="#AgentEvolverRayPPOTrainer.fit-1351"><span class="linenos">1351</span></a>                                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1352"><a href="#AgentEvolverRayPPOTrainer.fit-1352"><span class="linenos">1352</span></a>                                <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1353"><a href="#AgentEvolverRayPPOTrainer.fit-1353"><span class="linenos">1353</span></a>                                <span class="n">scores</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1354"><a href="#AgentEvolverRayPPOTrainer.fit-1354"><span class="linenos">1354</span></a>                                <span class="n">reward_extra_infos_dict</span><span class="o">=</span><span class="n">reward_extra_infos_dict</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1355"><a href="#AgentEvolverRayPPOTrainer.fit-1355"><span class="linenos">1355</span></a>                                <span class="n">dump_path</span><span class="o">=</span><span class="n">rollout_data_dir</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1356"><a href="#AgentEvolverRayPPOTrainer.fit-1356"><span class="linenos">1356</span></a>                            <span class="p">)</span>  <span class="c1"># ‚≠ê Dump the generated experiences and trajectories</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1357"><a href="#AgentEvolverRayPPOTrainer.fit-1357"><span class="linenos">1357</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1358"><a href="#AgentEvolverRayPPOTrainer.fit-1358"><span class="linenos">1358</span></a>                            <span class="c1"># save original trajectory</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1359"><a href="#AgentEvolverRayPPOTrainer.fit-1359"><span class="linenos">1359</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;traj_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1360"><a href="#AgentEvolverRayPPOTrainer.fit-1360"><span class="linenos">1360</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1361"><a href="#AgentEvolverRayPPOTrainer.fit-1361"><span class="linenos">1361</span></a>                                <span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1362"><a href="#AgentEvolverRayPPOTrainer.fit-1362"><span class="linenos">1362</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">traj</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1363"><a href="#AgentEvolverRayPPOTrainer.fit-1363"><span class="linenos">1363</span></a>                            <span class="c1"># save tasks</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1364"><a href="#AgentEvolverRayPPOTrainer.fit-1364"><span class="linenos">1364</span></a>                            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rollout_data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;task_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="si">}</span><span class="s2">.jsonl&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1365"><a href="#AgentEvolverRayPPOTrainer.fit-1365"><span class="linenos">1365</span></a>                            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1366"><a href="#AgentEvolverRayPPOTrainer.fit-1366"><span class="linenos">1366</span></a>                                <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span> <span class="c1"># this must be bounded # type: ignore</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1367"><a href="#AgentEvolverRayPPOTrainer.fit-1367"><span class="linenos">1367</span></a>                                    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">json</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1368"><a href="#AgentEvolverRayPPOTrainer.fit-1368"><span class="linenos">1368</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1369"><a href="#AgentEvolverRayPPOTrainer.fit-1369"><span class="linenos">1369</span></a>                    <span class="c1"># validate</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1370"><a href="#AgentEvolverRayPPOTrainer.fit-1370"><span class="linenos">1370</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_reward_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">test_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1371"><a href="#AgentEvolverRayPPOTrainer.fit-1371"><span class="linenos">1371</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1372"><a href="#AgentEvolverRayPPOTrainer.fit-1372"><span class="linenos">1372</span></a>                            <span class="n">val_metrics</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>  <span class="c1"># ‚≠ê Validate the model and collect validation metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1373"><a href="#AgentEvolverRayPPOTrainer.fit-1373"><span class="linenos">1373</span></a>                            <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1374"><a href="#AgentEvolverRayPPOTrainer.fit-1374"><span class="linenos">1374</span></a>                                <span class="n">last_val_metrics</span> <span class="o">=</span> <span class="n">val_metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1375"><a href="#AgentEvolverRayPPOTrainer.fit-1375"><span class="linenos">1375</span></a>                        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_metrics</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1376"><a href="#AgentEvolverRayPPOTrainer.fit-1376"><span class="linenos">1376</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1377"><a href="#AgentEvolverRayPPOTrainer.fit-1377"><span class="linenos">1377</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">is_last_step</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1378"><a href="#AgentEvolverRayPPOTrainer.fit-1378"><span class="linenos">1378</span></a>                        <span class="k">with</span> <span class="n">_timer</span><span class="p">(</span><span class="s2">&quot;save_checkpoint&quot;</span><span class="p">,</span> <span class="n">timing_raw</span><span class="p">):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1379"><a href="#AgentEvolverRayPPOTrainer.fit-1379"><span class="linenos">1379</span></a>                            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">()</span>  <span class="c1"># ‚≠ê Save the current state of the model as a checkpoint</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1380"><a href="#AgentEvolverRayPPOTrainer.fit-1380"><span class="linenos">1380</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1381"><a href="#AgentEvolverRayPPOTrainer.fit-1381"><span class="linenos">1381</span></a>                <span class="c1"># training metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1382"><a href="#AgentEvolverRayPPOTrainer.fit-1382"><span class="linenos">1382</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1383"><a href="#AgentEvolverRayPPOTrainer.fit-1383"><span class="linenos">1383</span></a>                    <span class="p">{</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1384"><a href="#AgentEvolverRayPPOTrainer.fit-1384"><span class="linenos">1384</span></a>                        <span class="s2">&quot;training/global_step&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1385"><a href="#AgentEvolverRayPPOTrainer.fit-1385"><span class="linenos">1385</span></a>                        <span class="s2">&quot;training/epoch&quot;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1386"><a href="#AgentEvolverRayPPOTrainer.fit-1386"><span class="linenos">1386</span></a>                        <span class="s2">&quot;training/num_not_none_traj&quot;</span><span class="p">:</span> <span class="n">num_not_none_traj</span><span class="p">,</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1387"><a href="#AgentEvolverRayPPOTrainer.fit-1387"><span class="linenos">1387</span></a>                        <span class="s2">&quot;training/num_term_traj&quot;</span><span class="p">:</span> <span class="n">num_term_traj</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1388"><a href="#AgentEvolverRayPPOTrainer.fit-1388"><span class="linenos">1388</span></a>                    <span class="p">}</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1389"><a href="#AgentEvolverRayPPOTrainer.fit-1389"><span class="linenos">1389</span></a>                <span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1390"><a href="#AgentEvolverRayPPOTrainer.fit-1390"><span class="linenos">1390</span></a>                <span class="c1"># collect metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1391"><a href="#AgentEvolverRayPPOTrainer.fit-1391"><span class="linenos">1391</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_data_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">use_critic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_critic</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1392"><a href="#AgentEvolverRayPPOTrainer.fit-1392"><span class="linenos">1392</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_timing_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1393"><a href="#AgentEvolverRayPPOTrainer.fit-1393"><span class="linenos">1393</span></a>                <span class="c1"># TODO: implement actual tflpo and theoretical tflpo</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1394"><a href="#AgentEvolverRayPPOTrainer.fit-1394"><span class="linenos">1394</span></a>                <span class="n">n_gpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resource_pool_manager</span><span class="o">.</span><span class="n">get_n_gpus</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1395"><a href="#AgentEvolverRayPPOTrainer.fit-1395"><span class="linenos">1395</span></a>                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">compute_throughout_metrics</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">timing_raw</span><span class="o">=</span><span class="n">timing_raw</span><span class="p">,</span> <span class="n">n_gpus</span><span class="o">=</span><span class="n">n_gpus</span><span class="p">))</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1396"><a href="#AgentEvolverRayPPOTrainer.fit-1396"><span class="linenos">1396</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1397"><a href="#AgentEvolverRayPPOTrainer.fit-1397"><span class="linenos">1397</span></a>                <span class="c1"># TODO: make a canonical logger that supports various backend</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1398"><a href="#AgentEvolverRayPPOTrainer.fit-1398"><span class="linenos">1398</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span><span class="p">)</span>  <span class="c1"># ‚≠ê Log the collected metrics</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1399"><a href="#AgentEvolverRayPPOTrainer.fit-1399"><span class="linenos">1399</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1400"><a href="#AgentEvolverRayPPOTrainer.fit-1400"><span class="linenos">1400</span></a>                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1401"><a href="#AgentEvolverRayPPOTrainer.fit-1401"><span class="linenos">1401</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">global_steps</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1402"><a href="#AgentEvolverRayPPOTrainer.fit-1402"><span class="linenos">1402</span></a>                <span class="k">if</span> <span class="n">is_last_step</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1403"><a href="#AgentEvolverRayPPOTrainer.fit-1403"><span class="linenos">1403</span></a>                    <span class="n">pprint</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final validation metrics: </span><span class="si">{</span><span class="n">last_val_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1404"><a href="#AgentEvolverRayPPOTrainer.fit-1404"><span class="linenos">1404</span></a>                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1405"><a href="#AgentEvolverRayPPOTrainer.fit-1405"><span class="linenos">1405</span></a>                    <span class="k">return</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1406"><a href="#AgentEvolverRayPPOTrainer.fit-1406"><span class="linenos">1406</span></a>
</span><span id="AgentEvolverRayPPOTrainer.fit-1407"><a href="#AgentEvolverRayPPOTrainer.fit-1407"><span class="linenos">1407</span></a>            <span class="c1"># we expect the train dataset is fully explored at the beginning, no reload needed.</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1408"><a href="#AgentEvolverRayPPOTrainer.fit-1408"><span class="linenos">1408</span></a>            <span class="c1"># if isinstance(self.train_dataset, FullDataset):</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1409"><a href="#AgentEvolverRayPPOTrainer.fit-1409"><span class="linenos">1409</span></a>            <span class="c1">#     self.train_dataset.reload()</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1410"><a href="#AgentEvolverRayPPOTrainer.fit-1410"><span class="linenos">1410</span></a>            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;DEBUG_ARG&quot;</span><span class="p">,</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;ratio_decay&quot;</span><span class="p">)</span><span class="o">!=-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1411"><a href="#AgentEvolverRayPPOTrainer.fit-1411"><span class="linenos">1411</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">agentevolver.module.task_manager.data_mixture</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnifiedMixtureStrategy</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1412"><a href="#AgentEvolverRayPPOTrainer.fit-1412"><span class="linenos">1412</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEBUG: change ratio of synthetic data from 1 to 0.5&quot;</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1413"><a href="#AgentEvolverRayPPOTrainer.fit-1413"><span class="linenos">1413</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="p">,</span><span class="n">UnifiedMixtureStrategy</span><span class="p">)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1414"><a href="#AgentEvolverRayPPOTrainer.fit-1414"><span class="linenos">1414</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">_mixture_strategy</span><span class="o">.</span><span class="n">_synthetic_ratio</span><span class="o">-=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span> <span class="c1"># initial 1, 0 at about epoch 5 (about step 30)</span>
</span><span id="AgentEvolverRayPPOTrainer.fit-1415"><a href="#AgentEvolverRayPPOTrainer.fit-1415"><span class="linenos">1415</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>  <span class="c1"># ‚≠ê Update the training dataset for the next iteration</span>
</span></pre></div>


            <div class="docstring"><p>The training loop of PPO.
The driver process only need to call the compute functions of the worker group through RPC
to construct the PPO dataflow.
The light-weight advantage computation is done on the driver process.</p>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>