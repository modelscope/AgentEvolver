import torch
import verl.utils.torch_functional as verl_F
from openai import AsyncOpenAI
import os
from loguru import logger
import time
import traceback
from tqdm import tqdm
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Tuple, Dict, Optional
import threading
from dataclasses import dataclass

__all__ = [
    "evaluate_step_flags_parallel",    # å¹¶è¡Œç‰ˆæœ¬çš„stepè¯„ä¼°
    "apply_step_mask_vectorized",      # å‘é‡åŒ–çš„maskåº”ç”¨
]

@dataclass
class EvaluationTask:
    """è¯„ä¼°ä»»åŠ¡çš„æ•°æ®ç»“æ„"""
    sample_idx: int
    step_idx: int
    query: str
    rollout: str
    step_text: str
    overall_adv: float

@dataclass
class EvaluationResult:
    """è¯„ä¼°ç»“æœçš„æ•°æ®ç»“æ„"""
    sample_idx: int
    step_idx: int
    is_good: bool
    response_time: float
    
def _get_overall_advantage(advantages_tensor, loss_mask=None):
    """
    ä»advantages tensorä¸­è·å–overall advantageå€¼
    åœ¨GRPOä¸­ï¼Œæ‰€æœ‰æœ‰æ•ˆtokenå…±äº«ä¸€ä¸ªadvantageï¼Œæˆ‘ä»¬éœ€è¦æ­£ç¡®æå–è¿™ä¸ªå€¼
    
    Args:
        advantages_tensor: advantage tensor, shape (resp_len,) 
        loss_mask: æ ‡è¯†éœ€è¦è®­ç»ƒçš„tokenä½ç½®çš„maskï¼Œshape (resp_len,)
                   åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œåªæœ‰assistantçš„æœ‰æ•ˆtokenä¸ºTrue
    
    Returns:
        float: æå–åˆ°çš„overall advantageå€¼
    """
    if advantages_tensor.dim() == 0:  # scalar
        return advantages_tensor.item()
    
    if advantages_tensor.dim() == 1:  # shape: (resp_len,)
        # ä¼˜å…ˆä½¿ç”¨loss_maskæ¥æå–æœ‰æ•ˆadvantage
        if loss_mask is not None:
            valid_advantages = advantages_tensor[loss_mask.bool()]
            if len(valid_advantages) > 0:
                # åœ¨GRPOä¸­ï¼Œæ‰€æœ‰æœ‰æ•ˆtokençš„advantageåº”è¯¥ç›¸åŒï¼Œå–ç¬¬ä¸€ä¸ªå³å¯
                return valid_advantages[0].item()
            else:
                # loss_maskä¸­æ²¡æœ‰æœ‰æ•ˆtokenï¼Œè¿”å›0
                return 0.0
        else:
            # fallback: æ²¡æœ‰loss_maskæ—¶ï¼Œå¯»æ‰¾ç¬¬ä¸€ä¸ªéé›¶å€¼
            non_zero_mask = torch.abs(advantages_tensor) > 1e-8
            if non_zero_mask.any():
                return advantages_tensor[non_zero_mask][0].item()
            else:
                return 0.0
    
    # å…¶ä»–ç»´åº¦ä¸æ”¯æŒ
    raise ValueError(f"Unsupported advantages_tensor shape: {advantages_tensor.shape}")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1. å¼‚æ­¥å¹¶è¡Œçš„stepè¯„ä¼°
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def _build_prompt(query: str, rollout: str, step: str, overall_adv: float) -> list[dict]:
    """
    æ„é€ å¯¹è¯æ¶ˆæ¯ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰
    
    Args:
        overall_adv: çœŸæ­£çš„å…±äº«advantageå€¼ï¼ˆGRPOä¸­æ‰€æœ‰tokenå…±äº«ï¼‰ï¼Œ
                    ä¸æ˜¯sum()åè¢«åºåˆ—é•¿åº¦æ”¾å¤§çš„é”™è¯¯å€¼
    """
    polarity = "positive" if overall_adv > 0 else "negative"
    sys = "You are an expert reward-model evaluator. Reply with **exactly one word**, either **GOOD** or **BAD** â€“ no explanations."
    user = (
        f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
        f"USER QUERY\n{query}\n\n"
        f"ASSISTANT FULL ANSWER\n{rollout}\n\n"
        f"CURRENT ASSISTANT STEP\n{step}\n"
        f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n"
        f"The total advantage (quality score) of the full answer is "
        f"**{overall_adv:+.4f}** â†’ this is {polarity} "
        f"(positive if > 0, negative if < 0).\n\n"
        f"**Task**\n"
        f"Does the *current assistant step* improve (GOOD) or harm (BAD) "
        f"the final answer given the user query and the overall advantage?"
    )
    return [{"role": "system", "content": sys}, {"role": "user", "content": user}]

async def _async_safe_query(client: AsyncOpenAI, 
                           model: str, 
                           messages: list[dict], 
                           semaphore: asyncio.Semaphore,
                           max_retries: int = 3) -> str:
    """å¼‚æ­¥å®‰å…¨çš„APIè°ƒç”¨"""
    async with semaphore:  # æ§åˆ¶å¹¶å‘æ•°
        last_exception = None
        
        for attempt in range(max_retries):
            try:
                response = await client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.0,
                    timeout=30,
                    max_tokens=10,
                )
                return response.choices[0].message.content.strip()
                
            except Exception as e:
                last_exception = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(1.0 * (attempt + 1))
        
        raise last_exception

async def _evaluate_single_task(client: AsyncOpenAI,
                               model_name: str,
                               task: EvaluationTask,
                               semaphore: asyncio.Semaphore) -> EvaluationResult:
    """è¯„ä¼°å•ä¸ªä»»åŠ¡"""
    start_time = time.time()
    
    try:
        messages = _build_prompt(task.query, task.rollout, task.step_text, task.overall_adv)
        answer = await _async_safe_query(client, model_name, messages, semaphore)
        
        answer_upper = answer.upper()
        is_good = answer_upper.startswith("G") or "GOOD" in answer_upper
        
        response_time = time.time() - start_time
        
        return EvaluationResult(
            sample_idx=task.sample_idx,
            step_idx=task.step_idx,
            is_good=is_good,
            response_time=response_time
        )
        
    except Exception as e:
        response_time = time.time() - start_time
        print(f"[parallel_eval] Failed to evaluate sample {task.sample_idx}, step {task.step_idx}: {e}")
        
        # å¤±è´¥æ—¶ä½¿ç”¨éšæœºfallback
        import random
        is_good = random.choice([True, False])
        
        return EvaluationResult(
            sample_idx=task.sample_idx,
            step_idx=task.step_idx,
            is_good=is_good,
            response_time=response_time
        )

async def evaluate_step_flags_parallel(tokenizer,
                                     batch,
                                     model_name: str = "qwen-max",
                                     max_concurrent: int = 20,
                                     batch_size_limit: int = 100) -> Tuple[List[List[bool]], Dict]:
    """
    å¹¶è¡Œè¯„ä¼°step flagsï¼Œå¯¹äºadvantage=0çš„æ ·æœ¬è·³è¿‡è¯„ä¼°ï¼Œç›´æ¥è¿”å›GOOD
    
    Args:
        tokenizer: åˆ†è¯å™¨
        batch: æ•°æ®æ‰¹æ¬¡
        model_name: æ¨¡å‹åç§°
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        batch_size_limit: å•æ‰¹æ¬¡å¤„ç†çš„æœ€å¤§ä»»åŠ¡æ•°
        
    Returns:
        (flags_per_sample, stats): è¯„ä¼°ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
    """
    batch_size = len(batch.batch['prompts'])
    print(f"[parallel_eval] Starting parallel evaluation for {batch_size} samples")
    
    # æ£€æŸ¥å¿…è¦çš„è¾“å…¥
    if 'steps' not in batch.non_tensor_batch:
        raise ValueError("batch.non_tensor_batch['steps'] is required but not found")
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("[parallel_eval] No API key found, using random fallback")
        return _apply_fallback_strategy_parallel(batch), {"fallback_used": True}
    
    # åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯
    client = AsyncOpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    # å‡†å¤‡æ‰€æœ‰è¯„ä¼°ä»»åŠ¡ï¼Œè·³è¿‡advantage=0çš„æ ·æœ¬
    all_tasks = []
    flags_per_sample = [[] for _ in range(batch_size)]
    skipped_samples = 0
    
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨loss_maskè€Œä¸æ˜¯response_mask
    response_length = batch.batch["responses"].size(1)
    loss_mask = batch.batch["loss_mask"][:, -response_length:]  # å–responseéƒ¨åˆ†çš„loss_mask
    
    for sample_idx in range(batch_size):
        query = tokenizer.decode(batch.batch["prompts"][sample_idx], skip_special_tokens=True)
        rollout = tokenizer.decode(batch.batch["responses"][sample_idx], skip_special_tokens=True)
        steps = batch.non_tensor_batch["steps"][sample_idx]
        
        # ä½¿ç”¨loss_maskæå–æ­£ç¡®çš„overall advantage
        sample_loss_mask = loss_mask[sample_idx]
        
        overall_adv = _get_overall_advantage(
            batch.batch["advantages"][sample_idx], 
            sample_loss_mask
        )
        
        # æ–°å¢ï¼šå¦‚æœadvantageä¸º0ï¼Œç›´æ¥è®¾ç½®æ‰€æœ‰stepä¸ºGOODï¼Œè·³è¿‡APIè°ƒç”¨
        if abs(overall_adv) < 1e-8:  # ä½¿ç”¨å°çš„é˜ˆå€¼å¤„ç†æµ®ç‚¹ç²¾åº¦é—®é¢˜
            print(f"[parallel_eval] Sample {sample_idx}: advantageâ‰ˆ0 ({overall_adv:.6f}), skipping evaluation, returning all GOOD")
            flags_per_sample[sample_idx] = [True] * len(steps)  # æ‰€æœ‰stepéƒ½æ ‡è®°ä¸ºGOOD
            skipped_samples += 1
            continue
        
        # ä¸ºéé›¶advantageçš„æ ·æœ¬åˆ›å»ºè¯„ä¼°ä»»åŠ¡
        for step_idx, step_text in enumerate(steps):
            task = EvaluationTask(
                sample_idx=sample_idx,
                step_idx=step_idx,
                query=query,
                rollout=rollout,
                step_text=step_text,
                overall_adv=overall_adv
            )
            all_tasks.append(task)
    
    total_tasks = len(all_tasks)
    print(f"[parallel_eval] Total tasks to process: {total_tasks}")
    print(f"[parallel_eval] Skipped {skipped_samples} samples with advantage=0")
    
    if total_tasks == 0:
        # æ‰€æœ‰æ ·æœ¬éƒ½è¢«è·³è¿‡äº†
        print("[parallel_eval] No tasks to process, all samples had advantage=0")
        await client.close()
        return flags_per_sample, {
            "total_tasks": 0,
            "successful_tasks": 0,
            "failed_tasks": 0,
            "total_api_time": 0,
            "avg_api_time": 0,
            "max_concurrent": max_concurrent,
            "fallback_used": False,
            "skipped_samples": skipped_samples
        }
    
    # åˆ†æ‰¹å¤„ç†ä»»åŠ¡ï¼ˆé¿å…å†…å­˜è¿‡å¤§ï¼‰
    all_results = []
    semaphore = asyncio.Semaphore(max_concurrent)
    
    # ä½¿ç”¨è¿›åº¦æ¡
    with tqdm(total=total_tasks, desc="[parallel_eval] Processing tasks") as pbar:
        for i in range(0, total_tasks, batch_size_limit):
            batch_tasks = all_tasks[i:i + batch_size_limit]
            
            # åˆ›å»ºåç¨‹ä»»åŠ¡
            coroutines = [
                _evaluate_single_task(client, model_name, task, semaphore)
                for task in batch_tasks
            ]
            
            # ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
            batch_results = await asyncio.gather(*coroutines, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for result in batch_results:
                if isinstance(result, Exception):
                    print(f"[parallel_eval] Task failed with exception: {result}")
                    continue
                all_results.append(result)
            
            pbar.update(len(batch_tasks))
    
    # æ•´ç†ç»“æœåˆ°å·²ç»åˆå§‹åŒ–çš„flags_per_sampleä¸­
    # æŒ‰sample_idxå’Œstep_idxæ’åº
    all_results.sort(key=lambda x: (x.sample_idx, x.step_idx))
    
    for result in all_results:
        # ä¸ºéè·³è¿‡çš„æ ·æœ¬å¡«å……ç»“æœ
        if not flags_per_sample[result.sample_idx]:  # å¦‚æœè¿˜æ˜¯ç©ºåˆ—è¡¨
            flags_per_sample[result.sample_idx] = []
        flags_per_sample[result.sample_idx].append(result.is_good)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_time = sum(r.response_time for r in all_results)
    avg_time = total_time / len(all_results) if all_results else 0
    
    stats = {
        "total_tasks": total_tasks,
        "successful_tasks": len(all_results),
        "failed_tasks": total_tasks - len(all_results),
        "total_api_time": total_time,
        "avg_api_time": avg_time,
        "max_concurrent": max_concurrent,
        "fallback_used": False,
        "skipped_samples": skipped_samples
    }
    
    print(f"[parallel_eval] Completed. Stats: {stats}")
    await client.close()  # å…³é—­å®¢æˆ·ç«¯
    
    return flags_per_sample, stats

def _apply_fallback_strategy_parallel(batch) -> List[List[bool]]:
    """å¹¶è¡Œfallbackç­–ç•¥"""
    import random
    
    flags_per_sample = []
    for steps in batch.non_tensor_batch["steps"]:
        flags = [random.choice([True, False]) for _ in steps]
        flags_per_sample.append(flags)
    
    return flags_per_sample

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2. å‘é‡åŒ–çš„maskåº”ç”¨
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def apply_step_mask_vectorized(batch,
                             step_flags: List[List[bool]],
                             good_scale: float = 1.0,
                             bad_scale: float = 0.2,
                             neg_bad_scale: float = -0.2) -> Dict:
    """
    å‘é‡åŒ–ç‰ˆæœ¬çš„step maskåº”ç”¨ï¼Œé¿å…åµŒå¥—å¾ªç¯
    å¯¹äºadvantage=0çš„æ ·æœ¬è·³è¿‡å¤„ç†
    
    Returns:
        stats: åº”ç”¨ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"[vectorized_mask] Starting vectorized mask application")
    
    # æ£€æŸ¥å¿…è¦çš„è¾“å…¥
    if 'step_ids' not in batch.batch:
        raise ValueError("batch.batch['step_ids'] is required but not found")
    
    adv = batch.batch["advantages"]  # (bs, resp_len)
    step_ids = batch.batch["step_ids"].to(adv.device)  # (bs, resp_len)
    
    bs, resp_len = adv.shape
    
    if len(step_flags) != bs:
        raise ValueError(f"step_flags length ({len(step_flags)}) != batch size ({bs})")
    
    # åˆå§‹åŒ–scaleä¸ºå…¨1
    scale = torch.ones_like(adv)
    
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨loss_maskè€Œä¸æ˜¯response_maskè®¡ç®—overall advantage
    overall_advs = []
    
    # è·å–loss_maskçš„responseéƒ¨åˆ†
    loss_mask = batch.batch["loss_mask"][:, -resp_len:]  # å–responseéƒ¨åˆ†çš„loss_mask
    
    for sample_idx in range(bs):
        sample_loss_mask = loss_mask[sample_idx]
        
        overall_adv = _get_overall_advantage(
            adv[sample_idx], 
            sample_loss_mask
        )
        overall_advs.append(overall_adv)
    
    overall_advs = torch.tensor(overall_advs, device=adv.device)
    overall_pos = overall_advs > 0  # (bs,) bool tensor
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "total_samples": bs,
        "total_tokens": resp_len * bs,
        "tokens_modified": 0,
        "good_steps": 0,
        "bad_steps": 0,
        "positive_samples": overall_pos.sum().item(),
        "negative_samples": (~overall_pos).sum().item(),
        "zero_adv_samples": 0  # æ–°å¢ï¼šé›¶advantageæ ·æœ¬ç»Ÿè®¡
    }
    
    # å¤„ç†æ¯ä¸ªæ ·æœ¬ï¼ˆè¿™éƒ¨åˆ†è¿˜æ˜¯éœ€è¦å¾ªç¯ï¼Œä½†å†…éƒ¨æ˜¯å‘é‡åŒ–çš„ï¼‰
    for b in tqdm(range(bs), desc="[vectorized_mask] Processing samples"):
        current_step_flags = step_flags[b]
        overall_adv_sum = overall_advs[b].item()
        
        # æ–°å¢ï¼šå¦‚æœadvantageä¸º0ï¼Œè·³è¿‡å¤„ç†ï¼ˆä¿æŒscale=1.0ï¼‰
        if abs(overall_adv_sum) < 1e-8:
            stats["zero_adv_samples"] += 1
            continue
        
        if not current_step_flags:
            continue
            
        # è·å–å½“å‰æ ·æœ¬çš„step_idså’Œadvantages
        sample_step_ids = step_ids[b]  # (resp_len,)
        sample_adv = adv[b]  # (resp_len,)
        sample_overall_pos = overall_pos[b].item()
        
        # ä¸ºæ¯ä¸ªstepåˆ›å»ºmaskå’Œå¯¹åº”çš„scale factor
        max_step_id = len(current_step_flags)
        
        # å‘é‡åŒ–å¤„ç†ï¼šä¸ºæ¯ä¸ªstep_idåˆ›å»ºmask
        for step_id, is_good in enumerate(current_step_flags):
            # åˆ›å»ºå½“å‰stepçš„token mask
            step_mask = (sample_step_ids == step_id)  # (resp_len,)
            
            if not step_mask.any():
                continue
            
            # æ ¹æ®overall_poså’Œis_goodç¡®å®šscale factor
            if sample_overall_pos:
                factor = good_scale if is_good else bad_scale
            else:
                factor = neg_bad_scale if is_good else good_scale
            
            # åº”ç”¨scale factor
            scale[b].masked_fill_(step_mask, factor)
            
            # æ›´æ–°ç»Ÿè®¡
            tokens_in_step = step_mask.sum().item()
            stats["tokens_modified"] += tokens_in_step
            
            if is_good:
                stats["good_steps"] += 1
            else:
                stats["bad_steps"] += 1
    
    # ç¡®ä¿å¡«å……tokenï¼ˆstep_id == -1ï¼‰ä¿æŒscale=1.0
    padding_mask = (step_ids == -1)
    scale.masked_fill_(padding_mask, 1.0)
    
    # åº”ç”¨scale
    original_adv_sum = adv.sum().item()
    batch.batch["advantages"] = adv * scale
    new_adv_sum = batch.batch["advantages"].sum().item()
    
    # ä¿å­˜scaleç”¨äºè°ƒè¯•
    batch.batch["semantic_scale"] = scale
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    stats["original_adv_sum"] = original_adv_sum
    stats["new_adv_sum"] = new_adv_sum
    stats["adv_change_ratio"] = new_adv_sum / original_adv_sum if original_adv_sum != 0 else 1.0
    
    print(f"[vectorized_mask] Completed. Advantages: {original_adv_sum:.4f} -> {new_adv_sum:.4f}")
    print(f"[vectorized_mask] Modified {stats['tokens_modified']} tokens ({stats['good_steps']} good steps, {stats['bad_steps']} bad steps)")
    print(f"[vectorized_mask] Skipped {stats['zero_adv_samples']} samples with advantage=0")
    
    return stats

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3. åŒæ­¥åŒ…è£…å‡½æ•°ï¼ˆç”¨äºæ›¿æ¢åŸæ¥çš„å‡½æ•°ï¼‰
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

def evaluate_step_flags(tokenizer,
                        batch,
                        good_words: tuple[str, ...] = ("GOOD",),
                        bad_words: tuple[str, ...] = ("BAD",),
                        model_name: str = "qwen-max",
                        use_parallel: bool = True,
                        max_concurrent: int = 20) -> List[List[bool]]:
    """
    å…¼å®¹æ€§åŒ…è£…å‡½æ•°ï¼Œå¯é€‰æ‹©ä½¿ç”¨å¹¶è¡Œæˆ–ä¸²è¡Œç‰ˆæœ¬
    """
    if use_parallel:
        # ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œç‰ˆæœ¬
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        flags, stats = loop.run_until_complete(
            evaluate_step_flags_parallel(
                tokenizer=tokenizer,
                batch=batch,
                model_name=model_name,
                max_concurrent=max_concurrent
            )
        )
        
        print(f"[evaluate_step_flags] Parallel execution stats: {stats}")
        return flags
    else:
        # ä½¿ç”¨åŸæ¥çš„ä¸²è¡Œç‰ˆæœ¬ï¼ˆéœ€è¦ä»åŸæ–‡ä»¶å¯¼å…¥ï¼‰
        print("[evaluate_step_flags] Using serial version (not implemented here)")
        raise NotImplementedError("Serial version not included in parallel implementation")

def apply_step_mask(batch,
                   step_flags: List[List[bool]],
                   good_scale: float = 1.0,
                   bad_scale: float = 0.2,
                   neg_bad_scale: float = -0.2,
                   use_vectorized: bool = True):
    """
    å…¼å®¹æ€§åŒ…è£…å‡½æ•°ï¼Œå¯é€‰æ‹©ä½¿ç”¨å‘é‡åŒ–æˆ–åŸç‰ˆæœ¬
    """
    if use_vectorized:
        stats = apply_step_mask_vectorized(
            batch=batch,
            step_flags=step_flags,
            good_scale=good_scale,
            bad_scale=bad_scale,
            neg_bad_scale=neg_bad_scale
        )
        return stats
    else:
        # ä½¿ç”¨åŸæ¥çš„ç‰ˆæœ¬ï¼ˆéœ€è¦ä»åŸæ–‡ä»¶å¯¼å…¥ï¼‰
        print("[apply_step_mask] Using original version (not implemented here)")
        raise NotImplementedError("Original version not included in vectorized implementation")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4. æ‰¹é‡å¤„ç†å·¥å…·å‡½æ•°
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

class ParallelSemanticProcessor:
    """å¹¶è¡Œè¯­ä¹‰å¤„ç†å™¨ï¼Œç”¨äºç®¡ç†æ•´ä¸ªæµç¨‹"""
    
    def __init__(self, 
                 max_concurrent: int = 20,
                 batch_size_limit: int = 100,
                 model_name: str = "qwen-max"):
        self.max_concurrent = max_concurrent
        self.batch_size_limit = batch_size_limit
        self.model_name = model_name
        
    async def process_batch(self, tokenizer, batch, 
                          good_scale: float = 1.0,
                          bad_scale: float = 0.2,
                          neg_bad_scale: float = -0.2) -> Dict:
        """
        å¤„ç†æ•´ä¸ªbatchçš„è¯­ä¹‰è¯„ä¼°å’Œmaskåº”ç”¨
        å¯¹äºadvantage=0çš„æ ·æœ¬ä¼šè·³è¿‡è¯„ä¼°
        
        Returns:
            ç»¼åˆç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()
        
        # 1. å¹¶è¡Œè¯„ä¼°step flags
        print("[ParallelSemanticProcessor] Starting step evaluation...")
        eval_start = time.time()
        
        step_flags, eval_stats = await evaluate_step_flags_parallel(
            tokenizer=tokenizer,
            batch=batch,
            model_name=self.model_name,
            max_concurrent=self.max_concurrent,
            batch_size_limit=self.batch_size_limit
        )
        
        eval_time = time.time() - eval_start
        print(f"[ParallelSemanticProcessor] Step evaluation completed in {eval_time:.2f}s")
        
        # 2. å‘é‡åŒ–åº”ç”¨mask
        print("[ParallelSemanticProcessor] Applying step mask...")
        mask_start = time.time()
        
        mask_stats = apply_step_mask_vectorized(
            batch=batch,
            step_flags=step_flags,
            good_scale=good_scale,
            bad_scale=bad_scale,
            neg_bad_scale=neg_bad_scale
        )
        
        mask_time = time.time() - mask_start
        print(f"[ParallelSemanticProcessor] Step mask applied in {mask_time:.2f}s")
        
        # 3. åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        total_time = time.time() - start_time
        
        combined_stats = {
            "total_processing_time": total_time,
            "evaluation_time": eval_time,
            "mask_application_time": mask_time,
            "evaluation_stats": eval_stats,
            "mask_stats": mask_stats,
            "speedup_info": {
                "parallel_evaluation": True,
                "vectorized_masking": True,
                "max_concurrent": self.max_concurrent
            }
        }
        
        print(f"[ParallelSemanticProcessor] Total processing time: {total_time:.2f}s")
        return combined_stats
    
    def process_batch_sync(self, tokenizer, batch, **kwargs) -> Dict:
        """åŒæ­¥ç‰ˆæœ¬çš„batchå¤„ç†"""
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        return loop.run_until_complete(
            self.process_batch(tokenizer, batch, **kwargs)
        )